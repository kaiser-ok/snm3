# 人工标注指南

**日期**: 2025-11-17
**版本**: v1.0
**适用工具**: `optimize_classifier_thresholds_v2.py`

---

## 目录

1. [标注概述](#标注概述)
2. [标注流程](#标注流程)
3. [如何做出正确判断](#如何做出正确判断)
4. [实战示例](#实战示例)
5. [标注策略](#标注策略)
6. [持续标注流程](#持续标注流程)
7. [注意事项](#注意事项)

---

## 标注概述

### 什么是人工标注？

人工标注是指**人工审查**分类器的判断结果，并标记为：
- **正确** (`y`): 分类器判断正确，这是真实威胁
- **错误** (`n`): 分类器判断错误，这是误报
- **跳过** (`s`): 不确定，需要更多信息

### 为什么需要人工标注？

```
问题：优化工具的假设
"被分类为 DDoS 的异常，都是真正的 DDoS"
       ↓
如果有大量误报，这个假设不成立
       ↓
基于误报数据优化，会放大错误
       ↓
需要人工标注，过滤误报
```

### 标注数据的用途

```
人工标注数据
    ↓
分离真实威胁 vs 误报
    ↓
只基于真实威胁优化阈值
    ↓
分析误报特征，提供排除规则
    ↓
提高分类器准确率
```

---

## 标注流程

### 启动标注

```bash
# 收集过去 7 天的异常并开始标注
python3 optimize_classifier_thresholds_v2.py --label --days 7
```

### 标注界面

工具会显示每个异常的详细信息：

```
================================================================================
异常 #1/50 (已标注: 0)
================================================================================

📍 基本信息:
   IP: 192.168.1.100
   时间: 2025-11-17 14:30:00
   异常分数: 0.7500

📊 流量特征:
   连线数: 7,500
   总流量: 2.63 GB
   平均流量: 350 bytes
   最大流量: 5.00 MB

🎯 目标分析:
   不同目的地: 5
   不同源端口: 1500
   不同目的端口: 3
   目的地分散度: 0.001

🏷️  行为标记:
   高连线数, 小封包

🤖 分类器判断:
   类别: DDoS 攻击 (DDOS)
   置信度: 75%
   严重性: CRITICAL
   关键指标:
      • 极高连线数: 7,500
      • 极小封包: 350 bytes

👤 这个判断正确吗？(y/n/s/q):
```

### 标注选项

| 输入 | 含义 | 何时使用 |
|------|------|---------|
| `y` | Yes - 判断正确 | 确认这是真实威胁 |
| `n` | No - 判断错误 | 这是误报 |
| `s` | Skip - 跳过 | 不确定，需要更多信息 |
| `q` | Quit - 退出 | 暂停标注，保存进度 |

---

## 标注场景详解

### 场景 1: 分类器判断正确

```
👤 这个判断正确吗？(y/n/s/q): y  ← 输入 y

   ✓ 标注为：真实威胁

[自动保存到 labeled_anomalies.json]
[继续下一个异常...]
```

#### 什么时候输入 `y`？

你确认这**确实是威胁**，符合分类器判断的威胁类型：

**DDoS 的典型特征**：
- ✅ 极高连线数 (> 50,000)
- ✅ 极小封包 (< 300 bytes) - SYN Flood
- ✅ 目标集中 (< 10 个目的地)
- ✅ 目的地分散度低 (< 0.05)
- ✅ 突然爆发
- ✅ 不是已知的正常服务

**端口扫描的典型特征**：
- ✅ 扫描大量端口 (> 100)
- ✅ 小封包 (< 5KB)
- ✅ 端口高度分散
- ✅ 不是正常业务流量

**网络扫描的典型特征**：
- ✅ 扫描大量主机 (> 50)
- ✅ 目的地高度分散
- ✅ 高连线数但低流量
- ✅ 不是正常业务流量

---

### 场景 2: 分类器判断错误（误报）

```
👤 这个判断正确吗？(y/n/s/q): n  ← 输入 n

   ✗ 标注为：误报

   真实类型是什么？
   1. PORT_SCAN (端口扫描)
   2. NETWORK_SCAN (网络扫描)
   3. DNS_TUNNELING (DNS 隧道)
   4. DDOS (DDoS 攻击)
   5. DATA_EXFILTRATION (数据外泄)
   6. C2_COMMUNICATION (C&C 通信)
   7. NORMAL_HIGH_TRAFFIC (正常高流量)  ← 最常选择
   8. UNKNOWN (未知)
   9. 跳过
   请选择 (1-9): 7  ← 输入 7

   → 真实类型：NORMAL_HIGH_TRAFFIC
```

#### 什么时候输入 `n`？

这**不是分类器判断的威胁类型**，例如：

**常见误报案例**：
- 🎥 **视频会议服务器**
  - 特征：工作时间，连接视频会议服务器，使用 443/3478 端口
  - 真实类型：选 `7` (正常高流量)

- 💾 **备份系统**
  - 特征：凌晨时间，超大流量，单一目的地，大包
  - 真实类型：选 `7` (正常高流量)

- 🔗 **API 网关**
  - 特征：高连线数，已知服务器，标准端口
  - 真实类型：选 `7` (正常高流量)

- 🌐 **DNS 服务器**
  - 特征：大量 DNS 查询，但是正常 DNS 解析
  - 真实类型：选 `7` (正常高流量)

- 🗄️ **数据库同步**
  - 特征：大流量，特定时间，已知数据库服务器
  - 真实类型：选 `7` (正常高流量)

#### 如何选择真实类型

| 真实情况 | 选择 |
|---------|------|
| 视频会议、备份、API 等正常业务 | 7 - NORMAL_HIGH_TRAFFIC |
| 确实在扫描端口 | 1 - PORT_SCAN |
| 确实在扫描网络 | 2 - NETWORK_SCAN |
| 完全无法判断 | 8 - UNKNOWN |
| 需要更多信息 | 9 - 跳过 |

---

### 场景 3: 不确定

```
👤 这个判断正确吗？(y/n/s/q): s  ← 输入 s

   ⊙ 跳过

[不标注此异常，继续下一个]
```

#### 什么时候输入 `s`？

- ❓ **信息不足**，无法判断
- ❓ 需要查看**更详细的数据**
- ❓ 需要**深入分析**目的地 IP
- ❓ 需要**查询时间模式**

**建议**：跳过后，使用 `verify_anomaly.py` 深入分析，分析清楚后再标注。

---

### 场景 4: 退出标注

```
👤 这个判断正确吗？(y/n/s/q): q  ← 输入 q

退出标注

💾 标注数据已保存到: nad/models/labeled_anomalies.json

================================================================================
标注统计
================================================================================

DDOS                      True:   3  False:   8
NORMAL_HIGH_TRAFFIC       True:  10  False:   0
PORT_SCAN                 True:   2  False:   1

总计                      True:  15  False:   9

整体准确率: 62.5%
```

#### 什么时候输入 `q`？

- 😴 **需要休息**
- ✅ **已标注足够数量**（建议每次 10-20 个）
- ⏰ **稍后继续**

**注意**：数据会**自动保存**，下次可以继续。

---

## 如何做出正确判断

### 判断技巧 1: 查看目的地 IP

虽然工具界面只显示统计信息，但你可以**结合 verify_anomaly.py** 进行深入分析。

#### 在另一个终端窗口执行

```bash
# 深入分析某个 IP
python3 verify_anomaly.py --ip 192.168.1.100 --minutes 30
```

#### 查看输出

```
================================================================================
🔍 深入分析: 192.168.1.100
================================================================================

📊 目的地分析:
  不同目的地数量: 5
  Top 5 目的地:
    1. 192.168.50.10 (5000 连线) ← 这是什么服务器？
    2. 192.168.50.11 (1500 连线)
    3. 192.168.50.12 (500 连线)
    4. 192.168.50.20 (300 连线)
    5. 192.168.50.30 (200 连线)

📊 端口分析:
  源端口: 主要使用 49152-65535 (客户端随机端口)
  目的端口:
    - 443 (3000 连线) ← HTTPS
    - 3478 (2000 连线) ← TURN (视频会议端口！)
    - 3479 (500 连线) ← TURN
```

#### 判断

- ✅ 如果目的地是**已知的视频会议服务器** → 不是 DDoS
  - 选择 `n` → `7` (正常高流量)

- ✅ 如果目的端口是**视频会议端口** (443, 3478, 3479) → 不是 DDoS
  - 选择 `n` → `7` (正常高流量)

- ⚠️ 如果目的地是**未知的外部 IP**，且端口异常 → 可能是 DDoS
  - 选择 `y` 或深入调查

---

### 判断技巧 2: 查看时间模式

```bash
# 分析 24 小时的时间模式
python3 verify_anomaly.py --ip 192.168.1.100 --minutes 1440
```

#### 输出

```
📊 时间模式:
  时间段: 09:00-17:00  ← 工作时间
  模式: 持续稳定
  周期性: 每个工作日都有
```

#### 判断

- ✅ 如果发生在**工作时间，持续稳定** → 可能是正常业务
  - 视频会议、API 调用等

- ⚠️ 如果**突然爆发，短时间内** → 更像 DDoS
  - 例如：凌晨 3 点突然出现 10 万连线

- ✅ 如果有**周期性规律** → 可能是定时任务
  - 备份（每天凌晨 2 点）
  - 数据同步（每小时）

---

### 判断技巧 3: 检查流量特征

#### 真实 DDoS 的典型特征

```
✓ 连线数: > 50,000（极高）
✓ 平均流量: < 300 bytes（极小包，SYN Flood）
✓ 目的地: < 10 个（非常集中）
✓ 目的地分散度: < 0.05（高度集中）
✓ 时间: 突然爆发，非规律
✓ 目的地: 通常是公网 IP 或关键服务器
✓ 端口: 可能集中在某个服务端口
```

#### 正常高流量的典型特征

```
✓ 连线数: 5,000-20,000（中等）
✓ 平均流量: 300-1,000 bytes（稍大）
✓ 目的地: 5-20 个（分散）
✓ 目的地: 已知的内网服务器
✓ 时间: 工作时间，有规律
✓ 端口: 标准服务端口（443, 8080, 3478 等）
✓ 周期性: 每天都有，或固定时间段
```

#### 端口扫描的典型特征

```
✓ 不同目的端口: > 100（扫描大量端口）
✓ 平均流量: < 5KB（小封包）
✓ 端口分散度: > 0.5（高度分散）
✓ 目的地: 可能只有 1-5 个
✓ 时间: 任意时间
```

#### 网络扫描的典型特征

```
✓ 不同目的地: > 50（扫描大量主机）
✓ 目的地分散度: > 0.3（高度分散）
✓ 连线数: > 1,000
✓ 平均流量: 中等（< 50KB）
✓ 时间: 任意时间
```

---

### 判断技巧 4: 查看置信度

```
🤖 分类器判断:
   类别: DDoS 攻击
   置信度: 65%  ← 注意这个值
```

#### 置信度参考

| 置信度 | 建议 |
|--------|------|
| < 60% | 很可能误报，重点审查 |
| 60-70% | 置信度偏低，建议深入分析 |
| 70-85% | 中等置信度，需要人工确认 |
| 85-95% | 置信度较高，但仍需验证 |
| > 95% | 高置信度，很可能是真实威胁 |

**注意**：置信度高不代表一定正确！仍需人工验证。

---

## 实战示例

### 示例 1: 真实的 DDoS ✓

```
================================================================================
异常 #15/50
================================================================================

📍 基本信息:
   IP: 192.168.5.80
   时间: 2025-11-17 03:25:00  ← 凌晨 3 点（异常时间）
   异常分数: 0.9500

📊 流量特征:
   连线数: 85,000  ← 极高！
   总流量: 12.5 GB
   平均流量: 150 bytes  ← 极小包！
   最大流量: 2.00 MB

🎯 目标分析:
   不同目的地: 3  ← 非常集中！
   不同源端口: 45,000
   不同目的端口: 1  ← 只攻击一个端口！
   目的地分散度: 0.003  ← 高度集中！

🏷️  行为标记:
   高连线数, 小封包

🤖 分类器判断:
   类别: DDoS 攻击 (DDOS)
   置信度: 95%
   严重性: CRITICAL
   关键指标:
      • 极高连线数: 85,000
      • 极小封包: 150 bytes
      • 目标集中: 3 个目的地
```

#### 分析

- ✅ 极高连线数（85,000）- 远超正常
- ✅ 极小封包（150 bytes）- 典型 SYN Flood
- ✅ 目标极度集中（3 个目的地）
- ✅ 凌晨时间（异常）
- ✅ 单一目的端口（可能攻击某个服务）
- ✅ 高异常分数（0.95）
- ✅ 高置信度（95%）

#### 判断

```
👤 这个判断正确吗？(y/n/s/q): y  ← 输入 y

   ✓ 标注为：真实威胁
```

**理由**：所有特征都符合 DDoS 攻击模式。

---

### 示例 2: 视频会议（误报）✗

```
================================================================================
异常 #8/50
================================================================================

📍 基本信息:
   IP: 192.168.1.100
   时间: 2025-11-17 14:30:00  ← 下午工作时间
   异常分数: 0.7500

📊 流量特征:
   连线数: 7,500  ← 不算特别高
   总流量: 2.63 GB
   平均流量: 350 bytes  ← 稍大
   最大流量: 5.00 MB

🎯 目标分析:
   不同目的地: 5  ← 几个视频会议服务器
   不同源端口: 1,500
   不同目的端口: 3  ← 443, 3478（视频会议端口）
   目的地分散度: 0.001

🏷️  行为标记:
   高连线数, 小封包

🤖 分类器判断:
   类别: DDoS 攻击 (DDOS)
   置信度: 75%
   严重性: CRITICAL
```

#### 深入分析（在另一个终端）

```bash
python3 verify_anomaly.py --ip 192.168.1.100 --minutes 30
```

```
📊 目的地分析:
  Top 5 目的地:
    1. 192.168.50.10 (5000 连线) - Zoom Server
    2. 192.168.50.11 (1500 连线) - Teams Server
    3. 192.168.50.12 (500 连线) - Zoom Server
    4. 192.168.50.20 (300 连线) - Teams Server
    5. 192.168.50.30 (200 连线) - Zoom Server

📊 端口分析:
  目的端口:
    - 443 (3500 连线) - HTTPS
    - 3478 (2500 连线) - TURN (视频会议)
    - 3479 (500 连线) - TURN

📊 时间模式:
  时间段: 14:00-15:00 (工作时间)
  模式: 持续稳定
```

#### 分析

- ❌ 连线数不算极高（7,500）
- ❌ 封包不算极小（350 bytes）
- ❌ 工作时间（14:30）
- ❌ 目的地是已知视频会议服务器
- ❌ 使用视频会议端口（443, 3478）
- ❌ 流量持续稳定，不是突发

#### 判断

```
👤 这个判断正确吗？(y/n/s/q): n  ← 输入 n

   ✗ 标注为：误报

   真实类型是什么？
   1. PORT_SCAN (端口扫描)
   2. NETWORK_SCAN (网络扫描)
   3. DNS_TUNNELING (DNS 隧道)
   4. DDOS (DDoS 攻击)
   5. DATA_EXFILTRATION (数据外泄)
   6. C2_COMMUNICATION (C&C 通信)
   7. NORMAL_HIGH_TRAFFIC (正常高流量)  ← 选择
   8. UNKNOWN (未知)
   9. 跳过
   请选择 (1-9): 7  ← 输入 7

   → 真实类型：NORMAL_HIGH_TRAFFIC
```

**理由**：这是正常的视频会议流量。

**建议**：应该加入白名单！

```yaml
# nad/config.yaml
whitelist:
  services:
    - name: "Video Conference"
      dst_ips:
        - 192.168.50.10
        - 192.168.50.11
        - 192.168.50.12
        - 192.168.50.20
        - 192.168.50.30
      dst_ports: [443, 3478, 3479]
      time_range: "08:00-18:00"
```

---

### 示例 3: 备份系统（误报）✗

```
================================================================================
异常 #23/50
================================================================================

📍 基本信息:
   IP: 192.168.2.50
   时间: 2025-11-17 02:00:00  ← 凌晨 2 点（备份时间）
   异常分数: 0.8200

📊 流量特征:
   连线数: 15,000
   总流量: 850 GB  ← 超大流量！
   平均流量: 56,666 bytes  ← 大包！
   最大流量: 2.5 GB  ← 超大单个流

🎯 目标分析:
   不同目的地: 1  ← 备份服务器
   不同源端口: 500
   不同目的端口: 1  ← 备份端口
   目的地分散度: 0.000

🏷️  行为标记:
   高连线数, 大流量

🤖 分类器判断:
   类别: 数据外泄 (DATA_EXFILTRATION)
   置信度: 82%
   严重性: CRITICAL
```

#### 深入分析

```bash
python3 verify_anomaly.py --ip 192.168.2.50 --minutes 120
```

```
📊 目的地分析:
  Top 1 目的地:
    1. 192.168.100.10 (15000 连线) - Backup Server

📊 端口分析:
  目的端口:
    - 9876 (15000 连线) - Backup Service

📊 时间模式:
  时间段: 01:00-05:00 (凌晨备份时间)
  模式: 每天凌晨都有
  周期性: 非常规律
```

#### 分析

- ❌ 平均流量很大（56KB）- 不是小包攻击
- ❌ 单个流超大（2.5GB）- 典型的文件传输
- ❌ 凌晨 2 点 - 备份时间
- ❌ 单一目的地 - 备份服务器
- ❌ 每天都有 - 定时任务
- ❌ 大流量是正常备份行为

#### 判断

```
👤 这个判断正确吗？(y/n/s/q): n  ← 输入 n

   ✗ 标注为：误报

   真实类型是什么？
   请选择 (1-9): 7  ← 正常高流量

   → 真实类型：NORMAL_HIGH_TRAFFIC
```

**理由**：这是正常的备份流量。

**建议**：加入白名单！

```yaml
# nad/config.yaml
whitelist:
  services:
    - name: "Backup System"
      src_ips: ["192.168.2.50"]
      dst_ips: ["192.168.100.10"]
      dst_ports: [9876]
      time_range: "01:00-05:00"
      min_total_bytes: 1e11  # > 100GB
```

---

### 示例 4: 不确定的案例（跳过）⊙

```
================================================================================
异常 #35/50
================================================================================

📍 基本信息:
   IP: 192.168.8.123
   时间: 2025-11-17 16:45:00
   异常分数: 0.7200

📊 流量特征:
   连线数: 12,000
   总流量: 5.5 GB
   平均流量: 458 bytes
   最大流量: 15 MB

🎯 目标分析:
   不同目的地: 15
   不同源端口: 3,000
   不同目的端口: 8
   目的地分散度: 0.125

🤖 分类器判断:
   类别: DDoS 攻击 (DDOS)
   置信度: 72%
```

#### 分析

- ⚠️ 连线数中等（12,000）- 不算极高也不算低
- ⚠️ 封包中等（458 bytes）- 不是极小包
- ⚠️ 目的地中等（15 个）- 不算集中也不算分散
- ❓ 没有明显的特征模式

#### 判断

```
👤 这个判断正确吗？(y/n/s/q): s  ← 输入 s（跳过）

   ⊙ 跳过
```

**理由**：特征不明显，需要更多信息。

**下一步**：
1. 使用 `verify_anomaly.py` 深入分析
2. 查看目的地 IP 是什么
3. 分析时间模式
4. 分析清楚后再标注

---

## 标注策略

### 标注数量目标

#### 最少目标

```
每种威胁类型: 10-20 个 true 样本
总计: 50-100 个标注

目标：
- 能够生成初步推荐
- 了解基本的误报模式
```

#### 理想目标

```
每种威胁类型: 50-100 个 true 样本
总计: 200-500 个标注

目标：
- 生成可靠的推荐阈值
- 全面分析误报特征
- 为监督学习准备数据
```

#### 最优目标

```
每种威胁类型: 200-500 个 true 样本
总计: 1000-2000 个标注

目标：
- 训练监督学习分类器
- 最高准确率
```

### 优先级排序

#### 第一优先：明显的案例

```
✅ 明显的 DDoS
- 连线数 > 100K
- 封包 < 200 bytes
- 目的地 < 5

✅ 明显的正常流量
- 已知服务器
- 工作时间
- 标准端口
```

**建议**：先标注 20-30 个明显案例，快速积累数据。

#### 第二优先：中等难度

```
⚠️ 需要查看目的地 IP
⚠️ 需要分析时间模式
⚠️ 需要查询端口用途
```

**建议**：结合 `verify_anomaly.py` 深入分析。

#### 第三优先：困难案例

```
❓ 特征不明显
❓ 需要深入调查
❓ 需要领域知识
```

**建议**：先跳过，等有更多经验后再标注。

### 标注时间安排

#### 每日标注计划

```
Session 1（早上 30 分钟）:
- 标注 10-15 个明显案例
- 休息 10 分钟

Session 2（下午 30 分钟）:
- 标注 10-15 个
- 深入分析 2-3 个困难案例

每天目标: 20-30 个标注
```

#### 周期计划

```
Week 1:
- 标注 100-150 个
- 主要是明显案例

Week 2:
- 标注 100-150 个
- 开始标注中等难度案例
- 第一次生成推荐

Week 3-4:
- 继续标注
- 应用推荐阈值
- 观察效果
```

**注意**：不要一次性标注太多（容易疲劳，质量下降）

---

## 持续标注流程

### 第一次标注

```bash
# 1. 收集过去 7 天的异常并标注
python3 optimize_classifier_thresholds_v2.py --label --days 7

# 2. 标注 20-30 个后，可以退出（输入 q）
# 数据会自动保存到: nad/models/labeled_anomalies.json
```

### 继续标注

```bash
# 下次继续标注（会自动加载之前的标注数据）
python3 optimize_classifier_thresholds_v2.py --label --days 7

# 工具会自动：
# 1. 加载之前的标注（从 labeled_anomalies.json）
# 2. 收集新的异常
# 3. 继续标注
# 4. 保存更新后的标注
```

### 查看标注进度

```bash
# 方法 1: 查看已标注数量
python3 -c "
import json
with open('nad/models/labeled_anomalies.json') as f:
    data = json.load(f)
    total_true = 0
    total_false = 0
    for threat, labels in data.items():
        true_count = len(labels['true'])
        false_count = len(labels['false'])
        if true_count + false_count > 0:
            print(f'{threat:25} True: {true_count:3}  False: {false_count:3}')
            total_true += true_count
            total_false += false_count
    print(f'\n总计: True: {total_true}  False: {total_false}')
"

# 输出示例：
# DDOS                      True:   5  False:   8
# NORMAL_HIGH_TRAFFIC       True:  12  False:   0
# PORT_SCAN                 True:   3  False:   1
#
# 总计: True: 20  False: 9

# 方法 2: 运行推荐工具查看
python3 optimize_classifier_thresholds_v2.py --recommend
```

### 生成推荐

当有足够标注数据后（每种威胁至少 5 个 true 样本）：

```bash
# 基于标注数据生成推荐
python3 optimize_classifier_thresholds_v2.py --recommend

# 输出：
# ================================================================================
# 基于标注数据推荐阈值
# ================================================================================
#
# ✓ DDoS: 5 个真实样本，8 个误报
#
# DDOS 阈值推荐：
#   flow_count:
#     当前值: 10000
#     推荐值: 45000      (P5)
#     变化: +35000 (+350.0%) - 更严格
#     理由: P5 值，基于真实 DDoS 数据（人工验证），95% 真实攻击会被捕获
#     样本数: 5
#     分布: min=45000, p25=52000, median=68000, p75=85000, max=120000
#
#   误报分析:
#     误报数量: 8
#     共同特征:
#       • 62% 的误报是服务器回应流量
#         建议：添加 'is_likely_server_response == 0' 条件
#       • 误报的流量集中度较低（中位数: 0.15 vs 真实: 0.85）
#         建议：添加 'traffic_concentration > 0.43' 条件
```

---

## 标注数据管理

### 数据存储位置

```
/home/kaisermac/snm_flow/nad/models/labeled_anomalies.json
```

### 数据格式

```json
{
  "DDOS": {
    "true": [
      {
        "features": {
          "flow_count": 85000,
          "avg_bytes": 150,
          "unique_dsts": 3,
          "total_bytes": 12750000,
          "dst_diversity": 0.003,
          ...
        },
        "context": {
          "src_ip": "192.168.5.80",
          "timestamp": "2025-11-17T03:25:00+00:00",
          "anomaly_score": 0.95
        },
        "classification": {
          "class": "DDOS",
          "class_name": "DDoS 攻击",
          "confidence": 0.95,
          "severity": "CRITICAL",
          ...
        }
      },
      ...
    ],
    "false": [
      {
        "features": {...},
        "context": {...},
        "classification": {...}
      },
      ...
    ]
  },
  "NORMAL_HIGH_TRAFFIC": {
    "true": [...],
    "false": [...]
  },
  ...
}
```

### 备份标注数据

```bash
# 定期备份（建议每周）
cp nad/models/labeled_anomalies.json \
   nad/models/labeled_anomalies_backup_$(date +%Y%m%d).json

# 或者使用版本控制
git add nad/models/labeled_anomalies.json
git commit -m "Update labeled anomalies - $(date +%Y%m%d)"
```

### 复查标注数据

```bash
# 每标注 50 个后，复查前 10 个
# 确保判断标准没有漂移

# 导出查看
python3 -c "
import json
with open('nad/models/labeled_anomalies.json') as f:
    data = json.load(f)
    # 查看前 5 个 DDoS true 样本
    for i, item in enumerate(data['DDOS']['true'][:5], 1):
        print(f'{i}. IP: {item[\"context\"][\"src_ip\"]}')
        print(f'   Flow count: {item[\"features\"][\"flow_count\"]:,}')
        print(f'   Avg bytes: {item[\"features\"][\"avg_bytes\"]:.0f}')
        print()
"
```

---

## 注意事项

### 1. 保持一致性

#### ✅ 好的做法

- 使用**相同的判断标准**
- 遇到类似情况时，保持**一致的判断**
- 记录判断标准，定期复查

#### ❌ 不好的做法

- 今天判断 A 是 DDoS，明天判断相同的 B 不是
- 随心情标注
- 没有判断标准

#### 建议

创建判断标准文档：

```bash
vim docs/labeling_criteria.md
```

```markdown
# 标注判断标准

## DDoS 判断标准

必须同时满足：
1. 连线数 > 50,000
2. 平均流量 < 300 bytes
3. 目的地 < 10
4. 不是已知的正常服务

## 正常高流量判断标准

符合以下任一条件：
1. 目的地是已知的视频会议/备份/API 服务器
2. 工作时间 + 标准端口
3. 有周期性规律
4. 已加入白名单
```

---

### 2. 不确定就跳过

#### ✅ 好的做法

- 不确定时输入 `s` **跳过**
- 稍后用 `verify_anomaly.py` **深入分析**
- 分析清楚后再标注
- 保持**高质量**标注

#### ❌ 不好的做法

- 随便猜一个
- 标注质量差的数据
- 强行标注不确定的案例

#### 示例

```bash
# 遇到不确定的 IP
👤 这个判断正确吗？(y/n/s/q): s  ← 跳过

# 稍后深入分析
python3 verify_anomaly.py --ip 192.168.X.X --minutes 1440

# 分析清楚后，下次标注时会再次遇到
# 这时可以做出准确判断
```

---

### 3. 定期复查

#### 复查频率

```
每标注 50 个 → 复查前 10 个
每周 → 复查本周的标注
每月 → 复查所有标注的 10%
```

#### 复查方法

```bash
# 1. 导出标注数据
python3 -c "
import json
with open('nad/models/labeled_anomalies.json') as f:
    data = json.load(f)
    # 随机抽查 10 个
    import random
    all_items = []
    for threat, labels in data.items():
        for item in labels['true']:
            all_items.append((threat, 'true', item))
        for item in labels['false']:
            all_items.append((threat, 'false', item))

    sample = random.sample(all_items, min(10, len(all_items)))

    for threat, label_type, item in sample:
        print(f'{threat} ({label_type}):')
        print(f'  IP: {item[\"context\"][\"src_ip\"]}')
        print(f'  Flow: {item[\"features\"][\"flow_count\"]:,}')
        print(f'  Bytes: {item[\"features\"][\"avg_bytes\"]:.0f}')
        print()
"

# 2. 重新验证这些案例
# 3. 如果发现错误，更正标注数据
```

---

### 4. 记录特殊案例

#### 创建案例笔记

```bash
vim docs/labeling_notes.md
```

```markdown
# 标注案例笔记

## 2025-11-17

### 案例 1: 视频会议误报
- **IP**: 192.168.1.100
- **时间**: 2025-11-17 14:30
- **特征**: 7500 连线，350 bytes，5 目的地
- **初判**: DDoS（误）
- **实际**: 视频会议
- **目的地**: 192.168.50.10-30 (Zoom/Teams 服务器)
- **端口**: 443, 3478
- **已加入白名单**: ✓

### 案例 2: 备份系统误报
- **IP**: 192.168.2.50
- **时间**: 2025-11-17 02:00
- **特征**: 15000 连线，56KB，1 目的地，850GB 总流量
- **初判**: 数据外泄（误）
- **实际**: 备份系统
- **目的地**: 192.168.100.10 (Backup Server)
- **时间模式**: 每天凌晨 1-5 点
- **已加入白名单**: ✓

### 案例 3: 真实 DDoS
- **IP**: 192.168.5.80
- **时间**: 2025-11-17 03:25
- **特征**: 85000 连线，150 bytes，3 目的地
- **判断**: DDoS（正确）
- **特点**: 凌晨突发，极小包，目标集中
- **响应**: 已隔离该主机

## 2025-11-18

### 案例 4: ...
```

#### 价值

- 📚 **知识积累**：记录特殊模式
- 🎓 **培训材料**：新成员学习
- 🔍 **troubleshooting**：遇到类似案例可参考
- 📊 **改进依据**：分析常见误报模式

---

### 5. 团队标注（如果有多人）

#### 统一标准

```bash
# 1. 创建共享的判断标准文档
vim docs/labeling_criteria_team.md

# 2. 定期开会讨论困难案例
# 3. 达成共识，更新判断标准
```

#### 交叉验证

```bash
# A 标注 → B 复查
# B 标注 → A 复查

# 不一致的案例 → 团队讨论
```

#### 一致性检查

```bash
# 定期计算标注一致性
# Kappa 系数 > 0.8 为良好
```

---

### 6. 避免标注疲劳

#### 识别疲劳信号

- 😴 开始随意标注
- 😴 不再深入分析
- 😴 大量跳过
- 😴 判断标准开始漂移

#### 应对方法

```
✅ 每次只标注 10-20 个
✅ 中间休息 10 分钟
✅ 每天最多 2 个 session
✅ 感觉疲劳立即停止
✅ 第二天复查前一天的标注
```

---

### 7. 持续改进

#### 定期评估

```bash
# 每周评估标注质量
# 1. 复查 10% 的标注
# 2. 计算错误率
# 3. 分析错误原因
# 4. 更新判断标准
```

#### 学习新模式

```bash
# 遇到新的威胁模式
# 1. 记录到案例笔记
# 2. 更新判断标准
# 3. 复查类似的历史标注
# 4. 必要时重新标注
```

---

## 总结

### 标注流程总结

```
1. 启动标注工具
   python3 optimize_classifier_thresholds_v2.py --label --days 7

2. 查看异常信息
   - 基本信息（IP、时间、分数）
   - 流量特征（连线数、流量、封包大小）
   - 目标分析（目的地、端口、分散度）

3. 结合深入分析（可选）
   python3 verify_anomaly.py --ip <IP> --minutes 30

4. 做出判断
   y - 分类正确（真实威胁）
   n - 分类错误（误报） → 选择真实类型
   s - 跳过（不确定）
   q - 退出（保存进度）

5. 定期复查
   - 每 50 个复查 10 个
   - 确保一致性

6. 生成推荐
   python3 optimize_classifier_thresholds_v2.py --recommend

7. 应用推荐
   编辑 nad/ml/anomaly_classifier.py
```

### 成功关键

1. **耐心**
   - 一次不要标注太多（10-20 个为佳）
   - 不要疲劳标注

2. **准确**
   - 不确定就跳过，不要随便猜
   - 使用工具深入分析

3. **坚持**
   - 持续 1-2 周，积累 100+ 标注
   - 每天 1-2 个 session

4. **利用工具**
   - 结合 `verify_anomaly.py` 深入分析
   - 查看目的地、端口、时间模式

5. **记录**
   - 记录特殊案例
   - 记录判断标准
   - 定期复查

### 预期成果

```
1 周后:
✓ 标注 50-100 个异常
✓ 了解常见误报模式
✓ 建立判断标准

2 周后:
✓ 标注 100-200 个异常
✓ 生成第一次推荐
✓ 开始应用推荐阈值

1 个月后:
✓ 标注 200-500 个异常
✓ 误报率显著下降
✓ 系统准确率提高

3 个月后:
✓ 标注 500-1000 个异常
✓ 考虑部署监督学习
✓ 达到生产级别准确率
```

---

**文档结束**

相关文档：
- [分类器优化与误分类处理](./CLASSIFIER_OPTIMIZATION_AND_MISCLASSIFICATION_HANDLING.md)
- [DDoS 检测与阈值优化问答](./DDOS_DETECTION_AND_THRESHOLD_OPTIMIZATION_QA.md)
- [异常验证指南](../ANOMALY_VERIFICATION_GUIDE.md)
