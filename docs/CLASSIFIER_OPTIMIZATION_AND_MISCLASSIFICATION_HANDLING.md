# åˆ†ç±»å™¨ä¼˜åŒ–ä¸è¯¯åˆ†ç±»å¤„ç†æŒ‡å—

**æ—¥æœŸ**: 2025-11-17
**ç‰ˆæœ¬**: v1.0
**é€‚ç”¨äº**: SNM Flow å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ

---

## ç›®å½•

1. [é—®é¢˜åœºæ™¯ï¼šè¯¯åˆ†ç±»çš„å½±å“](#é—®é¢˜åœºæ™¯è¯¯åˆ†ç±»çš„å½±å“)
2. [è¯¯åˆ†ç±»æ£€æµ‹æ–¹æ³•](#è¯¯åˆ†ç±»æ£€æµ‹æ–¹æ³•)
3. [å¤„ç†æ–¹æ¡ˆ](#å¤„ç†æ–¹æ¡ˆ)
   - [æ–¹æ³• 1: äººå·¥å®¡æŸ¥ + ç™½åå•](#æ–¹æ³•-1-äººå·¥å®¡æŸ¥--ç™½åå•)
   - [æ–¹æ³• 2: è°ƒæ•´åˆ†ç±»å™¨é˜ˆå€¼](#æ–¹æ³•-2-è°ƒæ•´åˆ†ç±»å™¨é˜ˆå€¼)
   - [æ–¹æ³• 3: æ”¹è¿›ä¼˜åŒ–å·¥å…·](#æ–¹æ³•-3-æ”¹è¿›ä¼˜åŒ–å·¥å…·)
   - [æ–¹æ³• 4: ä½¿ç”¨ç›‘ç£å­¦ä¹ ](#æ–¹æ³•-4-ä½¿ç”¨ç›‘ç£å­¦ä¹ )
4. [å®Œæ•´ä¼˜åŒ–æµç¨‹](#å®Œæ•´ä¼˜åŒ–æµç¨‹)
5. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## é—®é¢˜åœºæ™¯ï¼šè¯¯åˆ†ç±»çš„å½±å“

### å…¸å‹åœºæ™¯

```
åœºæ™¯ï¼šä¼˜åŒ–å·¥å…·æ”¶é›†åˆ° 12 ä¸ªè¢«åˆ†ç±»ä¸º DDoS çš„å¼‚å¸¸

IP 1:  flow_count=7500,  avg_bytes=350,  unique_dsts=5
IP 2:  flow_count=8200,  avg_bytes=420,  unique_dsts=8
...
IP 12: flow_count=50000, avg_bytes=1000, unique_dsts=35

åˆ†ç±»å™¨åˆ¤æ–­ï¼šDDoS æ”»å‡»

ä½†å®é™…æƒ…å†µï¼šè¿™äº›éƒ½ä¸æ˜¯çœŸæ­£çš„ DDoSï¼
å¯èƒ½æ˜¯ï¼š
- âœ“ æ­£å¸¸çš„è§†é¢‘ä¼šè®®æœåŠ¡å™¨
- âœ“ å¤‡ä»½ç³»ç»Ÿ
- âœ“ åˆæ³•çš„ API æœåŠ¡å™¨
- âœ“ CDN èŠ‚ç‚¹
- âœ“ æ•°æ®åº“åŒæ­¥
```

### ä¼šäº§ç”Ÿçš„é—®é¢˜

```python
# ä¼˜åŒ–å·¥å…·ä¼šåŸºäºè¿™ 12 ä¸ª"å‡ DDoS"æ¨èé˜ˆå€¼

é”™è¯¯æ¨èï¼š
  flow_count: > 7500   (P10)  â† é”™è¯¯ï¼ä¼šæŠŠæ­£å¸¸æµé‡ä¹Ÿæ ‡è®°ä¸º DDoS
  avg_bytes: < 750     (P75)  â† é”™è¯¯ï¼é˜ˆå€¼å¤ªå®½æ¾
  unique_dsts: < 30    (P90)  â† é”™è¯¯ï¼

å¦‚æœåº”ç”¨è¿™äº›é˜ˆå€¼ï¼š
â†’ å¤§é‡è¯¯æŠ¥ï¼ˆæŠŠæ­£å¸¸æµé‡è¯¯åˆ¤ä¸º DDoSï¼‰
â†’ è¿ç»´å›¢é˜Ÿç–²äºåº”å¯¹å‡è­¦æŠ¥
â†’ çœŸæ­£çš„å¨èƒå¯èƒ½è¢«å¿½ç•¥
â†’ ç³»ç»Ÿå¤±å»å¯ä¿¡åº¦
```

### æ ¸å¿ƒé—®é¢˜

âš ï¸ **ä¼˜åŒ–å·¥å…·çš„å…³é”®å‡è®¾**ï¼š

```
å‡è®¾ï¼š"è¢«åˆ†ç±»ä¸º X çš„å¼‚å¸¸ï¼Œå¤§éƒ¨åˆ†æ˜¯çœŸæ­£çš„ X"

å¦‚æœè¿™ä¸ªå‡è®¾ä¸æˆç«‹ï¼š
â†’ ç»Ÿè®¡æ•°æ®æœ‰åå·®
â†’ æ¨èçš„é˜ˆå€¼ä¼šæ”¾å¤§é”™è¯¯
â†’ å½¢æˆæ¶æ€§å¾ªç¯ï¼ˆè¶Šä¼˜åŒ–è¶Šå·®ï¼‰
```

---

## è¯¯åˆ†ç±»æ£€æµ‹æ–¹æ³•

### æ–¹æ³• 1: äººå·¥æŠ½æŸ¥

```bash
# 1. è¿è¡Œæ£€æµ‹ï¼ŒæŸ¥çœ‹æœ€è¿‘çš„å¼‚å¸¸
python3 realtime_detection.py --minutes 60

# 2. è®°å½•è¢«åˆ†ç±»ä¸º DDoS çš„ IP
# è¾“å‡ºç¤ºä¾‹ï¼š
âš ï¸  å‘ç° 12 ä¸ªå¼‚å¸¸:
1. 192.168.1.100 | DDoS | flow_count=7500  | avg_bytes=350
2. 192.168.1.200 | DDoS | flow_count=8200  | avg_bytes=420
3. 192.168.1.50  | DDoS | flow_count=12000 | avg_bytes=480
...

# 3. éšæœºæŠ½æŸ¥ 3-5 ä¸ªè¿›è¡Œæ·±å…¥åˆ†æ
python3 verify_anomaly.py --ip 192.168.1.100 --minutes 30
```

### æ–¹æ³• 2: éªŒè¯ç›®çš„åœ°

```bash
# åˆ†æå¼‚å¸¸ IP çš„ç›®çš„åœ°
python3 verify_anomaly.py --ip 192.168.1.100 --minutes 30

# æ£€æŸ¥è¾“å‡ºï¼š
ğŸ“Š ç›®çš„åœ°åˆ†æï¼š
  Top 5 ç›®çš„åœ°:
    1. 192.168.50.10 (5000 è¿çº¿) - å·²çŸ¥è§†é¢‘ä¼šè®®æœåŠ¡å™¨ âœ“
    2. 192.168.50.11 (2500 è¿çº¿) - å·²çŸ¥è§†é¢‘ä¼šè®®æœåŠ¡å™¨ âœ“
    ...

åˆ¤æ–­ï¼šè¿™ä¸æ˜¯ DDoSï¼Œæ˜¯æ­£å¸¸çš„è§†é¢‘ä¼šè®®æµé‡
```

### æ–¹æ³• 3: æ—¶é—´æ¨¡å¼åˆ†æ

```bash
# çœŸæ­£çš„ DDoS é€šå¸¸ï¼š
- çªç„¶çˆ†å‘
- æŒç»­æ—¶é—´çŸ­ï¼ˆå‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶ï¼‰
- ä¸è§„å¾‹

# æ­£å¸¸é«˜æµé‡é€šå¸¸ï¼š
- å›ºå®šæ—¶é—´æ®µï¼ˆå¦‚å·¥ä½œæ—¶é—´ 9:00-17:00ï¼‰
- å‘¨æœŸæ€§ï¼ˆæ¯å¤©/æ¯å‘¨ï¼‰
- å¯é¢„æµ‹

# æ£€æŸ¥æ—¶é—´æ¨¡å¼
python3 verify_anomaly.py --ip 192.168.1.100 --minutes 1440  # åˆ†æ 24 å°æ—¶

# å¦‚æœçœ‹åˆ°è§„å¾‹çš„æ—¶é—´æ¨¡å¼ â†’ å¾ˆå¯èƒ½ä¸æ˜¯ DDoS
```

### æ–¹æ³• 4: æ£€æŸ¥åˆ†ç±»ç½®ä¿¡åº¦

```python
# åœ¨ realtime_detection.py è¾“å‡ºä¸­æŸ¥çœ‹ç½®ä¿¡åº¦

âš ï¸  å‘ç°å¼‚å¸¸:
1. 192.168.1.100 | DDoS | ç½®ä¿¡åº¦: 65%  â† ç½®ä¿¡åº¦åä½ï¼Œéœ€è¦å®¡æŸ¥
2. 192.168.1.200 | DDoS | ç½®ä¿¡åº¦: 95%  â† ç½®ä¿¡åº¦é«˜ï¼Œå¯èƒ½æ˜¯çœŸå®å¨èƒ

è§„åˆ™ï¼š
- ç½®ä¿¡åº¦ < 70%ï¼šé‡ç‚¹å®¡æŸ¥
- ç½®ä¿¡åº¦ 70-85%ï¼šæŠ½æŸ¥
- ç½®ä¿¡åº¦ > 85%ï¼šå¯èƒ½æ˜¯çœŸå®å¨èƒ
```

---

## å¤„ç†æ–¹æ¡ˆ

### æ–¹æ³• 1: äººå·¥å®¡æŸ¥ + ç™½åå•

**é€‚ç”¨åœºæ™¯**: ç«‹å³å‡å°‘è¯¯æŠ¥
**å®æ–½éš¾åº¦**: â˜…â˜†â˜†â˜†â˜†
**æ•ˆæœ**: ç«‹å³è§æ•ˆ

#### Step 1: è¯†åˆ«è¯¯æŠ¥

```bash
# 1. è¿è¡Œæ£€æµ‹
python3 realtime_detection.py --minutes 60

# 2. æŸ¥çœ‹è¢«åˆ†ç±»ä¸º DDoS çš„å¼‚å¸¸
âš ï¸  å‘ç° 12 ä¸ª DDoS å¼‚å¸¸:
1. 192.168.1.100 | flow_count=7500
2. 192.168.1.200 | flow_count=8200
...
```

#### Step 2: æ·±å…¥åˆ†æ

```bash
# å¯¹æ¯ä¸ªå¯ç–‘ IP è¿›è¡Œåˆ†æ
python3 verify_anomaly.py --ip 192.168.1.100 --minutes 30

# è¾“å‡ºç¤ºä¾‹ï¼š
================================================================================
ğŸ” æ·±å…¥åˆ†æ: 192.168.1.100
================================================================================

ğŸ“Š ä½œä¸ºæº IP: 7,500 ç­†è¨˜éŒ„

ğŸ“Š åŸºæœ¬ç»Ÿè®¡:
  æ€»è¿çº¿æ•°: 7,500
  æ€»æµé‡: 2.63 GB
  å¹³å‡æµé‡: 350 bytes/flow
  æ—¶é—´è·¨åº¦: 30 åˆ†é’Ÿ

ğŸ“Š ç›®çš„åœ°åˆ†æ:
  ä¸åŒç›®çš„åœ°æ•°é‡: 5
  Top ç›®çš„åœ°:
    1. 192.168.50.10 (5000 è¿çº¿) - Video Conference Server
    2. 192.168.50.11 (1500 è¿çº¿) - Video Conference Server
    3. 192.168.50.12 (500 è¿çº¿)  - Video Conference Server
    4. 192.168.50.20 (300 è¿çº¿)  - Video Conference Server
    5. 192.168.50.30 (200 è¿çº¿)  - Video Conference Server

ğŸ“Š ç«¯å£åˆ†æ:
  æºç«¯å£: ä¸»è¦ä½¿ç”¨ 49152-65535 (å®¢æˆ·ç«¯éšæœºç«¯å£)
  ç›®çš„ç«¯å£: ä¸»è¦ä½¿ç”¨ 443 (HTTPS), 3478 (TURN)

ğŸ“Š æ—¶é—´æ¨¡å¼:
  æ—¶é—´æ®µ: 14:00-14:30 (å·¥ä½œæ—¶é—´)
  æ¨¡å¼: æŒç»­ç¨³å®š

ğŸ¯ åˆ¤æ–­:
  âœ“ æ­£å¸¸è§†é¢‘ä¼šè®®æµé‡
  âœ— ä¸æ˜¯ DDoS æ”»å‡»

ç†ç”±:
  - ç›®çš„åœ°æ˜¯å·²çŸ¥çš„è§†é¢‘ä¼šè®®æœåŠ¡å™¨
  - ä½¿ç”¨æ ‡å‡†çš„è§†é¢‘ä¼šè®®ç«¯å£
  - å‘ç”Ÿåœ¨å·¥ä½œæ—¶é—´
  - æµé‡æ¨¡å¼ç¨³å®š
```

#### Step 3: åˆ›å»ºç™½åå•

ç¼–è¾‘é…ç½®æ–‡ä»¶ `nad/config.yaml`ï¼š

```yaml
# ========== ç™½åå•é…ç½® ==========
whitelist:
  # 1. IP ç™½åå•ï¼ˆç®€å•ç›´æ¥ï¼‰
  ips:
    - 192.168.1.100    # è§†é¢‘ä¼šè®®å®¢æˆ·ç«¯
    - 192.168.1.200    # å¤‡ä»½æœåŠ¡å™¨
    - 192.168.1.50     # API ç½‘å…³
    - 192.168.2.0/24   # æ•´ä¸ªæ•°æ®ä¸­å¿ƒç½‘æ®µ

  # 2. æœåŠ¡ç™½åå•ï¼ˆæ›´ç²¾ç»†çš„æ§åˆ¶ï¼‰
  services:
    - name: "Video Conference"
      description: "Zoom/Teams è§†é¢‘ä¼šè®®æµé‡"
      dst_ips:
        - 192.168.50.10
        - 192.168.50.11
        - 192.168.50.12
      dst_ports: [443, 3478, 3479]
      # å¯é€‰ï¼šåªåœ¨ç‰¹å®šæ—¶é—´ç™½åå•
      time_range: "08:00-18:00"
      # å¯é€‰ï¼šåªåœ¨å·¥ä½œæ—¥ç™½åå•
      weekdays: [1, 2, 3, 4, 5]  # å‘¨ä¸€åˆ°å‘¨äº”

    - name: "Backup System"
      description: "å¤œé—´å¤‡ä»½æµé‡"
      dst_ips: ["192.168.100.10"]
      time_range: "01:00-05:00"  # åªåœ¨å‡Œæ™¨ 1-5 ç‚¹ç™½åå•
      min_flow_count: 1000       # æµé‡ç‰¹å¾
      max_flow_count: 100000

    - name: "API Gateway"
      description: "å†…éƒ¨ API æœåŠ¡"
      src_ips: ["192.168.1.50"]
      dst_ips: ["192.168.20.0/24"]
      dst_ports: [8080, 8443]

    - name: "Database Sync"
      description: "æ•°æ®åº“åŒæ­¥"
      src_ips: ["192.168.30.10"]
      dst_ips: ["192.168.30.20"]
      dst_ports: [3306, 5432]
      # å¤§æµé‡ç‰¹å¾
      min_total_bytes: 1e9  # > 1GB
```

#### Step 4: ä¿®æ”¹åˆ†ç±»å™¨ï¼Œæ”¯æŒç™½åå•

ç¼–è¾‘ `nad/ml/anomaly_classifier.py`ï¼š

```python
from datetime import datetime
from typing import Dict, List

class AnomalyClassifier:
    def __init__(self, config=None):
        self.config = config
        self.threat_classes = THREAT_CLASSES

        # ========== åŠ è½½ç™½åå•é…ç½® ==========
        whitelist_config = config.get('whitelist', {}) if config else {}
        self.whitelist_ips = whitelist_config.get('ips', [])
        self.whitelist_services = whitelist_config.get('services', [])

        # å·²çŸ¥çš„å†…éƒ¨ç½‘æ®µ
        self.internal_networks = [
            '192.168.', '10.',
            '172.16.', '172.17.', '172.18.', '172.19.',
            '172.20.', '172.21.', '172.22.', '172.23.',
            '172.24.', '172.25.', '172.26.', '172.27.',
            '172.28.', '172.29.', '172.30.', '172.31.'
        ]

    def classify(self, features: Dict, context: Dict = None) -> Dict:
        """åˆ†ç±»å¼‚å¸¸"""
        if context is None:
            context = {}

        src_ip = context.get('src_ip', '')
        dst_ips = context.get('dst_ips', [])
        timestamp = context.get('timestamp', datetime.now())

        # ========== ä¼˜å…ˆæ£€æŸ¥ç™½åå• ==========
        if self._is_whitelisted(src_ip, dst_ips, features, timestamp):
            return self._create_classification(
                'NORMAL_HIGH_TRAFFIC',
                confidence=0.95,
                features=features,
                context=context
            )

        # ç»§ç»­åŸæœ‰çš„åˆ†ç±»é€»è¾‘...
        if self._is_port_scan(features):
            return self._create_classification('PORT_SCAN', ...)

        if self._is_network_scan(features):
            return self._create_classification('NETWORK_SCAN', ...)

        # ... å…¶ä»–åˆ†ç±»é€»è¾‘

    def _is_whitelisted(self, src_ip: str, dst_ips: List[str],
                       features: Dict, timestamp: datetime) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åœ¨ç™½åå•ä¸­

        Args:
            src_ip: æº IP
            dst_ips: ç›®çš„åœ° IP åˆ—è¡¨
            features: ç‰¹å¾å­—å…¸
            timestamp: æ—¶é—´æˆ³

        Returns:
            True å¦‚æœåœ¨ç™½åå•ä¸­
        """
        # 1. æ£€æŸ¥ç®€å• IP ç™½åå•
        if self._check_ip_whitelist(src_ip):
            return True

        # 2. æ£€æŸ¥æœåŠ¡ç™½åå•ï¼ˆæ›´å¤æ‚çš„è§„åˆ™ï¼‰
        if self._check_service_whitelist(src_ip, dst_ips, features, timestamp):
            return True

        return False

    def _check_ip_whitelist(self, src_ip: str) -> bool:
        """æ£€æŸ¥ç®€å• IP ç™½åå•"""
        for whitelist_entry in self.whitelist_ips:
            if '/' in whitelist_entry:
                # CIDR ç½‘æ®µåŒ¹é…
                if self._ip_in_network(src_ip, whitelist_entry):
                    return True
            else:
                # ç²¾ç¡®åŒ¹é…
                if src_ip == whitelist_entry:
                    return True

        return False

    def _check_service_whitelist(self, src_ip: str, dst_ips: List[str],
                                 features: Dict, timestamp: datetime) -> bool:
        """æ£€æŸ¥æœåŠ¡ç™½åå•"""
        for service in self.whitelist_services:
            # æ£€æŸ¥æº IPï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            if 'src_ips' in service:
                if not any(self._ip_match(src_ip, allowed)
                          for allowed in service['src_ips']):
                    continue

            # æ£€æŸ¥ç›®çš„åœ° IPï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            if 'dst_ips' in service:
                if not any(
                    any(self._ip_match(dst, allowed) for allowed in service['dst_ips'])
                    for dst in dst_ips
                ):
                    continue

            # æ£€æŸ¥ç›®çš„ç«¯å£ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            if 'dst_ports' in service:
                # è¿™éœ€è¦ä»åŸå§‹æ•°æ®è·å–ç«¯å£ä¿¡æ¯
                # ç®€åŒ–å¤„ç†ï¼šå‡è®¾ç‰¹å¾ä¸­æœ‰ç«¯å£ä¿¡æ¯
                pass

            # æ£€æŸ¥æ—¶é—´èŒƒå›´ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            if 'time_range' in service:
                if not self._in_time_range(timestamp, service['time_range']):
                    continue

            # æ£€æŸ¥å·¥ä½œæ—¥ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            if 'weekdays' in service:
                if timestamp.weekday() + 1 not in service['weekdays']:
                    continue

            # æ£€æŸ¥æµé‡ç‰¹å¾ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            if 'min_flow_count' in service:
                if features.get('flow_count', 0) < service['min_flow_count']:
                    continue

            if 'max_flow_count' in service:
                if features.get('flow_count', 0) > service['max_flow_count']:
                    continue

            if 'min_total_bytes' in service:
                if features.get('total_bytes', 0) < service['min_total_bytes']:
                    continue

            # æ‰€æœ‰æ¡ä»¶éƒ½æ»¡è¶³ï¼ŒåŒ¹é…æˆåŠŸ
            return True

        return False

    def _ip_match(self, ip: str, pattern: str) -> bool:
        """IP åŒ¹é…ï¼ˆæ”¯æŒç²¾ç¡®åŒ¹é…å’Œ CIDRï¼‰"""
        if '/' in pattern:
            return self._ip_in_network(ip, pattern)
        else:
            return ip == pattern

    def _ip_in_network(self, ip: str, network: str) -> bool:
        """æ£€æŸ¥ IP æ˜¯å¦åœ¨ CIDR ç½‘æ®µä¸­"""
        try:
            from ipaddress import ip_address, ip_network
            return ip_address(ip) in ip_network(network, strict=False)
        except:
            return False

    def _in_time_range(self, timestamp: datetime, time_range: str) -> bool:
        """
        æ£€æŸ¥æ—¶é—´æ˜¯å¦åœ¨æŒ‡å®šèŒƒå›´å†…

        Args:
            timestamp: æ—¶é—´æˆ³
            time_range: æ—¶é—´èŒƒå›´ï¼Œæ ¼å¼ "HH:MM-HH:MM"ï¼Œå¦‚ "08:00-18:00"

        Returns:
            True å¦‚æœåœ¨æ—¶é—´èŒƒå›´å†…
        """
        try:
            start_str, end_str = time_range.split('-')
            start_hour, start_min = map(int, start_str.split(':'))
            end_hour, end_min = map(int, end_str.split(':'))

            current_time = timestamp.hour * 60 + timestamp.minute
            start_time = start_hour * 60 + start_min
            end_time = end_hour * 60 + end_min

            if start_time <= end_time:
                # æ­£å¸¸èŒƒå›´ï¼Œå¦‚ 08:00-18:00
                return start_time <= current_time <= end_time
            else:
                # è·¨åˆå¤œèŒƒå›´ï¼Œå¦‚ 22:00-02:00
                return current_time >= start_time or current_time <= end_time
        except:
            return False
```

#### Step 5: æµ‹è¯•ç™½åå•

```bash
# 1. é‡å¯æ£€æµ‹æœåŠ¡
python3 realtime_detection.py --continuous --interval 5

# 2. è§‚å¯Ÿè¾“å‡ºï¼Œç¡®è®¤ç™½åå•ç”Ÿæ•ˆ
âœ… æœªç™¼ç¾ç•°å¸¸

æˆ–è€…ï¼š

âš ï¸  ç™¼ç¾ 2 å€‹ç•°å¸¸:
1. 192.168.10.50 | Port Scan | ...
2. 192.168.20.80 | Network Scan | ...

# æ³¨æ„ï¼š192.168.1.100 åº”è¯¥ä¸å†å‡ºç°ï¼ˆå·²åŠ å…¥ç™½åå•ï¼‰

# 3. éªŒè¯ç‰¹å®š IP æ˜¯å¦è¢«ç™½åå•è¿‡æ»¤
# æŸ¥çœ‹æ—¥å¿—æˆ–æ·»åŠ è°ƒè¯•è¾“å‡º
```

---

### æ–¹æ³• 2: è°ƒæ•´åˆ†ç±»å™¨é˜ˆå€¼

**é€‚ç”¨åœºæ™¯**: åˆ†ç±»å™¨è¿‡äºæ•æ„Ÿï¼Œäº§ç”Ÿå¤§é‡è¯¯æŠ¥
**å®æ–½éš¾åº¦**: â˜…â˜…â˜†â˜†â˜†
**æ•ˆæœ**: ä¸­æœŸè§æ•ˆ

#### å½“å‰é˜ˆå€¼åˆ†æ

æŸ¥çœ‹ `nad/ml/anomaly_classifier.py`ï¼Œæ‰¾åˆ° DDoS åˆ†ç±»å‡½æ•°ï¼š

```python
def _is_ddos(self, features: Dict) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸º DDoS æ”»å‡»"""
    flow_count = features.get('flow_count', 0)
    avg_bytes = features.get('avg_bytes', 0)
    unique_dsts = features.get('unique_dsts', 0)

    # å½“å‰é˜ˆå€¼ï¼ˆå¯èƒ½å¤ªå®½æ¾ï¼‰
    return (
        flow_count > 10000 and      # 10K è¿çº¿
        avg_bytes < 500 and         # 500 bytes
        unique_dsts < 20            # 20 ä¸ªç›®çš„åœ°
    )
```

**é—®é¢˜åˆ†æ**ï¼š
```
flow_count > 10000
â†’ å¾ˆå¤šæ­£å¸¸æœåŠ¡å™¨ä¹Ÿæœ‰ 10K+ è¿çº¿ï¼ˆè§†é¢‘ä¼šè®®ã€APIã€å¤‡ä»½ï¼‰
â†’ å¤ªå®½æ¾ï¼Œå¯¼è‡´è¯¯æŠ¥

avg_bytes < 500
â†’ åªæœ‰æå°åŒ…æ‰ç¬¦åˆ
â†’ è¿™ä¸ªæ¡ä»¶è¿˜ç®—åˆç†

unique_dsts < 20
â†’ æœ‰äº›æ­£å¸¸æœåŠ¡ä¹Ÿåªè¿æ¥å°‘æ•°æœåŠ¡å™¨
â†’ å¯èƒ½å¯¼è‡´è¯¯æŠ¥
```

#### è°ƒæ•´ç­–ç•¥

```python
def _is_ddos(self, features: Dict) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸º DDoS æ”»å‡»ï¼ˆè°ƒæ•´å - æ›´ä¸¥æ ¼ï¼‰"""
    flow_count = features.get('flow_count', 0)
    avg_bytes = features.get('avg_bytes', 0)
    unique_dsts = features.get('unique_dsts', 0)

    # ========== è°ƒæ•´ 1: æé«˜è¿çº¿æ•°é˜ˆå€¼ ==========
    # ä» 10000 æé«˜åˆ° 50000
    # ç†ç”±ï¼šåªæœ‰çœŸæ­£çš„å¤§è§„æ¨¡æ”»å‡»æ‰ä¼šè§¦å‘
    if flow_count <= 50000:
        return False

    # ========== è°ƒæ•´ 2: é™ä½å°åŒ…å¤§å°é˜ˆå€¼ ==========
    # ä» 500 é™ä½åˆ° 300
    # ç†ç”±ï¼šçœŸæ­£çš„ SYN Flood å°åŒ…æå°ï¼ˆ64-100 bytesï¼‰
    if avg_bytes >= 300:
        return False

    # ========== è°ƒæ•´ 3: é™ä½ç›®çš„åœ°æ•°é‡é˜ˆå€¼ ==========
    # ä» 20 é™ä½åˆ° 10
    # ç†ç”±ï¼šçœŸæ­£çš„ DDoS ç›®æ ‡éå¸¸é›†ä¸­
    if unique_dsts >= 10:
        return False

    # ========== æ–°å¢ 4: æ’é™¤æœåŠ¡å™¨å›åº”æµé‡ ==========
    is_likely_server = features.get('is_likely_server_response', 0)
    if is_likely_server == 1:
        return False

    # ========== æ–°å¢ 5: æ£€æŸ¥æµé‡é›†ä¸­åº¦ ==========
    # DDoS é€šå¸¸æµé‡éå¸¸é›†ä¸­ï¼ˆæ”»å‡»åŒä¸€ä¸ªç›®æ ‡ï¼‰
    traffic_concentration = features.get('traffic_concentration', 0)
    if traffic_concentration < 0.5:  # æµé‡ä¸å¤Ÿé›†ä¸­
        return False

    # æ‰€æœ‰æ¡ä»¶éƒ½æ»¡è¶³ï¼Œæ‰åˆ¤æ–­ä¸º DDoS
    return True
```

#### é˜ˆå€¼è°ƒæ•´å¯¹æ¯”

| æ¡ä»¶ | åŸé˜ˆå€¼ | æ–°é˜ˆå€¼ | å½±å“ |
|------|-------|-------|------|
| flow_count | > 10,000 | > 50,000 | å‡å°‘è¯¯æŠ¥ï¼Œåªæ•è·å¤§è§„æ¨¡æ”»å‡» |
| avg_bytes | < 500 | < 300 | æ›´ä¸¥æ ¼ï¼Œåªæ•è·çœŸæ­£çš„å°åŒ…æ”»å‡» |
| unique_dsts | < 20 | < 10 | ç›®æ ‡å¿…é¡»éå¸¸é›†ä¸­ |
| is_likely_server_response | - | == 0 | æ’é™¤æœåŠ¡å™¨æµé‡ |
| traffic_concentration | - | > 0.5 | ç¡®ä¿æµé‡é›†ä¸­ |

#### é¢„æœŸæ•ˆæœ

```
è°ƒæ•´å‰ï¼š
  æ£€æµ‹åˆ° 12 ä¸ª DDoS
  å…¶ä¸­ 9 ä¸ªè¯¯æŠ¥ (75% è¯¯æŠ¥ç‡)

è°ƒæ•´åï¼š
  æ£€æµ‹åˆ° 3 ä¸ª DDoS
  å…¶ä¸­ 0 ä¸ªè¯¯æŠ¥ (0% è¯¯æŠ¥ç‡)

ä»£ä»·ï¼š
  å¯èƒ½æ¼æ‰ä¸€äº›å°è§„æ¨¡çš„ DDoS æ”»å‡»
  ä½†å¤§å¹…é™ä½è¯¯æŠ¥ï¼Œæé«˜ç³»ç»Ÿå¯ä¿¡åº¦
```

#### å®æ–½æ­¥éª¤

```bash
# 1. å¤‡ä»½åŸå§‹æ–‡ä»¶
cp nad/ml/anomaly_classifier.py nad/ml/anomaly_classifier.py.backup

# 2. ç¼–è¾‘åˆ†ç±»å™¨
vim nad/ml/anomaly_classifier.py

# 3. æ‰¾åˆ° _is_ddos å‡½æ•°ï¼ˆçº¦ 387 è¡Œï¼‰
# 4. åº”ç”¨ä¸Šè¿°è°ƒæ•´

# 5. æµ‹è¯•æ–°é˜ˆå€¼
python3 realtime_detection.py --minutes 60

# 6. è§‚å¯Ÿç»“æœï¼Œæ¯”è¾ƒè°ƒæ•´å‰åçš„å·®å¼‚

# 7. å¦‚æœæ•ˆæœä¸å¥½ï¼Œå¯ä»¥å›æ»š
cp nad/ml/anomaly_classifier.py.backup nad/ml/anomaly_classifier.py
```

---

### æ–¹æ³• 3: æ”¹è¿›ä¼˜åŒ–å·¥å…·

**é€‚ç”¨åœºæ™¯**: éœ€è¦åŸºäºçœŸå®æ•°æ®ä¼˜åŒ–ï¼Œä½†å½“å‰æ•°æ®è´¨é‡ä¸ä½³
**å®æ–½éš¾åº¦**: â˜…â˜…â˜…â˜…â˜†
**æ•ˆæœ**: é•¿æœŸæœ€ä½³

#### é—®é¢˜åˆ†æ

å½“å‰ä¼˜åŒ–å·¥å…· `optimize_classifier_thresholds.py` çš„é—®é¢˜ï¼š

```python
# å½“å‰é€»è¾‘ï¼š
1. æ”¶é›†è¢«åˆ†ç±»ä¸º DDoS çš„å¼‚å¸¸
2. ç»Ÿè®¡ç‰¹å¾åˆ†å¸ƒ
3. åŸºäºç™¾åˆ†ä½æ•°æ¨èé˜ˆå€¼

å‡è®¾ï¼š"è¿™äº›å¼‚å¸¸éƒ½æ˜¯çœŸæ­£çš„ DDoS"
      â†“
   å¦‚æœå‡è®¾é”™è¯¯ï¼ˆå¤§é‡è¯¯æŠ¥ï¼‰
      â†“
   æ¨èçš„é˜ˆå€¼ä¼šæ”¾å¤§é”™è¯¯
```

#### æ”¹è¿›æ–¹æ¡ˆï¼šåŠ å…¥äººå·¥æ ‡æ³¨

åˆ›å»ºæ”¹è¿›ç‰ˆä¼˜åŒ–å·¥å…· `optimize_classifier_thresholds_v2.py`ï¼š

```python
#!/usr/bin/env python3
"""
åˆ†ç±»å™¨é˜ˆå€¼ä¼˜åŒ–å·¥å…· v2.0

æ”¹è¿›ï¼š
1. æ”¯æŒäººå·¥æ ‡æ³¨
2. åªåŸºäºçœŸå®å¨èƒæ•°æ®ä¼˜åŒ–
3. åˆ†æè¯¯æŠ¥ç‰¹å¾ï¼Œæä¾›æ’é™¤è§„åˆ™å»ºè®®
4. æ”¯æŒæ ‡æ³¨æ•°æ®æŒä¹…åŒ–
"""

import sys
import json
import argparse
import numpy as np
from datetime import datetime, timedelta
from collections import defaultdict
from typing import Dict, List, Tuple

from nad.utils import load_config
from nad.ml import OptimizedIsolationForest
from nad.ml.anomaly_classifier import AnomalyClassifier


class ImprovedClassifierThresholdOptimizer:
    """
    æ”¹è¿›ç‰ˆåˆ†ç±»å™¨é˜ˆå€¼ä¼˜åŒ–å™¨

    æ”¯æŒäººå·¥æ ‡æ³¨ï¼ŒåªåŸºäºçœŸå®çš„å¨èƒæ•°æ®ä¼˜åŒ–
    """

    def __init__(self, config):
        self.config = config
        self.detector = OptimizedIsolationForest(config)
        self.classifier = AnomalyClassifier(config)

        # å­˜å‚¨äººå·¥æ ‡æ³¨çš„æ•°æ®
        self.labeled_data = {
            'PORT_SCAN': {'true': [], 'false': []},
            'NETWORK_SCAN': {'true': [], 'false': []},
            'DNS_TUNNELING': {'true': [], 'false': []},
            'DDOS': {'true': [], 'false': []},
            'DATA_EXFILTRATION': {'true': [], 'false': []},
            'C2_COMMUNICATION': {'true': [], 'false': []},
            'NORMAL_HIGH_TRAFFIC': {'true': [], 'false': []},
            'UNKNOWN': {'true': [], 'false': []}
        }

        # æ ‡æ³¨æ•°æ®æ–‡ä»¶
        self.label_file = 'nad/models/labeled_anomalies.json'

    def collect_and_label_anomalies(self, days: int = 7, auto_save: bool = True):
        """
        æ”¶é›†å¼‚å¸¸å¹¶è¿›è¡Œäººå·¥æ ‡æ³¨

        Args:
            days: åˆ†æè¿‡å» N å¤©
            auto_save: æ˜¯å¦è‡ªåŠ¨ä¿å­˜æ ‡æ³¨ç»“æœ
        """
        print(f"\n{'='*80}")
        print(f"æ”¶é›†è¿‡å» {days} å¤©çš„å¼‚å¸¸æ•°æ®ï¼ˆéœ€è¦äººå·¥æ ‡æ³¨ï¼‰")
        print(f"{'='*80}\n")

        # åŠ è½½æ¨¡å‹
        try:
            self.detector._load_model()
        except Exception as e:
            print(f"âŒ æ— æ³•è½½å…¥æ¨¡å‹: {e}")
            return 0

        # åŠ è½½å·²æœ‰çš„æ ‡æ³¨æ•°æ®
        self._load_labeled_data()

        # æ”¶é›†å¼‚å¸¸
        anomalies = []
        print(f"ğŸ“š æ”¶é›†å¼‚å¸¸æ•°æ®...")

        for day_offset in range(days):
            print(f"  Day {day_offset + 1}/{days}...", end=' ')

            try:
                day_anomalies = self.detector.predict_realtime(
                    recent_minutes=(day_offset * 1440 + 720)
                )

                if day_anomalies:
                    for anomaly in day_anomalies:
                        # æ·»åŠ ä¸Šä¸‹æ–‡
                        anomaly['context'] = {
                            'timestamp': datetime.fromisoformat(
                                anomaly['time_bucket'].replace('Z', '+00:00')
                            ),
                            'src_ip': anomaly['src_ip'],
                            'anomaly_score': anomaly['anomaly_score']
                        }
                        anomalies.append(anomaly)

                    print(f"æ‰¾åˆ° {len(day_anomalies)} ä¸ªå¼‚å¸¸")
                else:
                    print("æœªå‘ç°å¼‚å¸¸")

            except Exception as e:
                print(f"å¤±è´¥: {e}")

        total = len(anomalies)
        print(f"\nâœ“ æ”¶é›†åˆ° {total} ä¸ªå¼‚å¸¸\n")

        if total == 0:
            print("æ²¡æœ‰å¼‚å¸¸éœ€è¦æ ‡æ³¨")
            return 0

        # å¼€å§‹äººå·¥æ ‡æ³¨
        print(f"{'='*80}")
        print(f"å¼€å§‹äººå·¥æ ‡æ³¨ ({total} ä¸ªå¼‚å¸¸)")
        print(f"{'='*80}\n")
        print("æç¤º:")
        print("  y = åˆ†ç±»æ­£ç¡®ï¼ˆçœŸå®å¨èƒï¼‰")
        print("  n = åˆ†ç±»é”™è¯¯ï¼ˆè¯¯æŠ¥ï¼‰")
        print("  s = è·³è¿‡")
        print("  q = é€€å‡ºæ ‡æ³¨\n")

        labeled_count = 0

        for i, anomaly in enumerate(anomalies, 1):
            # æ˜¾ç¤ºè¿›åº¦
            print(f"\n{'='*80}")
            print(f"å¼‚å¸¸ #{i}/{total} (å·²æ ‡æ³¨: {labeled_count})")
            print(f"{'='*80}")

            # æ˜¾ç¤ºå¼‚å¸¸ä¿¡æ¯
            self._display_anomaly_for_labeling(anomaly)

            # è·å–åˆ†ç±»å™¨çš„åˆ¤æ–­
            classification = self.classifier.classify(
                anomaly['features'],
                anomaly['context']
            )
            predicted_class = classification['class']

            # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
            print(f"\nğŸ¤– åˆ†ç±»å™¨åˆ¤æ–­:")
            print(f"   ç±»åˆ«: {classification['class_name']} ({predicted_class})")
            print(f"   ç½®ä¿¡åº¦: {classification['confidence']:.0%}")
            print(f"   ä¸¥é‡æ€§: {classification['severity']}")

            if classification['indicators']:
                print(f"   å…³é”®æŒ‡æ ‡:")
                for indicator in classification['indicators'][:3]:
                    print(f"      â€¢ {indicator}")

            # è¯¢é—®äººå·¥åˆ¤æ–­
            while True:
                label = input("\nğŸ‘¤ è¿™ä¸ªåˆ¤æ–­æ­£ç¡®å—ï¼Ÿ(y/n/s/q): ").strip().lower()

                if label == 'y':
                    # æ ‡æ³¨ä¸ºæ­£ç¡®
                    self.labeled_data[predicted_class]['true'].append({
                        'features': anomaly['features'],
                        'context': anomaly['context'],
                        'classification': classification
                    })
                    print("   âœ“ æ ‡æ³¨ä¸ºï¼šçœŸå®å¨èƒ")
                    labeled_count += 1
                    break

                elif label == 'n':
                    # æ ‡æ³¨ä¸ºé”™è¯¯
                    self.labeled_data[predicted_class]['false'].append({
                        'features': anomaly['features'],
                        'context': anomaly['context'],
                        'classification': classification
                    })
                    print("   âœ— æ ‡æ³¨ä¸ºï¼šè¯¯æŠ¥")

                    # è¯¢é—®çœŸå®ç±»å‹
                    real_class = self._ask_real_class()
                    if real_class and real_class != predicted_class:
                        self.labeled_data[real_class]['true'].append({
                            'features': anomaly['features'],
                            'context': anomaly['context'],
                            'classification': classification
                        })
                        print(f"   â†’ çœŸå®ç±»å‹ï¼š{real_class}")

                    labeled_count += 1
                    break

                elif label == 's':
                    print("   âŠ™ è·³è¿‡")
                    break

                elif label == 'q':
                    print("\né€€å‡ºæ ‡æ³¨")
                    if auto_save and labeled_count > 0:
                        self._save_labeled_data()
                    return labeled_count

                else:
                    print("   âš ï¸  è¯·è¾“å…¥ y, n, s æˆ– q")

        # ä¿å­˜æ ‡æ³¨ç»“æœ
        if auto_save and labeled_count > 0:
            self._save_labeled_data()

        # æ˜¾ç¤ºæ ‡æ³¨ç»Ÿè®¡
        self._show_labeling_statistics()

        return labeled_count

    def _display_anomaly_for_labeling(self, anomaly):
        """æ˜¾ç¤ºå¼‚å¸¸ä¿¡æ¯ä¾›äººå·¥åˆ¤æ–­"""
        features = anomaly['features']
        context = anomaly['context']

        print(f"\nğŸ“ åŸºæœ¬ä¿¡æ¯:")
        print(f"   IP: {context['src_ip']}")
        print(f"   æ—¶é—´: {context['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   å¼‚å¸¸åˆ†æ•°: {context['anomaly_score']:.4f}")

        print(f"\nğŸ“Š æµé‡ç‰¹å¾:")
        print(f"   è¿çº¿æ•°: {features['flow_count']:,}")
        print(f"   æ€»æµé‡: {features['total_bytes'] / 1e9:.2f} GB")
        print(f"   å¹³å‡æµé‡: {features['avg_bytes']:,.0f} bytes")
        print(f"   æœ€å¤§æµé‡: {features['max_bytes'] / 1e6:.2f} MB")

        print(f"\nğŸ¯ ç›®æ ‡åˆ†æ:")
        print(f"   ä¸åŒç›®çš„åœ°: {features['unique_dsts']}")
        print(f"   ä¸åŒæºç«¯å£: {features['unique_src_ports']}")
        print(f"   ä¸åŒç›®çš„ç«¯å£: {features['unique_dst_ports']}")
        print(f"   ç›®çš„åœ°åˆ†æ•£åº¦: {features['dst_diversity']:.3f}")

        print(f"\nğŸ·ï¸  è¡Œä¸ºæ ‡è®°:")
        behaviors = []
        if features.get('is_high_connection'):
            behaviors.append("é«˜è¿çº¿æ•°")
        if features.get('is_scanning_pattern'):
            behaviors.append("æ‰«ææ¨¡å¼")
        if features.get('is_small_packet'):
            behaviors.append("å°å°åŒ…")
        if features.get('is_large_flow'):
            behaviors.append("å¤§æµé‡")
        if features.get('is_likely_server_response'):
            behaviors.append("å¯èƒ½æ˜¯æœåŠ¡å™¨å›åº”")

        if behaviors:
            print(f"   {', '.join(behaviors)}")
        else:
            print(f"   æ— ç‰¹æ®Šæ ‡è®°")

    def _ask_real_class(self) -> str:
        """è¯¢é—®çœŸå®çš„å¨èƒç±»å‹"""
        print("\n   çœŸå®ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ")
        print("   1. PORT_SCAN (ç«¯å£æ‰«æ)")
        print("   2. NETWORK_SCAN (ç½‘ç»œæ‰«æ)")
        print("   3. DNS_TUNNELING (DNS éš§é“)")
        print("   4. DDOS (DDoS æ”»å‡»)")
        print("   5. DATA_EXFILTRATION (æ•°æ®å¤–æ³„)")
        print("   6. C2_COMMUNICATION (C&C é€šä¿¡)")
        print("   7. NORMAL_HIGH_TRAFFIC (æ­£å¸¸é«˜æµé‡)")
        print("   8. UNKNOWN (æœªçŸ¥)")
        print("   9. è·³è¿‡")

        class_map = {
            '1': 'PORT_SCAN',
            '2': 'NETWORK_SCAN',
            '3': 'DNS_TUNNELING',
            '4': 'DDOS',
            '5': 'DATA_EXFILTRATION',
            '6': 'C2_COMMUNICATION',
            '7': 'NORMAL_HIGH_TRAFFIC',
            '8': 'UNKNOWN'
        }

        while True:
            choice = input("   è¯·é€‰æ‹© (1-9): ").strip()
            if choice == '9':
                return None
            if choice in class_map:
                return class_map[choice]
            print("   âš ï¸  è¯·è¾“å…¥ 1-9")

    def _save_labeled_data(self):
        """ä¿å­˜æ ‡æ³¨æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            # è½¬æ¢ datetime ä¸ºå­—ç¬¦ä¸²
            data_to_save = {}
            for threat_class, labels in self.labeled_data.items():
                data_to_save[threat_class] = {
                    'true': [],
                    'false': []
                }

                for label_type in ['true', 'false']:
                    for item in labels[label_type]:
                        item_copy = {
                            'features': item['features'],
                            'context': {
                                'src_ip': item['context']['src_ip'],
                                'timestamp': item['context']['timestamp'].isoformat(),
                                'anomaly_score': item['context']['anomaly_score']
                            },
                            'classification': item['classification']
                        }
                        data_to_save[threat_class][label_type].append(item_copy)

            with open(self.label_file, 'w') as f:
                json.dump(data_to_save, f, indent=2, ensure_ascii=False)

            print(f"\nğŸ’¾ æ ‡æ³¨æ•°æ®å·²ä¿å­˜åˆ°: {self.label_file}")

        except Exception as e:
            print(f"\nâš ï¸  ä¿å­˜å¤±è´¥: {e}")

    def _load_labeled_data(self):
        """ä»æ–‡ä»¶åŠ è½½æ ‡æ³¨æ•°æ®"""
        try:
            with open(self.label_file, 'r') as f:
                data = json.load(f)

            # è½¬æ¢å­—ç¬¦ä¸²ä¸º datetime
            for threat_class, labels in data.items():
                if threat_class not in self.labeled_data:
                    continue

                for label_type in ['true', 'false']:
                    for item in labels.get(label_type, []):
                        item['context']['timestamp'] = datetime.fromisoformat(
                            item['context']['timestamp']
                        )
                        self.labeled_data[threat_class][label_type].append(item)

            total = sum(
                len(labels['true']) + len(labels['false'])
                for labels in self.labeled_data.values()
            )

            if total > 0:
                print(f"ğŸ“‚ åŠ è½½äº† {total} ä¸ªå·²æ ‡æ³¨çš„å¼‚å¸¸")

        except FileNotFoundError:
            print(f"ğŸ“‚ æœªæ‰¾åˆ°æ ‡æ³¨æ•°æ®æ–‡ä»¶ï¼ˆå°†åˆ›å»ºæ–°æ–‡ä»¶ï¼‰")
        except Exception as e:
            print(f"âš ï¸  åŠ è½½æ ‡æ³¨æ•°æ®å¤±è´¥: {e}")

    def _show_labeling_statistics(self):
        """æ˜¾ç¤ºæ ‡æ³¨ç»Ÿè®¡"""
        print(f"\n{'='*80}")
        print(f"æ ‡æ³¨ç»Ÿè®¡")
        print(f"{'='*80}\n")

        total_true = 0
        total_false = 0

        for threat_class, labels in self.labeled_data.items():
            true_count = len(labels['true'])
            false_count = len(labels['false'])

            if true_count > 0 or false_count > 0:
                accuracy = true_count / (true_count + false_count) * 100 if (true_count + false_count) > 0 else 0
                print(f"{threat_class:25} True: {true_count:3}  False: {false_count:3}  å‡†ç¡®ç‡: {accuracy:5.1f}%")

                total_true += true_count
                total_false += false_count

        print(f"\n{'æ€»è®¡':25} True: {total_true:3}  False: {total_false:3}")

        if total_true + total_false > 0:
            overall_accuracy = total_true / (total_true + total_false) * 100
            print(f"\næ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.1f}%")

    def recommend_thresholds_from_labeled_data(self) -> Dict:
        """
        åŸºäºäººå·¥æ ‡æ³¨çš„çœŸå®æ•°æ®æ¨èé˜ˆå€¼

        åªä½¿ç”¨æ ‡æ³¨ä¸º 'true' çš„æ•°æ®
        """
        print(f"\n{'='*80}")
        print(f"åŸºäºæ ‡æ³¨æ•°æ®æ¨èé˜ˆå€¼")
        print(f"{'='*80}\n")

        recommendations = {}

        # ========== DDoS ä¼˜åŒ– ==========
        true_ddos = self.labeled_data['DDOS']['true']
        false_ddos = self.labeled_data['DDOS']['false']

        if len(true_ddos) < 5:
            print(f"âš ï¸  çœŸå® DDoS æ ·æœ¬å¤ªå°‘ ({len(true_ddos)} ä¸ª)ï¼Œè‡³å°‘éœ€è¦ 5 ä¸ª")
            print(f"   è¯·ç»§ç»­æ ‡æ³¨æ•°æ®\n")
        else:
            print(f"âœ“ DDoS: {len(true_ddos)} ä¸ªçœŸå®æ ·æœ¬ï¼Œ{len(false_ddos)} ä¸ªè¯¯æŠ¥")

            # æå–çœŸå® DDoS çš„ç‰¹å¾
            features = self._extract_features_from_labeled(true_ddos)

            # æ¨èé˜ˆå€¼ï¼ˆä½¿ç”¨æ›´ä¿å®ˆçš„ç™¾åˆ†ä½æ•°ï¼‰
            recommendations['DDOS'] = {
                'flow_count': {
                    'current': 10000,
                    'recommended': max(10000, int(features['flow_count']['p5'])),
                    'rationale': 'P5 å€¼ï¼ŒåŸºäºçœŸå® DDoS æ•°æ®ï¼ˆäººå·¥éªŒè¯ï¼‰ï¼Œ95% çœŸå®æ”»å‡»ä¼šè¢«æ•è·',
                    'samples': len(true_ddos),
                    'distribution': {
                        'min': int(features['flow_count']['min']),
                        'p25': int(features['flow_count']['p25']),
                        'median': int(features['flow_count']['p50']),
                        'p75': int(features['flow_count']['p75']),
                        'max': int(features['flow_count']['max'])
                    }
                },
                'avg_bytes': {
                    'current': 500,
                    'recommended': min(500, int(features['avg_bytes']['p90'])),
                    'rationale': 'P90 å€¼ï¼Œè¦†ç›– 90% çš„çœŸå® DDoS',
                    'samples': len(true_ddos),
                    'distribution': {
                        'min': int(features['avg_bytes']['min']),
                        'p25': int(features['avg_bytes']['p25']),
                        'median': int(features['avg_bytes']['p50']),
                        'p75': int(features['avg_bytes']['p75']),
                        'max': int(features['avg_bytes']['max'])
                    }
                },
                'unique_dsts': {
                    'current': 20,
                    'recommended': max(5, int(features['unique_dsts']['p90'])),
                    'rationale': 'P90 å€¼ï¼Œæ”»å‡»ç›®æ ‡é›†ä¸­',
                    'samples': len(true_ddos),
                    'distribution': {
                        'min': int(features['unique_dsts']['min']),
                        'p25': int(features['unique_dsts']['p25']),
                        'median': int(features['unique_dsts']['p50']),
                        'p75': int(features['unique_dsts']['p75']),
                        'max': int(features['unique_dsts']['max'])
                    }
                }
            }

            # åˆ†æè¯¯æŠ¥çš„ç‰¹å¾
            if len(false_ddos) > 0:
                false_features = self._extract_features_from_labeled(false_ddos)
                patterns = self._analyze_false_positives(false_features, true_ddos)

                recommendations['DDOS']['false_positive_analysis'] = {
                    'count': len(false_ddos),
                    'common_patterns': patterns,
                    'suggestion': 'è€ƒè™‘æ·»åŠ è¿™äº›ç‰¹å¾çš„æ’é™¤è§„åˆ™åˆ°åˆ†ç±»å™¨'
                }

        # ========== å…¶ä»–å¨èƒç±»å‹ ==========
        # TODO: å®ç°å…¶ä»–å¨èƒç±»å‹çš„ä¼˜åŒ–

        return recommendations

    def _extract_features_from_labeled(self, labeled_items: List[Dict]) -> Dict:
        """ä»æ ‡æ³¨æ•°æ®ä¸­æå–ç‰¹å¾ç»Ÿè®¡"""
        if not labeled_items:
            return {}

        # æå–æ‰€æœ‰ç‰¹å¾
        features_data = defaultdict(list)

        for item in labeled_items:
            for feature_name, value in item['features'].items():
                if isinstance(value, (int, float)):
                    features_data[feature_name].append(value)

        # è®¡ç®—ç»Ÿè®¡é‡
        statistics = {}

        for feature_name, values in features_data.items():
            if values:
                statistics[feature_name] = {
                    'min': float(np.min(values)),
                    'max': float(np.max(values)),
                    'mean': float(np.mean(values)),
                    'median': float(np.median(values)),
                    'std': float(np.std(values)),
                    'p5': float(np.percentile(values, 5)),
                    'p10': float(np.percentile(values, 10)),
                    'p25': float(np.percentile(values, 25)),
                    'p50': float(np.percentile(values, 50)),
                    'p75': float(np.percentile(values, 75)),
                    'p90': float(np.percentile(values, 90)),
                    'p95': float(np.percentile(values, 95))
                }

        return statistics

    def _analyze_false_positives(self, false_features: Dict, true_samples: List[Dict]) -> List[str]:
        """åˆ†æè¯¯æŠ¥çš„å…±åŒç‰¹å¾"""
        patterns = []

        # 1. æ£€æŸ¥æ˜¯å¦éƒ½æ˜¯æœåŠ¡å™¨å›åº”
        if 'is_likely_server_response' in false_features:
            mean_server = false_features['is_likely_server_response']['mean']
            if mean_server > 0.5:
                patterns.append(
                    f"â€¢ {mean_server*100:.0f}% çš„è¯¯æŠ¥æ˜¯æœåŠ¡å™¨å›åº”æµé‡"
                )
                patterns.append(
                    "  å»ºè®®ï¼šæ·»åŠ  'is_likely_server_response == 0' æ¡ä»¶"
                )

        # 2. æ£€æŸ¥æµé‡é›†ä¸­åº¦å·®å¼‚
        if 'traffic_concentration' in false_features:
            false_conc = false_features['traffic_concentration']['median']

            # è®¡ç®—çœŸå®æ ·æœ¬çš„ä¸­ä½æ•°
            true_conc_values = [
                item['features'].get('traffic_concentration', 0)
                for item in true_samples
            ]
            true_conc = np.median(true_conc_values) if true_conc_values else 0

            if false_conc < true_conc * 0.5:
                patterns.append(
                    f"â€¢ è¯¯æŠ¥çš„æµé‡é›†ä¸­åº¦è¾ƒä½ï¼ˆä¸­ä½æ•°: {false_conc:.2f} vs çœŸå®: {true_conc:.2f}ï¼‰"
                )
                patterns.append(
                    f"  å»ºè®®ï¼šæ·»åŠ  'traffic_concentration > {true_conc*0.5:.2f}' æ¡ä»¶"
                )

        # 3. æ£€æŸ¥è¿çº¿æ•°å·®å¼‚
        if 'flow_count' in false_features:
            false_flow = false_features['flow_count']['median']
            true_flow_values = [
                item['features'].get('flow_count', 0)
                for item in true_samples
            ]
            true_flow = np.median(true_flow_values) if true_flow_values else 0

            if false_flow < true_flow * 0.3:
                patterns.append(
                    f"â€¢ è¯¯æŠ¥çš„è¿çº¿æ•°æ˜æ˜¾è¾ƒå°‘ï¼ˆä¸­ä½æ•°: {false_flow:,.0f} vs çœŸå®: {true_flow:,.0f}ï¼‰"
                )
                patterns.append(
                    f"  å»ºè®®ï¼šæé«˜ flow_count é˜ˆå€¼åˆ° {int(true_flow*0.5):,}"
                )

        return patterns

    def generate_report(self, recommendations: Dict, output_file: str = None):
        """ç”Ÿæˆè¯¦ç»†çš„ä¼˜åŒ–æŠ¥å‘Š"""
        lines = []

        lines.append("=" * 80)
        lines.append("åˆ†ç±»å™¨é˜ˆå€¼ä¼˜åŒ–æŠ¥å‘Š (åŸºäºäººå·¥æ ‡æ³¨æ•°æ®)")
        lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("=" * 80)
        lines.append("")

        if not recommendations:
            lines.append("âš ï¸  æ²¡æœ‰æ¨èçš„é˜ˆå€¼è°ƒæ•´")
            lines.append("   åŸå› ï¼šæ ‡æ³¨æ•°æ®ä¸è¶³ï¼ˆæ¯ç§å¨èƒè‡³å°‘éœ€è¦ 5 ä¸ªçœŸå®æ ·æœ¬ï¼‰")
        else:
            for threat_class, rec in recommendations.items():
                lines.append(f"\n{'='*80}")
                lines.append(f"{threat_class} å¨èƒ")
                lines.append(f"{'='*80}\n")

                # æ’é™¤åˆ†æéƒ¨åˆ†
                false_positive_analysis = rec.pop('false_positive_analysis', None)

                for feature_name, feature_rec in rec.items():
                    if feature_name == 'false_positive_analysis':
                        continue

                    lines.append(f"\nğŸ“Š {feature_name}:")
                    lines.append(f"   å½“å‰é˜ˆå€¼: {feature_rec['current']}")
                    lines.append(f"   æ¨èé˜ˆå€¼: {feature_rec['recommended']}")

                    change = feature_rec['recommended'] - feature_rec['current']
                    change_pct = (change / feature_rec['current'] * 100) if feature_rec['current'] != 0 else 0

                    if change > 0:
                        lines.append(f"   å˜åŒ–: +{change} (+{change_pct:.1f}%) - æ›´ä¸¥æ ¼")
                    elif change < 0:
                        lines.append(f"   å˜åŒ–: {change} ({change_pct:.1f}%) - æ›´å®½æ¾")
                    else:
                        lines.append(f"   å˜åŒ–: æ— å˜åŒ–")

                    lines.append(f"   ç†ç”±: {feature_rec['rationale']}")
                    lines.append(f"   æ ·æœ¬æ•°: {feature_rec['samples']}")

                    if 'distribution' in feature_rec:
                        dist = feature_rec['distribution']
                        lines.append(f"   åˆ†å¸ƒ: min={dist['min']}, p25={dist['p25']}, median={dist['median']}, p75={dist['p75']}, max={dist['max']}")

                # è¯¯æŠ¥åˆ†æ
                if false_positive_analysis:
                    lines.append(f"\nâš ï¸  è¯¯æŠ¥åˆ†æ:")
                    lines.append(f"   è¯¯æŠ¥æ•°é‡: {false_positive_analysis['count']}")
                    lines.append(f"\n   å…±åŒç‰¹å¾:")
                    for pattern in false_positive_analysis['common_patterns']:
                        lines.append(f"   {pattern}")

        lines.append(f"\n\n{'='*80}")
        lines.append("ä¸‹ä¸€æ­¥æ“ä½œ")
        lines.append(f"{'='*80}\n")
        lines.append("1. å®¡æŸ¥æ¨èçš„é˜ˆå€¼è°ƒæ•´")
        lines.append("2. ç¼–è¾‘ nad/ml/anomaly_classifier.py")
        lines.append("3. åº”ç”¨æ¨èçš„é˜ˆå€¼å’Œæ’é™¤è§„åˆ™")
        lines.append("4. æµ‹è¯•è°ƒæ•´åçš„åˆ†ç±»å™¨")
        lines.append("5. æŒç»­æ”¶é›†æ ‡æ³¨æ•°æ®ï¼Œå®šæœŸé‡æ–°ä¼˜åŒ–")

        report = "\n".join(lines)

        # æ‰“å°åˆ°æ§åˆ¶å°
        print(report)

        # ä¿å­˜åˆ°æ–‡ä»¶
        if output_file:
            try:
                with open(output_file, 'w') as f:
                    f.write(report)
                print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            except Exception as e:
                print(f"\nâš ï¸  ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

        return report


def main():
    parser = argparse.ArgumentParser(
        description='åˆ†ç±»å™¨é˜ˆå€¼ä¼˜åŒ–å·¥å…· v2.0 (æ”¯æŒäººå·¥æ ‡æ³¨)'
    )

    parser.add_argument(
        '--config',
        type=str,
        default='nad/config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„'
    )

    parser.add_argument(
        '--label',
        action='store_true',
        help='æ”¶é›†å¹¶æ ‡æ³¨å¼‚å¸¸æ•°æ®'
    )

    parser.add_argument(
        '--recommend',
        action='store_true',
        help='åŸºäºæ ‡æ³¨æ•°æ®æ¨èé˜ˆå€¼'
    )

    parser.add_argument(
        '--days',
        type=int,
        default=7,
        help='åˆ†æå¤©æ•°ï¼ˆé»˜è®¤ 7 å¤©ï¼‰'
    )

    parser.add_argument(
        '--report',
        type=str,
        help='æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶è·¯å¾„'
    )

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    try:
        config = load_config(args.config)
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
        sys.exit(1)

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = ImprovedClassifierThresholdOptimizer(config)

    # æ‰§è¡Œæ“ä½œ
    if args.label:
        # æ ‡æ³¨æ¨¡å¼
        optimizer.collect_and_label_anomalies(days=args.days)

    elif args.recommend:
        # æ¨èæ¨¡å¼
        recommendations = optimizer.recommend_thresholds_from_labeled_data()

        if recommendations:
            # ç”ŸæˆæŠ¥å‘Š
            report_file = args.report or f"reports/threshold_optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            optimizer.generate_report(recommendations, report_file)
        else:
            print("\nâš ï¸  æ— æ³•ç”Ÿæˆæ¨è")
            print("   è¯·å…ˆæ ‡æ³¨æ•°æ®: python3 optimize_classifier_thresholds_v2.py --label --days 7")

    else:
        # é»˜è®¤ï¼šå…ˆæ ‡æ³¨ï¼Œå†æ¨è
        print("é»˜è®¤æ¨¡å¼ï¼šæ”¶é›†å¹¶æ ‡æ³¨æ•°æ®ï¼Œç„¶åç”Ÿæˆæ¨è")
        print()

        labeled = optimizer.collect_and_label_anomalies(days=args.days)

        if labeled > 0:
            print(f"\nâœ“ å·²æ ‡æ³¨ {labeled} ä¸ªå¼‚å¸¸")
            print("\nç»§ç»­ç”Ÿæˆæ¨è...\n")

            recommendations = optimizer.recommend_thresholds_from_labeled_data()

            if recommendations:
                report_file = args.report or f"reports/threshold_optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                optimizer.generate_report(recommendations, report_file)


if __name__ == "__main__":
    main()
```

#### ä½¿ç”¨æ”¹è¿›ç‰ˆå·¥å…·

```bash
# 1. æ”¶é›†æ•°æ®å¹¶äººå·¥æ ‡æ³¨
python3 optimize_classifier_thresholds_v2.py --label --days 7

# äº¤äº’å¼æ ‡æ³¨è¿‡ç¨‹ï¼š
# ================================================================================
# å¼‚å¸¸ #1/50 (å·²æ ‡æ³¨: 0)
# ================================================================================
#
# ğŸ“ åŸºæœ¬ä¿¡æ¯:
#    IP: 192.168.1.100
#    æ—¶é—´: 2025-11-17 14:30:00
#    å¼‚å¸¸åˆ†æ•°: 0.7500
#
# ğŸ“Š æµé‡ç‰¹å¾:
#    è¿çº¿æ•°: 7,500
#    æ€»æµé‡: 2.63 GB
#    å¹³å‡æµé‡: 350 bytes
#    æœ€å¤§æµé‡: 5.00 MB
#
# ğŸ¯ ç›®æ ‡åˆ†æ:
#    ä¸åŒç›®çš„åœ°: 5
#    ä¸åŒæºç«¯å£: 1500
#    ä¸åŒç›®çš„ç«¯å£: 3
#    ç›®çš„åœ°åˆ†æ•£åº¦: 0.001
#
# ğŸ·ï¸  è¡Œä¸ºæ ‡è®°:
#    é«˜è¿çº¿æ•°, å°å°åŒ…
#
# ğŸ¤– åˆ†ç±»å™¨åˆ¤æ–­:
#    ç±»åˆ«: DDoS æ”»å‡» (DDOS)
#    ç½®ä¿¡åº¦: 75%
#    ä¸¥é‡æ€§: CRITICAL
#    å…³é”®æŒ‡æ ‡:
#       â€¢ æé«˜è¿çº¿æ•°: 7,500
#       â€¢ æå°å°åŒ…: 350 bytes
#
# ğŸ‘¤ è¿™ä¸ªåˆ¤æ–­æ­£ç¡®å—ï¼Ÿ(y/n/s/q): n  â† åˆ¤æ–­ï¼šä¸æ˜¯ DDoS
#    âœ— æ ‡æ³¨ä¸ºï¼šè¯¯æŠ¥
#
#    çœŸå®ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ
#    1. PORT_SCAN (ç«¯å£æ‰«æ)
#    2. NETWORK_SCAN (ç½‘ç»œæ‰«æ)
#    3. DNS_TUNNELING (DNS éš§é“)
#    4. DDOS (DDoS æ”»å‡»)
#    5. DATA_EXFILTRATION (æ•°æ®å¤–æ³„)
#    6. C2_COMMUNICATION (C&C é€šä¿¡)
#    7. NORMAL_HIGH_TRAFFIC (æ­£å¸¸é«˜æµé‡)  â† é€‰æ‹©
#    8. UNKNOWN (æœªçŸ¥)
#    9. è·³è¿‡
#    è¯·é€‰æ‹© (1-9): 7
#    â†’ çœŸå®ç±»å‹ï¼šNORMAL_HIGH_TRAFFIC

# 2. åŸºäºæ ‡æ³¨æ•°æ®ç”Ÿæˆæ¨è
python3 optimize_classifier_thresholds_v2.py --recommend

# è¾“å‡ºç¤ºä¾‹ï¼š
# ================================================================================
# åˆ†ç±»å™¨é˜ˆå€¼ä¼˜åŒ–æŠ¥å‘Š (åŸºäºäººå·¥æ ‡æ³¨æ•°æ®)
# ç”Ÿæˆæ—¶é—´: 2025-11-17 16:30:00
# ================================================================================
#
# ================================================================================
# DDOS å¨èƒ
# ================================================================================
#
# ğŸ“Š flow_count:
#    å½“å‰é˜ˆå€¼: 10000
#    æ¨èé˜ˆå€¼: 45000
#    å˜åŒ–: +35000 (+350.0%) - æ›´ä¸¥æ ¼
#    ç†ç”±: P5 å€¼ï¼ŒåŸºäºçœŸå® DDoS æ•°æ®ï¼ˆäººå·¥éªŒè¯ï¼‰ï¼Œ95% çœŸå®æ”»å‡»ä¼šè¢«æ•è·
#    æ ·æœ¬æ•°: 3
#    åˆ†å¸ƒ: min=45000, p25=52000, median=68000, p75=85000, max=120000
#
# ğŸ“Š avg_bytes:
#    å½“å‰é˜ˆå€¼: 500
#    æ¨èé˜ˆå€¼: 280
#    å˜åŒ–: -220 (-44.0%) - æ›´å®½æ¾
#    ç†ç”±: P90 å€¼ï¼Œè¦†ç›– 90% çš„çœŸå® DDoS
#    æ ·æœ¬æ•°: 3
#    åˆ†å¸ƒ: min=120, p25=180, median=220, p75=260, max=280
#
# âš ï¸  è¯¯æŠ¥åˆ†æ:
#    è¯¯æŠ¥æ•°é‡: 9
#
#    å…±åŒç‰¹å¾:
#    â€¢ 67% çš„è¯¯æŠ¥æ˜¯æœåŠ¡å™¨å›åº”æµé‡
#      å»ºè®®ï¼šæ·»åŠ  'is_likely_server_response == 0' æ¡ä»¶
#    â€¢ è¯¯æŠ¥çš„æµé‡é›†ä¸­åº¦è¾ƒä½ï¼ˆä¸­ä½æ•°: 0.15 vs çœŸå®: 0.85ï¼‰
#      å»ºè®®ï¼šæ·»åŠ  'traffic_concentration > 0.43' æ¡ä»¶
#    â€¢ è¯¯æŠ¥çš„è¿çº¿æ•°æ˜æ˜¾è¾ƒå°‘ï¼ˆä¸­ä½æ•°: 8,500 vs çœŸå®: 68,000ï¼‰
#      å»ºè®®ï¼šæé«˜ flow_count é˜ˆå€¼åˆ° 34,000
#
# ================================================================================
# ä¸‹ä¸€æ­¥æ“ä½œ
# ================================================================================
#
# 1. å®¡æŸ¥æ¨èçš„é˜ˆå€¼è°ƒæ•´
# 2. ç¼–è¾‘ nad/ml/anomaly_classifier.py
# 3. åº”ç”¨æ¨èçš„é˜ˆå€¼å’Œæ’é™¤è§„åˆ™
# 4. æµ‹è¯•è°ƒæ•´åçš„åˆ†ç±»å™¨
# 5. æŒç»­æ”¶é›†æ ‡æ³¨æ•°æ®ï¼Œå®šæœŸé‡æ–°ä¼˜åŒ–
#
# ğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜åˆ°: reports/threshold_optimization_20251117_163000.txt

# 3. åº”ç”¨æ¨èçš„é˜ˆå€¼
vim nad/ml/anomaly_classifier.py

# æ ¹æ®æŠ¥å‘Šä¿®æ”¹ _is_ddos å‡½æ•°ï¼š
def _is_ddos(self, features: Dict) -> bool:
    return (
        flow_count > 45000 and                              # ä» 10000 æ”¹ä¸º 45000
        avg_bytes < 280 and                                 # ä» 500 æ”¹ä¸º 280
        unique_dsts < 10 and                                # ä¿æŒä¸å˜
        features.get('is_likely_server_response', 0) == 0 and  # æ–°å¢
        features.get('traffic_concentration', 0) > 0.43     # æ–°å¢
    )
```

---

### æ–¹æ³• 4: ä½¿ç”¨ç›‘ç£å­¦ä¹ 

**é€‚ç”¨åœºæ™¯**: æœ‰è¶³å¤Ÿçš„æ ‡æ³¨æ•°æ®ï¼Œéœ€è¦æœ€é«˜çš„åˆ†ç±»å‡†ç¡®ç‡
**å®æ–½éš¾åº¦**: â˜…â˜…â˜…â˜…â˜…
**æ•ˆæœ**: é•¿æœŸæœ€ä¼˜

#### å½“å‰æ¶æ„ vs æ”¹è¿›æ¶æ„

```
å½“å‰æ¶æ„ï¼ˆæ— ç›‘ç£ + è§„åˆ™ï¼‰:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Isolation Forestâ”‚ --> â”‚ è§„åˆ™åˆ†ç±»å™¨        â”‚
â”‚  (æ— ç›‘ç£å­¦ä¹ )    â”‚     â”‚ (ç¡¬ç¼–ç è§„åˆ™)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                        â†“
   æ‰¾å‡ºå¼‚å¸¸              å®¹æ˜“è¯¯åˆ†ç±»
                      (è§„åˆ™ä¸å¤Ÿçµæ´»)

æ”¹è¿›æ¶æ„ï¼ˆæ— ç›‘ç£ + ç›‘ç£å­¦ä¹ ï¼‰:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Isolation Forestâ”‚ --> â”‚ éšæœºæ£®æ—/XGBoost  â”‚
â”‚  (æ— ç›‘ç£å­¦ä¹ )    â”‚     â”‚  (ç›‘ç£å­¦ä¹ )       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                        â†“
   æ‰¾å‡ºå¼‚å¸¸            å‡†ç¡®åˆ†ç±»ï¼ˆåŸºäºæ ‡æ³¨æ•°æ®ï¼‰
                      è‡ªåŠ¨å­¦ä¹ æœ€ä½³é˜ˆå€¼
```

#### éœ€è¦çš„æ•°æ®é‡

```
æœ€å°‘éœ€æ±‚ï¼š
- æ¯ç§å¨èƒç±»å‹: 50-100 ä¸ªæ ‡æ³¨æ ·æœ¬
- æ€»è®¡: 300-500 ä¸ªæ ‡æ³¨æ ·æœ¬

ç†æƒ³æƒ…å†µï¼š
- æ¯ç§å¨èƒç±»å‹: 200-500 ä¸ªæ ‡æ³¨æ ·æœ¬
- æ€»è®¡: 1000-2000 ä¸ªæ ‡æ³¨æ ·æœ¬
```

#### å®æ–½æ­¥éª¤

```bash
# Phase 1: æ”¶é›†æ ‡æ³¨æ•°æ®ï¼ˆ1-2 ä¸ªæœˆï¼‰
# æŒç»­ä½¿ç”¨æ”¹è¿›ç‰ˆä¼˜åŒ–å·¥å…·æ ‡æ³¨æ•°æ®
python3 optimize_classifier_thresholds_v2.py --label --days 7

# Phase 2: è®­ç»ƒç›‘ç£å­¦ä¹ åˆ†ç±»å™¨
python3 train_supervised_classifier.py --data nad/models/labeled_anomalies.json

# Phase 3: è¯„ä¼°æ€§èƒ½
python3 evaluate_supervised_classifier.py

# Phase 4: éƒ¨ç½²
# æ›¿æ¢è§„åˆ™åˆ†ç±»å™¨ä¸ºç›‘ç£å­¦ä¹ åˆ†ç±»å™¨
```

#### ä¼˜ç‚¹

- âœ… è‡ªåŠ¨å­¦ä¹ æœ€ä½³å†³ç­–è¾¹ç•Œ
- âœ… å¯ä»¥æ•è·å¤æ‚çš„ç‰¹å¾ç»„åˆ
- âœ… æŒç»­æ”¹è¿›ï¼ˆéšç€æ•°æ®å¢åŠ ï¼‰
- âœ… æ›´é«˜çš„å‡†ç¡®ç‡

#### ç¼ºç‚¹

- âŒ éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®
- âŒ å®æ–½å¤æ‚åº¦é«˜
- âŒ å¯è§£é‡Šæ€§é™ä½
- âŒ éœ€è¦å®šæœŸé‡æ–°è®­ç»ƒ

---

## å®Œæ•´ä¼˜åŒ–æµç¨‹

### é˜¶æ®µ 1: åˆå§‹éƒ¨ç½²ï¼ˆç¬¬ 1 å‘¨ï¼‰

```bash
# Day 1: éƒ¨ç½²ç³»ç»Ÿ
# ä½¿ç”¨ä¿å®ˆçš„åˆå§‹é˜ˆå€¼ï¼ˆå®å¯æ¼æŠ¥ï¼Œä¸è¦è¯¯æŠ¥ï¼‰

# 1. æ£€æŸ¥å½“å‰é…ç½®
cat nad/config.yaml
cat nad/ml/anomaly_classifier.py

# 2. å¦‚æœæ‹…å¿ƒè¯¯æŠ¥ï¼Œå…ˆæé«˜é˜ˆå€¼
vim nad/ml/anomaly_classifier.py
# å°† DDoS çš„ flow_count > 10000 æ”¹ä¸º flow_count > 50000

# 3. å¯åŠ¨æ£€æµ‹
python3 realtime_detection.py --continuous --interval 5 &

# 4. è§‚å¯Ÿ 1 å‘¨ï¼Œä¸è¦è°ƒæ•´
tail -f logs/nad.log
```

### é˜¶æ®µ 2: æ•°æ®æ”¶é›†ï¼ˆç¬¬ 2-3 å‘¨ï¼‰

```bash
# Day 7-21: æŒç»­è¿è¡Œï¼Œæ”¶é›†æ•°æ®

# æ¯å¤©æ£€æŸ¥æ£€æµ‹ç»“æœ
python3 realtime_detection.py --minutes 1440  # åˆ†æ 24 å°æ—¶

# è®°å½•è§‚å¯Ÿï¼š
# - æ¯å¤©æ£€æµ‹åˆ°å¤šå°‘å¼‚å¸¸ï¼Ÿ
# - å“ªäº›æ˜¯çœŸå®å¨èƒï¼Ÿ
# - å“ªäº›æ˜¯è¯¯æŠ¥ï¼Ÿ
# - æœ‰æ²¡æœ‰æ¼æŠ¥ï¼Ÿ

# å¦‚æœè¯¯æŠ¥å¤ªå¤šï¼Œæ‰‹åŠ¨æ·»åŠ ç™½åå•
vim nad/config.yaml
# æ·»åŠ å·²çŸ¥æ­£å¸¸çš„ IP/æœåŠ¡
```

### é˜¶æ®µ 3: äººå·¥å®¡æŸ¥ï¼ˆç¬¬ 4 å‘¨ï¼‰

```bash
# Day 22-28: æ·±å…¥åˆ†æ

# 1. éšæœºæŠ½æŸ¥å¼‚å¸¸
python3 verify_anomaly.py --ip <éšæœºé€‰æ‹©çš„ IP> --minutes 30

# 2. å¯¹äºæ¯ä¸ªå¼‚å¸¸ï¼Œåˆ¤æ–­ï¼š
#    - è¿™æ˜¯çœŸå®å¨èƒå—ï¼Ÿ
#    - åˆ†ç±»æ­£ç¡®å—ï¼Ÿ
#    - å¦‚æœè¯¯æŠ¥ï¼ŒåŸå› æ˜¯ä»€ä¹ˆï¼Ÿ

# 3. åˆ›å»ºç™½åå•
vim nad/config.yaml
# æ·»åŠ ç¡®è®¤çš„æ­£å¸¸æœåŠ¡

# 4. å¼€å§‹äººå·¥æ ‡æ³¨
python3 optimize_classifier_thresholds_v2.py --label --days 7

# ç›®æ ‡ï¼šæ ‡æ³¨è‡³å°‘ 50 ä¸ªå¼‚å¸¸
```

### é˜¶æ®µ 4: é¦–æ¬¡ä¼˜åŒ–ï¼ˆç¬¬ 5 å‘¨ï¼‰

```bash
# Day 29-35: åŸºäºæ ‡æ³¨æ•°æ®ä¼˜åŒ–

# 1. ç”Ÿæˆæ¨è
python3 optimize_classifier_thresholds_v2.py --recommend

# 2. å®¡æŸ¥æ¨èå€¼
#    - æ¨èå€¼åˆç†å—ï¼Ÿ
#    - å˜åŒ–å¹…åº¦æ˜¯å¦å¤ªå¤§ï¼ˆ> 100%ï¼‰ï¼Ÿ
#    - æ˜¯å¦æœ‰è¯¯æŠ¥åˆ†æå»ºè®®ï¼Ÿ

# 3. è°¨æ…åº”ç”¨æ¨èå€¼
#    - å¦‚æœå˜åŒ– < 30%ï¼šå¯ä»¥ç›´æ¥åº”ç”¨
#    - å¦‚æœå˜åŒ– 30-100%ï¼šåˆ†æ­¥è°ƒæ•´ï¼ˆå…ˆè°ƒä¸€åŠï¼‰
#    - å¦‚æœå˜åŒ– > 100%ï¼šéœ€è¦äººå·¥åˆ¤æ–­

# 4. å¤‡ä»½å¹¶ä¿®æ”¹
cp nad/ml/anomaly_classifier.py nad/ml/anomaly_classifier.py.backup_week5
vim nad/ml/anomaly_classifier.py

# 5. æµ‹è¯•æ–°é˜ˆå€¼
python3 realtime_detection.py --minutes 1440

# 6. å¦‚æœæ•ˆæœä¸å¥½ï¼Œå›æ»š
cp nad/ml/anomaly_classifier.py.backup_week5 nad/ml/anomaly_classifier.py
```

### é˜¶æ®µ 5: æŒç»­æ”¹è¿›ï¼ˆç¬¬ 6 å‘¨+ï¼‰

```bash
# æ¯æœˆä¾‹è¡Œä»»åŠ¡ï¼š

# 1. æŒç»­æ ‡æ³¨ï¼ˆæ¯å‘¨ï¼‰
python3 optimize_classifier_thresholds_v2.py --label --days 7

# 2. æ¯æœˆä¼˜åŒ–ï¼ˆæœˆåˆï¼‰
python3 optimize_classifier_thresholds_v2.py --recommend

# 3. å®¡æŸ¥å¹¶åº”ç”¨

# 4. ç›‘æ§æ•ˆæœ

# 5. å½“æ ‡æ³¨æ•°æ® > 500 ä¸ªæ—¶ï¼Œè€ƒè™‘åˆ‡æ¢åˆ°ç›‘ç£å­¦ä¹ 
```

---

## æœ€ä½³å®è·µ

### 1. æ¸è¿›å¼è°ƒæ•´åŸåˆ™

```
âœ… å¥½çš„åšæ³•ï¼š
- å°æ­¥å¿«è·‘ï¼šæ¯æ¬¡è°ƒæ•´ 20-30%
- è§‚å¯Ÿ 1-2 å‘¨åå†ç»§ç»­è°ƒæ•´
- ä¿ç•™æ¯æ¬¡è°ƒæ•´çš„å¤‡ä»½

âŒ ä¸å¥½çš„åšæ³•ï¼š
- ä¸€æ¬¡æ€§å¤§å¹…è°ƒæ•´ï¼ˆå¦‚ 100% ä»¥ä¸Šï¼‰
- è°ƒæ•´åä¸è§‚å¯Ÿæ•ˆæœå°±ç»§ç»­è°ƒæ•´
- ä¸ä¿ç•™å¤‡ä»½
```

### 2. æ•°æ®è´¨é‡ä¼˜å…ˆ

```
âœ… å¥½çš„åšæ³•ï¼š
- æ ‡æ³¨æ•°æ®è¦å‡†ç¡®
- ä¸ç¡®å®šçš„è·³è¿‡ï¼Œä¸è¦éšä¾¿æ ‡æ³¨
- å®šæœŸå¤æŸ¥å·²æ ‡æ³¨çš„æ•°æ®

âŒ ä¸å¥½çš„åšæ³•ï¼š
- éšæ„æ ‡æ³¨
- æ ‡æ³¨æ•°é‡å¤šä½†è´¨é‡å·®
- ä»ä¸å¤æŸ¥
```

### 3. å¹³è¡¡å¬å›ç‡å’Œç²¾ç¡®ç‡

```
åœºæ™¯ 1: å®‰å…¨æ€§ä¼˜å…ˆï¼ˆå¦‚é‡‘èã€åŒ»ç–—ï¼‰
â†’ å®å¯è¯¯æŠ¥ï¼Œä¸è¦æ¼æŠ¥
â†’ ä½¿ç”¨è¾ƒä½çš„é˜ˆå€¼
â†’ å®¹å¿ä¸€å®šçš„è¯¯æŠ¥ç‡

åœºæ™¯ 2: è¿ç»´æ•ˆç‡ä¼˜å…ˆ
â†’ å®å¯æ¼æŠ¥ï¼Œä¸è¦è¯¯æŠ¥
â†’ ä½¿ç”¨è¾ƒé«˜çš„é˜ˆå€¼
â†’ åªæŠ¥å‘Šé«˜ç½®ä¿¡åº¦çš„å¨èƒ

ä½ çš„é€‰æ‹©åº”è¯¥åŸºäºï¼š
- ä¸šåŠ¡ç‰¹æ€§
- è¿ç»´èµ„æº
- é£é™©æ‰¿å—èƒ½åŠ›
```

### 4. æ–‡æ¡£åŒ–æ‰€æœ‰è°ƒæ•´

```bash
# åˆ›å»ºè°ƒæ•´æ—¥å¿—
vim docs/threshold_adjustment_log.md

# è®°å½•æ¯æ¬¡è°ƒæ•´ï¼š
## 2025-11-17 é¦–æ¬¡ä¼˜åŒ–

### èƒŒæ™¯
- è¿è¡Œ 3 å‘¨åï¼Œå‘ç° DDoS è¯¯æŠ¥ç‡ 75%
- ä¸»è¦è¯¯æŠ¥ï¼šè§†é¢‘ä¼šè®®æœåŠ¡å™¨ã€å¤‡ä»½ç³»ç»Ÿ

### è°ƒæ•´
- flow_count: 10000 â†’ 45000 (+350%)
- avg_bytes: 500 â†’ 280 (-44%)
- æ–°å¢æ¡ä»¶ï¼šis_likely_server_response == 0

### æ•ˆæœ
- è¯¯æŠ¥ç‡: 75% â†’ 10%
- å¬å›ç‡: 100% â†’ 95%
- æ•´ä½“æ»¡æ„åº¦: æå‡

### ä¸‹æ¬¡ä¼˜åŒ–è®¡åˆ’
- 2025-12-15
- ç›®æ ‡ï¼šè¿›ä¸€æ­¥é™ä½è¯¯æŠ¥ç‡åˆ° < 5%
```

### 5. å»ºç«‹åé¦ˆæœºåˆ¶

```bash
# åˆ›å»ºå¼‚å¸¸åé¦ˆæµç¨‹

# 1. è¿ç»´äººå‘˜å‘ç°è¯¯æŠ¥æ—¶
#    â†’ è®°å½•åˆ°åé¦ˆè¡¨æ ¼
#    â†’ æ·»åŠ åˆ°ç™½åå•

# 2. å‘ç°æ¼æŠ¥æ—¶
#    â†’ è®°å½•æ¼æŠ¥æ¡ˆä¾‹
#    â†’ è°ƒæŸ¥åŸå› 
#    â†’ è°ƒæ•´é˜ˆå€¼

# 3. æ¯æœˆæ±‡æ€»
#    â†’ åˆ†æè¯¯æŠ¥/æ¼æŠ¥è¶‹åŠ¿
#    â†’ ä¼˜åŒ–ç­–ç•¥
```

### 6. å®šæœŸæ£€æŸ¥

```bash
# æ¯å‘¨æ£€æŸ¥ï¼ˆå‘¨ä¸€æ—©ä¸Šï¼‰
- æŸ¥çœ‹è¿‡å»ä¸€å‘¨çš„å¼‚å¸¸æ•°é‡
- æœ‰æ²¡æœ‰æ–°çš„è¯¯æŠ¥æ¨¡å¼ï¼Ÿ
- æœ‰æ²¡æœ‰æ¼æŠ¥ï¼Ÿ

# æ¯æœˆæ£€æŸ¥ï¼ˆæœˆåˆï¼‰
- è¿è¡Œä¼˜åŒ–å·¥å…·
- å®¡æŸ¥æ¨èçš„è°ƒæ•´
- åº”ç”¨è°ƒæ•´

# æ¯å­£åº¦æ£€æŸ¥ï¼ˆå­£åº¦æœ«ï¼‰
- å›é¡¾æ•´ä½“è¡¨ç°
- è¯„ä¼°æ˜¯å¦éœ€è¦åˆ‡æ¢æ–¹æ¡ˆï¼ˆå¦‚ç›‘ç£å­¦ä¹ ï¼‰
- æ›´æ–°æ–‡æ¡£
```

### 7. ä¿ç•™å†å²æ•°æ®

```bash
# ä¿ç•™æ‰€æœ‰ç‰ˆæœ¬çš„é…ç½®å’Œé˜ˆå€¼
mkdir -p nad/config_history
mkdir -p nad/models/classifier_history

# æ¯æ¬¡è°ƒæ•´å‰å¤‡ä»½
cp nad/config.yaml nad/config_history/config_$(date +%Y%m%d_%H%M%S).yaml
cp nad/ml/anomaly_classifier.py nad/models/classifier_history/classifier_$(date +%Y%m%d_%H%M%S).py

# ä¿ç•™æ ‡æ³¨æ•°æ®
cp nad/models/labeled_anomalies.json nad/models/labeled_anomalies_$(date +%Y%m%d).json
```

---

## æ€»ç»“

### å…³é”®è¦ç‚¹

1. **è¯¯åˆ†ç±»æ˜¯æ­£å¸¸çš„**
   - åˆå§‹é˜¶æ®µå¿…ç„¶æœ‰è¯¯æŠ¥
   - å…³é”®æ˜¯å¦‚ä½•å¿«é€Ÿå‘ç°å’Œä¿®æ­£

2. **ä¸è¦ç›²ç›®ä¼˜åŒ–**
   - ä¼˜åŒ–å·¥å…·çš„å‡è®¾ï¼š"è¢«åˆ†ç±»ä¸º X çš„éƒ½æ˜¯çœŸæ­£çš„ X"
   - å¦‚æœå‡è®¾ä¸æˆç«‹ï¼Œä¼˜åŒ–ä¼šæ”¾å¤§é”™è¯¯

3. **äººå·¥å®¡æŸ¥ä¸å¯å°‘**
   - ç‰¹åˆ«æ˜¯åˆæœŸï¼ˆå‰ 1-2 ä¸ªæœˆï¼‰
   - å»ºç«‹ç™½åå•
   - æ”¶é›†æ ‡æ³¨æ•°æ®

4. **æ¸è¿›å¼è°ƒæ•´**
   - å°æ­¥å¿«è·‘
   - è§‚å¯Ÿæ•ˆæœ
   - ä¿ç•™å¤‡ä»½

5. **é•¿æœŸç›®æ ‡ï¼šç›‘ç£å­¦ä¹ **
   - æ”¶é›† 500+ æ ‡æ³¨æ ·æœ¬
   - è®­ç»ƒç›‘ç£å­¦ä¹ åˆ†ç±»å™¨
   - è‡ªåŠ¨å­¦ä¹ æœ€ä½³é˜ˆå€¼

### å·¥å…·é€‰æ‹©

| é˜¶æ®µ | æ¨èå·¥å…· | ç›®æ ‡ |
|------|---------|------|
| ç¬¬ 1 å‘¨ | æ‰‹åŠ¨è°ƒæ•´é˜ˆå€¼ | å¿«é€Ÿé™ä½è¯¯æŠ¥ |
| ç¬¬ 2-4 å‘¨ | ç™½åå• + äººå·¥å®¡æŸ¥ | å»ºç«‹ä¿¡ä»»ï¼Œæ”¶é›†æ•°æ® |
| ç¬¬ 5-8 å‘¨ | æ”¹è¿›ç‰ˆä¼˜åŒ–å·¥å…· | åŸºäºçœŸå®æ•°æ®ä¼˜åŒ– |
| ç¬¬ 3 ä¸ªæœˆ+ | ç›‘ç£å­¦ä¹  | æœ€ä¼˜æ€§èƒ½ |

### æˆåŠŸæŒ‡æ ‡

```
çŸ­æœŸï¼ˆ1 ä¸ªæœˆï¼‰ï¼š
âœ“ è¯¯æŠ¥ç‡ < 20%
âœ“ è¿ç»´å›¢é˜Ÿæ¥å—åº¦æé«˜
âœ“ æ”¶é›† > 50 ä¸ªæ ‡æ³¨æ ·æœ¬

ä¸­æœŸï¼ˆ3 ä¸ªæœˆï¼‰ï¼š
âœ“ è¯¯æŠ¥ç‡ < 10%
âœ“ å¬å›ç‡ > 90%
âœ“ æ”¶é›† > 200 ä¸ªæ ‡æ³¨æ ·æœ¬

é•¿æœŸï¼ˆ6 ä¸ªæœˆï¼‰ï¼š
âœ“ è¯¯æŠ¥ç‡ < 5%
âœ“ å¬å›ç‡ > 95%
âœ“ éƒ¨ç½²ç›‘ç£å­¦ä¹ åˆ†ç±»å™¨
```

---

**æ–‡æ¡£ç»“æŸ**

ç›¸å…³æ–‡æ¡£ï¼š
- [DDoS æ£€æµ‹ä¸é˜ˆå€¼ä¼˜åŒ–é—®ç­”](./DDOS_DETECTION_AND_THRESHOLD_OPTIMIZATION_QA.md)
- [Isolation Forest ä½¿ç”¨æŒ‡å—](../ISOLATION_FOREST_GUIDE.md)
- [å¼‚å¸¸åˆ†ç±»æŒ‡å—](../ANOMALY_CLASSIFICATION_GUIDE.md)
