#!/usr/bin/env python3
"""
å¯¦æ™‚ç•°å¸¸æª¢æ¸¬è…³æœ¬ï¼ˆèšåˆç‰ˆï¼‰

å°‡åŒä¸€ IP çš„å¤šå€‹ç•°å¸¸æ™‚é–“æ¡¶èšåˆé¡¯ç¤º
"""

import sys
import argparse
import time
import warnings
from datetime import datetime
from collections import defaultdict

# å¿½ç•¥ Elasticsearch å®‰å…¨è­¦å‘Š
warnings.filterwarnings('ignore', message='.*Elasticsearch built-in security features.*')

from nad.utils import load_config
from nad.ml import OptimizedIsolationForest


def aggregate_anomalies_by_ip(anomalies):
    """å°‡ç•°å¸¸æŒ‰ IP èšåˆ"""
    ip_anomalies = defaultdict(list)

    for anomaly in anomalies:
        ip = anomaly['src_ip']
        ip_anomalies[ip].append(anomaly)

    # ç‚ºæ¯å€‹ IP è¨ˆç®—èšåˆçµ±è¨ˆ
    aggregated = []
    for ip, records in ip_anomalies.items():
        # ä½¿ç”¨æœ€é«˜ç•°å¸¸åˆ†æ•¸
        max_score_record = max(records, key=lambda x: x['anomaly_score'])

        agg = {
            'src_ip': ip,
            'occurrence_count': len(records),  # ç•°å¸¸å‡ºç¾æ¬¡æ•¸
            'max_anomaly_score': max(r['anomaly_score'] for r in records),
            'avg_anomaly_score': sum(r['anomaly_score'] for r in records) / len(records),
            'total_flow_count': sum(r['flow_count'] for r in records),
            'avg_flow_count': sum(r['flow_count'] for r in records) / len(records),
            'max_unique_dsts': max(r['unique_dsts'] for r in records),
            'avg_bytes': sum(r['avg_bytes'] for r in records) / len(records),
            'total_bytes': sum(r['total_bytes'] for r in records),
            'time_buckets': [r['time_bucket'] for r in records],
            'confidence': max_score_record['confidence'],
            'features': max_score_record['features']
        }
        aggregated.append(agg)

    # æŒ‰æœ€é«˜ç•°å¸¸åˆ†æ•¸æ’åº
    aggregated.sort(key=lambda x: x['max_anomaly_score'], reverse=True)

    return aggregated


def print_aggregated_anomalies(anomalies, top_n=20):
    """æ‰“å°èšåˆå¾Œçš„ç•°å¸¸çµæœ"""
    if not anomalies:
        print("âœ… æœªç™¼ç¾ç•°å¸¸\n")
        return

    print(f"\nâš ï¸  ç™¼ç¾ {len(anomalies)} å€‹ç•°å¸¸ IP\n")
    print(f"{'='*120}")
    print(f"{'æ’å':<6} {'IPåœ°å€':<17} {'å‡ºç¾æ¬¡æ•¸':<10} {'æœ€é«˜åˆ†æ•¸':<12} {'å¹³å‡åˆ†æ•¸':<12} {'ç¸½é€£ç·šæ•¸':<12} {'ç›®çš„åœ°':<10} {'ç¸½æµé‡(MB)':<15}")
    print(f"{'='*120}")

    for i, anomaly in enumerate(anomalies[:top_n], 1):
        total_mb = anomaly['total_bytes'] / 1024 / 1024
        print(f"{i:<6} "
              f"{anomaly['src_ip']:<17} "
              f"{anomaly['occurrence_count']:<10} "
              f"{anomaly['max_anomaly_score']:< 12.4f} "
              f"{anomaly['avg_anomaly_score']:< 12.4f} "
              f"{anomaly['total_flow_count']:< 12,} "
              f"{anomaly['max_unique_dsts']:< 10} "
              f"{total_mb:< 15.2f}")

    print(f"{'='*120}\n")


def analyze_aggregated_anomalies(anomalies):
    """åˆ†æèšåˆå¾Œçš„ç•°å¸¸æ¨¡å¼"""
    if not anomalies:
        return

    print("ğŸ“Š ç•°å¸¸æ¨¡å¼åˆ†æ\n")

    # çµ±è¨ˆè¡Œç‚ºæ¨¡å¼
    high_conn = sum(1 for a in anomalies if a['features']['is_high_connection'])
    scanning = sum(1 for a in anomalies if a['features']['is_scanning_pattern'])
    small_packet = sum(1 for a in anomalies if a['features']['is_small_packet'])
    large_flow = sum(1 for a in anomalies if a['features']['is_large_flow'])
    persistent = sum(1 for a in anomalies if a['occurrence_count'] >= 3)

    print(f"è¡Œç‚ºçµ±è¨ˆ:")
    print(f"  é«˜é€£ç·šæ•¸: {high_conn} å€‹IP")
    print(f"  æƒææ¨¡å¼: {scanning} å€‹IP")
    print(f"  å°å°åŒ…: {small_packet} å€‹IP")
    print(f"  å¤§æµé‡: {large_flow} å€‹IP")
    print(f"  æŒçºŒç•°å¸¸ (â‰¥3æ¬¡): {persistent} å€‹IP\n")

    # Top ç•°å¸¸è©³ç´°åˆ†æ
    print("ğŸ” Top 5 ç•°å¸¸ IP è©³ç´°åˆ†æ:\n")

    for i, anomaly in enumerate(anomalies[:5], 1):
        print(f"{i}. {anomaly['src_ip']}")
        print(f"   ç•°å¸¸å‡ºç¾: {anomaly['occurrence_count']} æ¬¡")
        print(f"   æ™‚é–“ç¯„åœ: {anomaly['time_buckets'][0]} â†’ {anomaly['time_buckets'][-1]}")
        print(f"   æœ€é«˜ç•°å¸¸åˆ†æ•¸: {anomaly['max_anomaly_score']:.4f}")
        print(f"   å¹³å‡ç•°å¸¸åˆ†æ•¸: {anomaly['avg_anomaly_score']:.4f}")
        print(f"   ç¸½é€£ç·šæ•¸: {anomaly['total_flow_count']:,}")
        print(f"   å¹³å‡æ¯æ¬¡é€£ç·šæ•¸: {anomaly['avg_flow_count']:.0f}")
        print(f"   æœ€å¤§ç›®çš„åœ°æ•¸: {anomaly['max_unique_dsts']}")
        print(f"   ç¸½æµé‡: {anomaly['total_bytes'] / 1024 / 1024:.2f} MB")
        print(f"   å¹³å‡æµé‡/é€£ç·š: {anomaly['avg_bytes']:.0f} bytes")

        # è¡Œç‚ºç‰¹å¾µ
        features = []
        if anomaly['features']['is_high_connection']:
            features.append('é«˜é€£ç·šæ•¸')
        if anomaly['features']['is_scanning_pattern']:
            features.append('æƒææ¨¡å¼')
        if anomaly['features']['is_small_packet']:
            features.append('å°å°åŒ…')
        if anomaly['features']['is_large_flow']:
            features.append('å¤§æµé‡')
        if anomaly['occurrence_count'] >= 3:
            features.append('æŒçºŒç•°å¸¸')

        if features:
            print(f"   è¡Œç‚ºç‰¹å¾µ: {', '.join(features)}")

        print()


def main():
    parser = argparse.ArgumentParser(
        description='å¯¦æ™‚ç•°å¸¸æª¢æ¸¬ - IP èšåˆç‰ˆ'
    )
    parser.add_argument(
        '--minutes',
        type=int,
        default=10,
        help='æª¢æ¸¬æœ€è¿‘ N åˆ†é˜çš„æ•¸æ“šï¼ˆé»˜èª: 10ï¼‰'
    )
    parser.add_argument(
        '--config',
        type=str,
        default='nad/config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾‘'
    )
    parser.add_argument(
        '--top',
        type=int,
        default=20,
        help='é¡¯ç¤ºå‰ N å€‹ç•°å¸¸ IPï¼ˆé»˜èª: 20ï¼‰'
    )
    parser.add_argument(
        '--loop',
        action='store_true',
        help='æŒçºŒé‹è¡Œæª¢æ¸¬'
    )
    parser.add_argument(
        '--interval',
        type=int,
        default=60,
        help='å¾ªç’°æª¢æ¸¬é–“éš”ï¼ˆç§’ï¼Œé»˜èª: 60ï¼‰'
    )

    args = parser.parse_args()

    # åŠ è¼‰é…ç½®
    print("ğŸ“‹ åŠ è¼‰é…ç½®...")
    try:
        config = load_config(args.config)
        print("âœ“ é…ç½®åŠ è¼‰æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è¼‰å¤±æ•—: {e}")
        sys.exit(1)

    # å‰µå»ºæª¢æ¸¬å™¨
    print("ğŸ¤– åŠ è¼‰æ¨¡å‹...")
    detector = OptimizedIsolationForest(config)

    # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
    model_info = detector.get_model_info()
    if model_info['status'] != 'trained':
        print("âŒ æ¨¡å‹å°šæœªè¨“ç·´")
        print("   è«‹å…ˆåŸ·è¡Œ: python3 train_isolation_forest.py --days 7")
        sys.exit(1)

    print("âœ“ æ¨¡å‹åŠ è¼‰æˆåŠŸ\n")
    print("æ¨¡å‹ä¿¡æ¯:")
    print(f"  æ¨¹çš„æ•¸é‡: {model_info['n_estimators']}")
    print(f"  ç‰¹å¾µæ•¸é‡: {model_info['n_features']}")
    print(f"  æ±¡æŸ“ç‡: {model_info['contamination']}\n")

    # åŸ·è¡Œæª¢æ¸¬
    detection_num = 0
    try:
        while True:
            detection_num += 1

            print("=" * 100)
            print(f"å¯¦æ™‚ç•°å¸¸æª¢æ¸¬ï¼ˆIPèšåˆï¼‰ - åˆ†ææœ€è¿‘ {args.minutes} åˆ†é˜")
            print("=" * 100)

            if args.loop:
                print(f"ğŸ” æª¢æ¸¬ #{detection_num} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                print("-" * 100)

            # æª¢æ¸¬ç•°å¸¸
            start_time = time.time()
            raw_anomalies = detector.detect_realtime(minutes=args.minutes)
            elapsed = time.time() - start_time

            print(f"\nâ±ï¸  æª¢æ¸¬è€—æ™‚: {elapsed:.2f} ç§’")

            if raw_anomalies:
                # èšåˆç•°å¸¸
                aggregated_anomalies = aggregate_anomalies_by_ip(raw_anomalies)

                # é¡¯ç¤ºçµæœ
                print_aggregated_anomalies(aggregated_anomalies, args.top)
                analyze_aggregated_anomalies(aggregated_anomalies)
            else:
                print("\nâœ… æœªç™¼ç¾ç•°å¸¸\n")

            # å¦‚æœä¸æ˜¯å¾ªç’°æ¨¡å¼ï¼ŒçµæŸ
            if not args.loop:
                break

            # ç­‰å¾…ä¸‹æ¬¡æª¢æ¸¬
            print(f"â³ {args.interval} ç§’å¾ŒåŸ·è¡Œä¸‹æ¬¡æª¢æ¸¬...\n")
            time.sleep(args.interval)

    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æª¢æ¸¬å·²åœæ­¢")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ æª¢æ¸¬å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
