#!/usr/bin/env python3
"""
æ¸¬è©¦é€²éšåŠŸèƒ½

æ¸¬è©¦å…§å®¹ï¼š
1. å››ç¨®é€²éš Pattern è­˜åˆ¥
   - SINGLE_TARGET_PATTERN (å‚ç›´æƒæ)
   - BROADCAST_PATTERN (æ°´å¹³æƒæ)
   - REVERSE_SCAN_PATTERN (ç›®æ¨™è¢«æƒæ)
   - MICROSERVICE_PATTERN (å¾®æœå‹™æ¶æ§‹)

2. Baseline é©—è­‰æ©Ÿåˆ¶
   - å­¸ç¿’ IP è¡Œç‚ºåŸºæº–ç·š
   - åµæ¸¬è¡Œç‚ºåé›¢
   - è¨ˆç®—åé›¢åš´é‡ç¨‹åº¦
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from nad.ml.bidirectional_analyzer import BidirectionalAnalyzer
from nad.ml.baseline_manager import BaselineManager
from nad.ml.post_processor import AnomalyPostProcessor
from nad.ml.isolation_forest_detector import OptimizedIsolationForest
from nad.ml.anomaly_classifier import AnomalyClassifier


def test_pattern_recognition():
    """æ¸¬è©¦å››ç¨® Pattern è­˜åˆ¥"""
    print("=" * 70)
    print("æ¸¬è©¦ 1: å››ç¨®é€²éš Pattern è­˜åˆ¥")
    print("=" * 70)

    analyzer = BidirectionalAnalyzer()

    # å¾æœ€è¿‘çš„ç•°å¸¸ä¸­é¸æ“‡å¹¾å€‹æ¸¬è©¦æ¨£æœ¬
    print("\næ­£åœ¨å¾å¯¦æ™‚æ•¸æ“šä¸­æ¸¬è©¦ pattern è­˜åˆ¥...")

    # ç²å–æœ€è¿‘çš„ç•°å¸¸æ•¸æ“š
    detector = OptimizedIsolationForest()
    try:
        detector._load_model()
    except FileNotFoundError:
        print("\nâš ï¸  Isolation Forest æ¨¡å‹æœªæ‰¾åˆ°")
        print("è«‹å…ˆè¨“ç·´æ¨¡å‹: python3 train_isolation_forest.py")
        return

    anomalies = detector.predict_realtime(recent_minutes=30)

    if not anomalies:
        print("\næœªç™¼ç¾ç•°å¸¸ï¼Œç„¡æ³•æ¸¬è©¦ pattern è­˜åˆ¥")
        return

    print(f"\nç™¼ç¾ {len(anomalies)} å€‹ç•°å¸¸ï¼Œæ¸¬è©¦å‰ 5 å€‹...")
    print()

    pattern_counts = {
        'SINGLE_TARGET_PATTERN': 0,
        'BROADCAST_PATTERN': 0,
        'REVERSE_SCAN_PATTERN': 0,
        'MICROSERVICE_PATTERN': 0,
        'LOAD_BALANCER': 0,
        'OTHER': 0
    }

    for i, anomaly in enumerate(anomalies[:5], 1):
        src_ip = anomaly['src_ip']

        print(f"{i}. æ¸¬è©¦ {src_ip}")
        print(f"   - unique_dsts: {anomaly.get('unique_dsts', 0)}")
        print(f"   - unique_dst_ports: {anomaly.get('unique_dst_ports', 0)}")
        print(f"   - flow_count: {anomaly.get('flow_count', 0)}")
        print(f"   - avg_bytes: {anomaly.get('avg_bytes', 0):.0f}")

        # ä½¿ç”¨æ”¹é€²çš„ pattern è­˜åˆ¥
        result = analyzer.detect_port_scan_improved(src_ip, time_range="now-30m")

        pattern = result.get('pattern', 'UNKNOWN')
        is_scan = result.get('is_port_scan', False)

        print(f"   >>> Pattern: {pattern}")
        print(f"   >>> Is Scan: {is_scan}")
        print(f"   >>> Confidence: {result.get('confidence', 0):.0%}")

        if 'indicators' in result:
            for indicator in result['indicators']:
                print(f"       - {indicator}")

        pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1
        print()

    # çµ±è¨ˆçµæœ
    print("Pattern è­˜åˆ¥çµ±è¨ˆ:")
    for pattern, count in pattern_counts.items():
        if count > 0:
            print(f"  - {pattern}: {count}")
    print()


def test_baseline_verification():
    """æ¸¬è©¦ Baseline é©—è­‰æ©Ÿåˆ¶"""
    print("=" * 70)
    print("æ¸¬è©¦ 2: Baseline é©—è­‰æ©Ÿåˆ¶")
    print("=" * 70)

    manager = BaselineManager(learning_days=7)

    # é¸æ“‡å¹¾å€‹å¸¸è¦‹çš„ IP é€²è¡Œæ¸¬è©¦
    test_ips = ['192.168.10.135', '192.168.10.100', '192.168.10.50']

    print(f"\nå­¸ç¿’ {len(test_ips)} å€‹ IP çš„è¡Œç‚ºåŸºæº–ç·šï¼ˆéå» 7 å¤©ï¼‰...")
    print()

    baselines_learned = 0
    for test_ip in test_ips:
        print(f"å­¸ç¿’ {test_ip}...")
        baseline = manager.learn_baseline(test_ip)

        if baseline:
            baselines_learned += 1
            print(f"  âœ“ åŸºæº–ç·šå­¸ç¿’æˆåŠŸ")
            print(f"    - æ¨£æœ¬æ•¸: {baseline['sample_count']}")
            print(f"    - unique_dst_ports (å¹³å‡): {baseline['unique_dst_ports']['mean']:.1f}")
            print(f"    - unique_dst_ports (æœ€å¤§): {baseline['unique_dst_ports']['max']:.0f}")
            print(f"    - unique_dsts (å¹³å‡): {baseline['unique_dsts']['mean']:.1f}")
        else:
            print(f"  âœ— æ­·å²æ•¸æ“šä¸è¶³")
        print()

    if baselines_learned == 0:
        print("æ‰€æœ‰ IP çš„æ­·å²æ•¸æ“šéƒ½ä¸è¶³ï¼Œç„¡æ³•æ¸¬è©¦åé›¢åµæ¸¬")
        return

    # ä½¿ç”¨å¯¦æ™‚æ•¸æ“šæ¸¬è©¦åé›¢åµæ¸¬
    print("=" * 70)
    print("æ¸¬è©¦åé›¢åµæ¸¬ï¼ˆä½¿ç”¨å¯¦æ™‚ç•°å¸¸æ•¸æ“šï¼‰")
    print("=" * 70)
    print()

    detector = OptimizedIsolationForest()
    anomalies = detector.predict_realtime(recent_minutes=30)

    if not anomalies:
        print("æœªç™¼ç¾ç•°å¸¸ï¼Œç„¡æ³•æ¸¬è©¦åé›¢åµæ¸¬")
        return

    deviation_count = 0
    for anomaly in anomalies[:5]:
        src_ip = anomaly['src_ip']
        features = anomaly['features']

        current_data = {
            'unique_dst_ports': features.get('unique_dst_ports', 0),
            'unique_dsts': features.get('unique_dsts', 0),
            'flow_count': features.get('flow_count', 0),
            'avg_bytes': features.get('avg_bytes', 0),
            'total_bytes': features.get('total_bytes', 0)
        }

        print(f"æª¢æŸ¥ {src_ip} çš„è¡Œç‚ºåé›¢...")
        result = manager.check_deviation(src_ip, current_data)

        if result['has_deviation']:
            deviation_count += 1
            print(f"  âš ï¸  åµæ¸¬åˆ°è¡Œç‚ºåé›¢ï¼")
            print(f"  åš´é‡ç¨‹åº¦: {result['severity']}")

            for metric_name, deviation in result['deviations'].items():
                print(f"  - {metric_name}:")
                print(f"    ç•¶å‰: {deviation['current_value']:.0f}")
                print(f"    åŸºæº–å¹³å‡: {deviation['baseline_mean']:.0f}")
                print(f"    åŸºæº–æœ€å¤§: {deviation['baseline_max']:.0f}")
                print(f"    Z-score: {deviation['z_score']:.2f}")
        else:
            print(f"  âœ“ è¡Œç‚ºæ­£å¸¸")
        print()

    print(f"åé›¢çµ±è¨ˆ: {deviation_count}/{min(5, len(anomalies))} å€‹ç•°å¸¸åµæ¸¬åˆ°åŸºæº–ç·šåé›¢")
    print()


def test_integrated_detection_with_baseline():
    """æ¸¬è©¦æ•´åˆçš„åµæ¸¬ç³»çµ±ï¼ˆåŒ…å« Baselineï¼‰"""
    print("=" * 70)
    print("æ¸¬è©¦ 3: æ•´åˆåµæ¸¬ç³»çµ±ï¼ˆPattern + Baselineï¼‰")
    print("=" * 70)

    # åˆå§‹åŒ–çµ„ä»¶
    detector = OptimizedIsolationForest()
    classifier = AnomalyClassifier()
    post_processor = AnomalyPostProcessor(enable_baseline=True, baseline_learning_days=7)

    # åŠ è¼‰æ¨¡å‹
    try:
        detector._load_model()
    except FileNotFoundError:
        print("\nâš ï¸  Isolation Forest æ¨¡å‹æœªæ‰¾åˆ°")
        return

    # Step 1: Isolation Forest åµæ¸¬
    print("\nStep 1: Isolation Forest åµæ¸¬ï¼ˆæœ€è¿‘ 30 åˆ†é˜ï¼‰...")
    anomalies = detector.predict_realtime(recent_minutes=30)
    print(f"âœ“ åµæ¸¬åˆ° {len(anomalies)} å€‹ç•°å¸¸")

    if not anomalies:
        print("æœªç™¼ç¾ç•°å¸¸ï¼Œæ¸¬è©¦çµæŸ")
        return

    # Step 2: åˆ†é¡
    print("\nStep 2: å¨è„…åˆ†é¡...")
    classified = []
    for anomaly in anomalies:
        classification = classifier.classify(
            features=anomaly['features'],
            context={'src_ip': anomaly['src_ip']}
        )
        classified.append({**anomaly, 'classification': classification})

    class_counts = {}
    for a in classified:
        c = a['classification']['class']
        class_counts[c] = class_counts.get(c, 0) + 1

    print(f"âœ“ åˆ†é¡çµæœ:")
    for threat_class, count in class_counts.items():
        print(f"  - {threat_class}: {count}")

    # Step 3: å¾Œè™•ç†é©—è­‰ï¼ˆåŒ…å« Pattern è­˜åˆ¥ + Baseline é©—è­‰ï¼‰
    print("\nStep 3: å¾Œè™•ç†é©—è­‰ï¼ˆPattern + Baselineï¼‰...")
    result = post_processor.validate_anomalies(classified, time_range="now-30m")

    validated = result['validated']
    false_positives = result['false_positives']

    print(f"âœ“ é©—è­‰çµæœ:")
    print(f"  - çœŸå¯¦ç•°å¸¸: {len(validated)}")
    print(f"  - èª¤å ±: {len(false_positives)}")
    print(f"  - åŸºæº–ç·šåé›¢: {post_processor.stats.get('baseline_deviations', 0)}")

    # é¡¯ç¤ºè©³ç´°å ±å‘Š
    print("\n" + "=" * 70)
    print("è©³ç´°å ±å‘Š")
    print("=" * 70)

    if validated:
        print("\nçœŸå¯¦ç•°å¸¸ï¼ˆå‰ 3 å€‹ï¼‰:")
        for i, v in enumerate(validated[:3], 1):
            print(f"\n{i}. {v['src_ip']}")
            print(f"   å¨è„…é¡åˆ¥: {v['classification']['class']}")
            print(f"   Pattern: {v.get('verification_details', {}).get('pattern', 'Unknown')}")

            # é¡¯ç¤ºåŸºæº–ç·šåé›¢
            if 'baseline_deviation' in v:
                baseline_dev = v['baseline_deviation']
                if baseline_dev.get('has_deviation'):
                    print(f"   åŸºæº–ç·šåé›¢: {baseline_dev['severity']}")
                    print(f"   åé›¢æŒ‡æ¨™: {', '.join(baseline_dev['deviations'].keys())}")

    if false_positives:
        print("\nèª¤å ±ï¼ˆå‰ 3 å€‹ï¼‰:")
        for i, fp in enumerate(false_positives[:3], 1):
            print(f"\n{i}. {fp['src_ip']}")
            print(f"   ML åˆ¤æ–·: {fp['classification']['class']}")
            print(f"   èª¤å ±åŸå› : {fp['false_positive_reason']}")

    print("\n" + "=" * 70)


def main():
    """ä¸»æ¸¬è©¦æµç¨‹"""
    print("\n" + "ğŸ§ª " * 25)
    print("é€²éšåŠŸèƒ½æ¸¬è©¦")
    print("ğŸ§ª " * 25 + "\n")

    # æ¸¬è©¦ 1: Pattern è­˜åˆ¥
    test_pattern_recognition()

    # æ¸¬è©¦ 2: Baseline é©—è­‰
    test_baseline_verification()

    # æ¸¬è©¦ 3: æ•´åˆåµæ¸¬
    test_integrated_detection_with_baseline()

    print("\n" + "=" * 70)
    print("æ‰€æœ‰æ¸¬è©¦å®Œæˆ")
    print("=" * 70)


if __name__ == "__main__":
    main()
