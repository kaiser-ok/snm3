#!/usr/bin/env python3
"""
IP è¦†è“‹ç‡é©—è­‰å·¥å…·

æ¯”è¼ƒåŸå§‹ç´¢å¼•å’Œèšåˆç´¢å¼•çš„å”¯ä¸€ IP æ•¸é‡ï¼Œç¢ºä¿ Transform æ²’æœ‰éºæ¼æ•¸æ“š
"""

import requests
import json
from datetime import datetime

ES_HOST = "http://localhost:9200"

def verify_coverage(hours=1):
    """é©—è­‰èšåˆæ•¸æ“šçš„ IP è¦†è“‹ç‡"""

    print("=" * 60)
    print("IP è¦†è“‹ç‡é©—è­‰")
    print("=" * 60)
    print(f"åˆ†ææ™‚é–“ç¯„åœ: éå» {hours} å°æ™‚\n")

    # 1. æŸ¥è©¢åŸå§‹æ•¸æ“šçš„å”¯ä¸€ IP æ•¸
    print("ğŸ” æŸ¥è©¢åŸå§‹ç´¢å¼• (radar_flow_collector-*)...")
    raw_query = {
        "size": 0,
        "query": {
            "range": {
                "FLOW_START_MILLISECONDS": {
                    "gte": f"now-{hours}h"
                }
            }
        },
        "aggs": {
            "unique_ips": {
                "cardinality": {
                    "field": "IPV4_SRC_ADDR",
                    "precision_threshold": 10000
                }
            },
            "total_docs": {
                "value_count": {
                    "field": "IPV4_SRC_ADDR"
                }
            }
        }
    }

    try:
        resp1 = requests.post(
            f"{ES_HOST}/radar_flow_collector-*/_search",
            json=raw_query,
            headers={'Content-Type': 'application/json'}
        )
        resp1.raise_for_status()
        raw_data = resp1.json()

        raw_unique_ips = raw_data['aggregations']['unique_ips']['value']
        raw_total_docs = raw_data['aggregations']['total_docs']['value']

        print(f"âœ“ åŸå§‹ç´¢å¼•å”¯ä¸€ IP æ•¸: {raw_unique_ips:,}")
        print(f"âœ“ åŸå§‹ç´¢å¼•ç¸½æ–‡æª”æ•¸: {raw_total_docs:,}\n")

    except Exception as e:
        print(f"âŒ æŸ¥è©¢åŸå§‹ç´¢å¼•å¤±æ•—: {e}")
        return

    # 2. æŸ¥è©¢èšåˆæ•¸æ“šçš„å”¯ä¸€ IP æ•¸
    print("ğŸ” æŸ¥è©¢èšåˆç´¢å¼• (netflow_stats_5m)...")
    agg_query = {
        "size": 0,
        "query": {
            "range": {
                "time_bucket": {
                    "gte": f"now-{hours}h"
                }
            }
        },
        "aggs": {
            "unique_ips": {
                "cardinality": {
                    "field": "src_ip",
                    "precision_threshold": 10000
                }
            },
            "total_docs": {
                "value_count": {
                    "field": "src_ip"
                }
            }
        }
    }

    try:
        resp2 = requests.post(
            f"{ES_HOST}/netflow_stats_5m/_search",
            json=agg_query,
            headers={'Content-Type': 'application/json'}
        )
        resp2.raise_for_status()
        agg_data = resp2.json()

        agg_unique_ips = agg_data['aggregations']['unique_ips']['value']
        agg_total_docs = agg_data['aggregations']['total_docs']['value']

        print(f"âœ“ èšåˆç´¢å¼•å”¯ä¸€ IP æ•¸: {agg_unique_ips:,}")
        print(f"âœ“ èšåˆç´¢å¼•ç¸½æ–‡æª”æ•¸: {agg_total_docs:,}\n")

    except Exception as e:
        print(f"âŒ æŸ¥è©¢èšåˆç´¢å¼•å¤±æ•—: {e}")
        return

    # 3. è¨ˆç®—è¦†è“‹ç‡
    print("=" * 60)
    print("è¦†è“‹ç‡åˆ†æ")
    print("=" * 60)

    if raw_unique_ips > 0:
        coverage_rate = (agg_unique_ips / raw_unique_ips) * 100

        print(f"åŸå§‹æ•¸æ“šå”¯ä¸€ IP:   {raw_unique_ips:>8,}")
        print(f"èšåˆæ•¸æ“šå”¯ä¸€ IP:   {agg_unique_ips:>8,}")
        print(f"è¦†è“‹ç‡:            {coverage_rate:>7.1f}%")
        print()

        # æ•¸æ“šå£“ç¸®ç‡
        if raw_total_docs > 0:
            compression_rate = (1 - agg_total_docs / raw_total_docs) * 100
            print(f"æ•¸æ“šå£“ç¸®ç‡:        {compression_rate:>7.1f}%")
            print(f"(å¾ {raw_total_docs:,} ç­†å£“ç¸®åˆ° {agg_total_docs:,} ç­†)")
            print()

        # è©•ä¼°çµæœ
        print("=" * 60)
        print("è©•ä¼°çµæœ")
        print("=" * 60)

        if coverage_rate >= 99:
            print("âœ… è¦†è“‹ç‡å„ªç§€ (â‰¥99%)")
            print("   Transform æ­£ç¢ºè™•ç†äº†å¹¾ä¹æ‰€æœ‰ IP")
        elif coverage_rate >= 95:
            print("âœ… è¦†è“‹ç‡è‰¯å¥½ (95-99%)")
            print("   Transform è™•ç†äº†çµ•å¤§éƒ¨åˆ† IPï¼Œç•¥æœ‰éºæ¼å±¬æ­£å¸¸")
        elif coverage_rate >= 90:
            print("âš ï¸  è¦†è“‹ç‡å¯æ¥å— (90-95%)")
            print("   æœ‰å°‘é‡ IP æœªè¢«è¨˜éŒ„ï¼Œå¯èƒ½éœ€è¦æª¢æŸ¥é…ç½®")
        else:
            print("ğŸ”´ è¦†è“‹ç‡ä¸è¶³ (<90%)")
            print("   å¤§é‡ IP æœªè¢«è¨˜éŒ„ï¼Œéœ€è¦èª¿æ•´ Transform é…ç½®")
            print("   å»ºè­°æª¢æŸ¥:")
            print("   - max_page_search_size æ˜¯å¦è¶³å¤ ")
            print("   - Transform æ˜¯å¦æ­£å¸¸é‹è¡Œ")
            print("   - æŸ¥è©¢æ™‚é–“ç¯„åœæ˜¯å¦æ­£ç¢º")

        # å¦‚æœè¦†è“‹ç‡ä¸æ˜¯ 100%ï¼Œåˆ†æå¯èƒ½åŸå› 
        if coverage_rate < 100:
            missing_ips = raw_unique_ips - agg_unique_ips
            print(f"\nğŸ“Š éºæ¼ IP æ•¸é‡: {missing_ips:,} å€‹")

            if missing_ips < 10:
                print("   å¯èƒ½åŸå› : cardinality èšåˆçš„è¿‘ä¼¼èª¤å·®")
            elif missing_ips < 100:
                print("   å¯èƒ½åŸå› : Transform å°šæœªå®Œå…¨åŒæ­¥æœ€æ–°æ•¸æ“š")
            else:
                print("   å¯èƒ½åŸå› : Transform é…ç½®å•é¡Œæˆ–è™•ç†é™åˆ¶")
    else:
        print("âŒ åŸå§‹æ•¸æ“šä¸­æ²’æœ‰ IPï¼Œç„¡æ³•è¨ˆç®—è¦†è“‹ç‡")

    print("=" * 60)


def check_transform_status():
    """æª¢æŸ¥ Transform ç‹€æ…‹"""
    print("\n" + "=" * 60)
    print("Transform ç‹€æ…‹æª¢æŸ¥")
    print("=" * 60)

    try:
        resp = requests.get(
            f"{ES_HOST}/_transform/netflow_production/_stats",
            headers={'Content-Type': 'application/json'}
        )
        resp.raise_for_status()
        stats = resp.json()

        if 'transforms' in stats and len(stats['transforms']) > 0:
            t = stats['transforms'][0]
            state = t['state']

            print(f"Transform ID: netflow_production")
            print(f"ç‹€æ…‹: {state}")

            if 'stats' in t:
                s = t['stats']
                print(f"å·²è™•ç†æ–‡æª”: {s.get('documents_processed', 0):,}")
                print(f"å·²ç´¢å¼•æ–‡æª”: {s.get('documents_indexed', 0):,}")
                print(f"è§¸ç™¼æ¬¡æ•¸: {s.get('trigger_count', 0):,}")

                if 'checkpointing' in t:
                    cp = t['checkpointing']
                    if 'last' in cp:
                        last_checkpoint = cp['last'].get('checkpoint', 0)
                        print(f"æœ€å¾Œæª¢æŸ¥é»: {last_checkpoint}")

            if state != 'started':
                print(f"\nâš ï¸  Transform æœªåœ¨é‹è¡Œç‹€æ…‹ (ç•¶å‰: {state})")
                print("   é€™å¯èƒ½å½±éŸ¿æ•¸æ“šåŒæ­¥")
        else:
            print("âŒ æœªæ‰¾åˆ° Transform: netflow_production")

    except Exception as e:
        print(f"âŒ æŸ¥è©¢ Transform ç‹€æ…‹å¤±æ•—: {e}")

    print("=" * 60)


if __name__ == "__main__":
    # æª¢æŸ¥ Transform ç‹€æ…‹
    check_transform_status()

    # é©—è­‰è¦†è“‹ç‡
    print("\n")
    verify_coverage(hours=1)

    print("\nğŸ’¡ å»ºè­°:")
    print("   - å¦‚æœè¦†è“‹ç‡ â‰¥95%ï¼Œç•¶å‰é…ç½®è‰¯å¥½")
    print("   - å¦‚æœè¦†è“‹ç‡ <90%ï¼Œè€ƒæ…®å¢åŠ  max_page_search_size")
    print("   - å®šæœŸåŸ·è¡Œæ­¤è…³æœ¬ä»¥ç›£æ§æ•¸æ“šå“è³ª")
    print()
