#!/usr/bin/env python3
"""
ç•°å¸¸é©—è­‰åˆ†æå·¥å…·

æ·±å…¥åˆ†æ Isolation Forest æª¢æ¸¬å‡ºçš„ç•°å¸¸ IPï¼Œ
æŸ¥è©¢åŸå§‹ netflow æ•¸æ“šï¼Œåˆ¤æ–·æ˜¯å¦ç‚ºçœŸæ­£çš„ç•°å¸¸è¡Œç‚ºã€‚
"""

import sys
import json
import math
import argparse
import warnings
from datetime import datetime, timedelta
from collections import Counter, defaultdict
from elasticsearch import Elasticsearch
from nad.utils.config_loader import load_config

# é—œé–‰ Elasticsearch å®‰å…¨è­¦å‘Š
warnings.filterwarnings('ignore', message='.*Elasticsearch built-in security features are not enabled.*')

# MySQL æ”¯æ´ï¼ˆå¯é¸ï¼‰
try:
    import pymysql
    MYSQL_AVAILABLE = True
except ImportError:
    MYSQL_AVAILABLE = False


class AnomalyVerifier:
    """ç•°å¸¸é©—è­‰å™¨"""

    # è‡¨æ™‚åŸ èµ·å§‹é» (Linux é è¨­ 32768, ä½¿ç”¨ 32000 è¼ƒå¯¬é¬†)
    EPHEMERAL_PORT_START = 32000

    # è§’è‰²ç‰¹å¾µåº« (Signature Library)
    # æ ¼å¼: 'ROLE_NAME': {'ports': set, 'threshold': float, 'desc': str, 'category': str}
    ROLE_SIGNATURES = {
        'DNS_SERVER': {
            'ports': {53},
            'threshold': 0.5,  # æµé‡ä¸­è¶…é 50% æ˜¯æ­¤åŸ å³å‘½ä¸­
            'desc': 'DNS è§£æä¼ºæœå™¨',
            'category': 'infrastructure'
        },
        'WEB_SERVER': {
            'ports': {80, 443, 8080, 8443},
            'threshold': 0.6,
            'desc': 'Web ç¶²é ä¼ºæœå™¨',
            'category': 'service'
        },
        'AD_CONTROLLER': {
            'ports': {88, 389, 636, 445, 3268, 3269},
            'threshold': 0.3,  # AD æ¯”è¼ƒåš´æ ¼ï¼Œé€šå¸¸éœ€è¦å‘½ä¸­å¤šå€‹æ ¸å¿ƒåŸ 
            'desc': 'Windows AD ç¶²åŸŸæ§åˆ¶ç«™',
            'category': 'infrastructure',
            'core_ports': {88, 389, 53}  # æ ¸å¿ƒè­˜åˆ¥åŸ ï¼ˆéœ€é¡å¤–é©—è­‰ï¼‰
        },
        'FILE_SERVER': {
            'ports': {445, 139, 2049},
            'threshold': 0.7,
            'desc': 'SMB/NFS æª”æ¡ˆä¼ºæœå™¨',
            'category': 'service'
        },
        'DB_SERVER': {
            'ports': {3306, 5432, 1433, 1521, 27017, 6379},
            'threshold': 0.6,
            'desc': 'è³‡æ–™åº«ä¼ºæœå™¨',
            'category': 'service'
        },
        'MAIL_SERVER': {
            'ports': {25, 110, 143, 993, 995, 587},
            'threshold': 0.4,
            'desc': 'éƒµä»¶ä¼ºæœå™¨',
            'category': 'service'
        },
        'NTP_SERVER': {
            'ports': {123},
            'threshold': 0.6,
            'desc': 'NTP æ™‚é–“ä¼ºæœå™¨',
            'category': 'infrastructure'
        },
        'MONITORING_SYSTEM': {
            'ports': {161, 162, 9090, 9100, 10050, 10051},
            'threshold': 0.4,
            'desc': 'ç›£æ§ç³»çµ±/Agent',
            'category': 'management'
        },
        'PROXY_SERVER': {
            'ports': {3128, 8080, 8888},
            'threshold': 0.5,
            'desc': 'Proxy ä»£ç†ä¼ºæœå™¨',
            'category': 'service'
        },
        'LDAP_SERVER': {
            'ports': {389, 636},
            'threshold': 0.7,
            'desc': 'LDAP ç›®éŒ„æœå‹™',
            'category': 'infrastructure'
        }
    }

    def __init__(self, es_client, config):
        self.es = es_client
        self.config = config
        self.netflow_index = config.get('elasticsearch', {}).get('indices', {}).get('raw', 'radar_flow_collector-*')

        # åˆå§‹åŒ– MySQL é€£ç·šï¼ˆå¯é¸ï¼‰
        self.mysql_conn = None
        self.mysql_connected = False  # MySQL é€£ç·šç‹€æ…‹
        self.ip_name_cache = {}  # IP åç¨±å¿«å–
        self._init_mysql_connection()

    def _init_mysql_connection(self):
        """åˆå§‹åŒ– MySQL é€£ç·šï¼ˆå¦‚æœå¯ç”¨ä¸”é…ç½®æ­£ç¢ºï¼‰"""
        if not MYSQL_AVAILABLE:
            self.mysql_connected = False
            return

        mysql_config = self.config.get('mysql', {})
        if not mysql_config:
            self.mysql_connected = False
            return

        try:
            self.mysql_conn = pymysql.connect(
                host=mysql_config.get('host', 'localhost'),
                port=mysql_config.get('port', 3306),
                user=mysql_config.get('user'),
                password=mysql_config.get('password'),
                database=mysql_config.get('database'),
                connect_timeout=3
            )
            # æ¸¬è©¦é€£ç·š
            with self.mysql_conn.cursor() as cursor:
                cursor.execute("SELECT 1")
            self.mysql_connected = True
        except Exception as e:
            # é€£ç·šå¤±æ•—æ™‚éœé»˜è™•ç†ï¼Œä¸å½±éŸ¿ä¸»è¦åŠŸèƒ½
            self.mysql_conn = None
            self.mysql_connected = False

    def _get_ip_name(self, ip):
        """
        å¾ MySQL æŸ¥è©¢ IP å°æ‡‰çš„è¨­å‚™åç¨±

        Args:
            ip: IP åœ°å€

        Returns:
            è¨­å‚™åç¨±ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› None
        """
        # æª¢æŸ¥å¿«å–
        if ip in self.ip_name_cache:
            return self.ip_name_cache[ip]

        # å¦‚æœ MySQL ä¸å¯ç”¨ï¼Œç›´æ¥è¿”å›
        if not self.mysql_conn:
            self.ip_name_cache[ip] = None
            return None

        try:
            with self.mysql_conn.cursor() as cursor:
                # å…ˆæŸ¥è©¢ Device è¡¨
                cursor.execute(
                    "SELECT Name FROM Device WHERE IP = %s LIMIT 1",
                    (ip,)
                )
                result = cursor.fetchone()
                if result and result[0]:
                    name = result[0].strip()
                    self.ip_name_cache[ip] = name
                    return name

                # å†æŸ¥è©¢ ip_alias è¡¨
                cursor.execute(
                    "SELECT alias FROM ip_alias WHERE ip = %s LIMIT 1",
                    (ip,)
                )
                result = cursor.fetchone()
                if result and result[0]:
                    name = result[0].strip()
                    self.ip_name_cache[ip] = name
                    return name

            # æ²’æ‰¾åˆ°
            self.ip_name_cache[ip] = None
            return None

        except Exception:
            # æŸ¥è©¢å¤±æ•—æ™‚éœé»˜è™•ç†
            self.ip_name_cache[ip] = None
            return None

    def _format_ip_with_name(self, ip):
        """
        æ ¼å¼åŒ– IP é¡¯ç¤ºï¼ˆå¦‚æœæœ‰è¨­å‚™åç¨±å‰‡é™„åŠ ï¼‰

        Args:
            ip: IP åœ°å€

        Returns:
            æ ¼å¼åŒ–çš„å­—ä¸²ï¼Œä¾‹å¦‚ "192.168.1.1 (Web Server)"
        """
        name = self._get_ip_name(ip)
        if name:
            return f"{ip} ({name})"
        return ip

    def verify_ip(self, src_ip, time_range_minutes=30):
        """
        æ·±å…¥åˆ†æå–®å€‹ç•°å¸¸ IPï¼ˆé›™å‘å®Œæ•´åˆ†æï¼‰

        Args:
            src_ip: è¦åˆ†æçš„ IP åœ°å€
            time_range_minutes: åˆ†ææ™‚é–“ç¯„åœï¼ˆåˆ†é˜ï¼‰

        Returns:
            åˆ†æå ±å‘Šå­—å…¸ï¼ˆåŒ…å«é›™å‘åˆ†æçµæœï¼‰
        """
        print(f"\n{'='*100}")
        print(f"ğŸ” æ·±å…¥åˆ†æ: {src_ip}")
        print(f"{'='*100}\n")

        # æŸ¥è©¢ä½œç‚ºæº IP çš„æµé‡
        flows_as_src = self._fetch_netflow_data(src_ip, time_range_minutes, role='src')
        # æŸ¥è©¢ä½œç‚ºç›®çš„åœ°çš„æµé‡
        flows_as_dst = self._fetch_netflow_data(src_ip, time_range_minutes, role='dst')

        print(f"ğŸ“Š ä½œç‚ºæº IP: {len(flows_as_src):,} ç­†è¨˜éŒ„")
        print(f"ğŸ“Š ä½œç‚ºç›®çš„åœ°: {len(flows_as_dst):,} ç­†è¨˜éŒ„\n")

        if not flows_as_src and not flows_as_dst:
            print(f"âš ï¸  æ²’æœ‰æ‰¾åˆ° {src_ip} çš„ netflow æ•¸æ“š")
            return None

        # é›™å‘åˆ†æï¼šåˆ†æå…©å€‹æ–¹å‘
        analysis_result = {
            'target_ip': src_ip,
            'time_range_minutes': time_range_minutes,
            'as_source': None,
            'as_destination': None,
        }

        # åˆ†æä½œç‚ºæº IP çš„æƒ…æ³
        if flows_as_src:
            print(f"ğŸ“Š åˆ†æä½œç‚ºæº IP çš„ {len(flows_as_src):,} ç­†è¨˜éŒ„...\n")
            analysis_result['as_source'] = {
                'role': 'src',
                'total_flows': len(flows_as_src),
                'basic_stats': self._analyze_basic_stats(flows_as_src),
                'destination_analysis': self._analyze_destinations(flows_as_src, 'src'),
                'port_analysis': self._analyze_ports(flows_as_src, 'src'),
                'protocol_analysis': self._analyze_protocols(flows_as_src),
                'temporal_analysis': self._analyze_temporal_pattern(flows_as_src),
                'traffic_analysis': self._analyze_traffic_pattern(flows_as_src),
                'behavioral_analysis': self._analyze_behavior(flows_as_src, 'src'),
            }

        # åˆ†æä½œç‚ºç›®çš„åœ° IP çš„æƒ…æ³
        if flows_as_dst:
            print(f"ğŸ“Š åˆ†æä½œç‚ºç›®çš„åœ° IP çš„ {len(flows_as_dst):,} ç­†è¨˜éŒ„...\n")
            analysis_result['as_destination'] = {
                'role': 'dst',
                'total_flows': len(flows_as_dst),
                'basic_stats': self._analyze_basic_stats(flows_as_dst),
                'destination_analysis': self._analyze_destinations(flows_as_dst, 'dst'),
                'port_analysis': self._analyze_ports(flows_as_dst, 'dst'),
                'protocol_analysis': self._analyze_protocols(flows_as_dst),
                'temporal_analysis': self._analyze_temporal_pattern(flows_as_dst),
                'traffic_analysis': self._analyze_traffic_pattern(flows_as_dst),
                'behavioral_analysis': self._analyze_behavior(flows_as_dst, 'dst'),
            }

        # ç”Ÿæˆç¶œåˆåˆ¤æ–·
        analysis_result['verdict'] = self._generate_bidirectional_verdict(analysis_result)

        # é¡¯ç¤ºé›™å‘å ±å‘Š
        self._print_bidirectional_report(analysis_result)

        return analysis_result

    def _fetch_netflow_data(self, ip, minutes, role='src'):
        """
        æŸ¥è©¢åŸå§‹ netflow æ•¸æ“šï¼ˆä½¿ç”¨ scroll API ç²å–æ‰€æœ‰è¨˜éŒ„ï¼‰

        Args:
            ip: IP åœ°å€
            minutes: æ™‚é–“ç¯„åœï¼ˆåˆ†é˜ï¼‰
            role: 'src' æˆ– 'dst'ï¼ŒæŒ‡å®šæŸ¥è©¢æº IP é‚„æ˜¯ç›®çš„ IP
        """
        # æ”¯æŒ IPv4 å’Œ IPv6
        if role == 'src':
            query = {
                "size": 10000,  # æ¯æ‰¹æ¬¡å– 10000 ç­†
                "query": {
                    "bool": {
                        "should": [
                            {"term": {"IPV4_SRC_ADDR": ip}},
                            {"term": {"IPV6_SRC_ADDR": ip}},
                        ],
                        "minimum_should_match": 1,
                        "filter": [
                            {"range": {"FLOW_START_MILLISECONDS": {
                                "gte": f"now-{minutes}m",
                                "lte": "now+1m"  # é¿å…æœªä¾†æ™‚é–“æˆ³ï¼ˆ2106å¹´çš„éŒ¯èª¤æ•¸æ“šï¼‰
                            }}}
                        ]
                    }
                },
                "sort": [{"FLOW_START_MILLISECONDS": "desc"}]
            }
        else:  # dst
            query = {
                "size": 10000,
                "query": {
                    "bool": {
                        "should": [
                            {"term": {"IPV4_DST_ADDR": ip}},
                            {"term": {"IPV6_DST_ADDR": ip}},
                        ],
                        "minimum_should_match": 1,
                        "filter": [
                            {"range": {"FLOW_START_MILLISECONDS": {
                                "gte": f"now-{minutes}m",
                                "lte": "now+1m"  # é¿å…æœªä¾†æ™‚é–“æˆ³
                            }}}
                        ]
                    }
                },
                "sort": [{"FLOW_START_MILLISECONDS": "desc"}]
            }

        try:
            # ä½¿ç”¨ scroll API ç²å–æ‰€æœ‰æ•¸æ“š
            flows_raw = []

            # åˆå§‹æŸ¥è©¢
            response = self.es.search(index=self.netflow_index, scroll='5m', **query)
            scroll_id = response.get('_scroll_id')
            hits = response['hits']['hits']
            flows_raw.extend([hit['_source'] for hit in hits])

            # ç¹¼çºŒæ»¾å‹•ç²å–
            while len(hits) > 0:
                response = self.es.scroll(scroll_id=scroll_id, scroll='5m')
                scroll_id = response.get('_scroll_id')
                hits = response['hits']['hits']
                flows_raw.extend([hit['_source'] for hit in hits])

                # é€²åº¦æç¤ºï¼ˆæ¯10000ç­†é¡¯ç¤ºä¸€æ¬¡ï¼‰
                if len(flows_raw) % 10000 == 0 and len(hits) > 0:
                    print(f"   å·²è¼‰å…¥ {len(flows_raw):,} ç­†è¨˜éŒ„...")

            # æ¸…ç† scroll
            if scroll_id:
                try:
                    self.es.clear_scroll(scroll_id=scroll_id)
                except:
                    pass

            # æ¨™æº–åŒ–æ¬„ä½åç¨±ï¼Œæ–¹ä¾¿å¾ŒçºŒè™•ç†
            flows = []
            for f in flows_raw:
                normalized = {
                    'src_ip': f.get('IPV4_SRC_ADDR') or f.get('IPV6_SRC_ADDR'),
                    'dst_ip': f.get('IPV4_DST_ADDR') or f.get('IPV6_DST_ADDR'),
                    'src_port': f.get('L4_SRC_PORT', 0),
                    'dst_port': f.get('L4_DST_PORT', 0),
                    'protocol': f.get('PROTOCOL', 0),
                    'in_bytes': f.get('IN_BYTES', 0),
                    'out_bytes': 0,  # åŸå§‹æ•¸æ“šæ²’æœ‰ out_bytes
                    'in_pkts': f.get('IN_PKTS', 0),
                    'out_pkts': 0,  # åŸå§‹æ•¸æ“šæ²’æœ‰ out_pkts
                    '@timestamp': f.get('FLOW_START_MILLISECONDS'),
                    'timestamp': f.get('FLOW_START_MILLISECONDS'),
                }
                flows.append(normalized)

            return flows
        except Exception as e:
            print(f"âŒ æŸ¥è©¢å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _analyze_basic_stats(self, flows):
        """åŸºæœ¬çµ±è¨ˆ"""
        total_bytes = sum(f.get('in_bytes', 0) + f.get('out_bytes', 0) for f in flows)
        total_packets = sum(f.get('in_pkts', 0) + f.get('out_pkts', 0) for f in flows)

        return {
            'total_flows': len(flows),
            'total_bytes': total_bytes,
            'total_packets': total_packets,
            'avg_bytes_per_flow': total_bytes / len(flows) if flows else 0,
            'avg_packets_per_flow': total_packets / len(flows) if flows else 0,
        }

    def _analyze_destinations(self, flows, role='src'):
        """
        ç›®çš„åœ°åˆ†æï¼ˆæ ¹æ“šè§’è‰²å‹•æ…‹èª¿æ•´ï¼‰

        Args:
            flows: æµé‡è¨˜éŒ„åˆ—è¡¨
            role: 'src' è¡¨ç¤ºåˆ†æç›®çš„åœ°ï¼Œ'dst' è¡¨ç¤ºåˆ†æä¾†æº
        """
        # æ ¹æ“šè§’è‰²é¸æ“‡è¦åˆ†æçš„ IP æ¬„ä½
        if role == 'src':
            # IP ä½œç‚ºæºï¼šåˆ†æå®ƒé€£åˆ°å“ªäº›ç›®çš„åœ°
            target_ips = [f['dst_ip'] for f in flows if 'dst_ip' in f]
            label = 'destinations'
        else:  # role == 'dst'
            # IP ä½œç‚ºç›®çš„åœ°ï¼šåˆ†æèª°é€£åˆ°å®ƒï¼ˆä¾†æºåˆ†æï¼‰
            target_ips = [f['src_ip'] for f in flows if 'src_ip' in f]
            label = 'sources'

        target_counter = Counter(target_ips)
        unique_targets = len(target_counter)

        # æ‰¾å‡ºæœ€å¸¸è¦‹çš„ç›®æ¨™ï¼ˆé¡¯ç¤ºæ‰€æœ‰ï¼Œæœ€å¤š50å€‹ï¼‰
        top_targets = target_counter.most_common(50)

        # è¨ˆç®—åˆ†å¸ƒç†µï¼ˆè¡¡é‡å¤šæ¨£æ€§ï¼‰
        total = len(target_ips)
        entropy = 0
        if total > 0:
            for count in target_counter.values():
                p = count / total
                entropy -= p * (math.log(p) if p > 0 else 0)

        return {
            'role': role,
            'label': label,
            'unique_destinations': unique_targets,
            'total_connections': len(target_ips),
            'dst_diversity_ratio': unique_targets / len(target_ips) if target_ips else 0,
            'top_destinations': [{'ip': ip, 'count': count, 'percentage': count/total*100}
                                for ip, count in top_targets],
            'is_highly_distributed': unique_targets > 50,  # é«˜åº¦åˆ†æ•£
            'is_concentrated': unique_targets < 5 and len(target_ips) > 100,  # é«˜åº¦é›†ä¸­
        }

    def _analyze_ports(self, flows, role='src'):
        """
        é€šè¨ŠåŸ åˆ†æï¼ˆæ ¹æ“šè§’è‰²å‹•æ…‹èª¿æ•´ï¼‰

        Args:
            flows: æµé‡è¨˜éŒ„åˆ—è¡¨
            role: 'src' è¡¨ç¤ºåˆ†æç›®çš„åŸ ï¼Œ'dst' è¡¨ç¤ºåˆ†æä¾†æºåŸ 
        """
        # æ ¹æ“šè§’è‰²é¸æ“‡è¦åˆ†æçš„é€šè¨ŠåŸ æ¬„ä½
        if role == 'src':
            # IP ä½œç‚ºæºï¼šåˆ†æç›®çš„é€šè¨ŠåŸ 
            target_ports = [f['dst_port'] for f in flows if 'dst_port' in f and f['dst_port'] > 0]
            label = 'destination_ports'
        else:  # role == 'dst'
            # ã€ä¿®æ­£ã€‘IP ä½œç‚ºç›®çš„åœ°ï¼šæ‡‰è©²åˆ†æã€Œå“ªäº›æœå‹™åŸ è¢«è¨ªå•ã€(dst_port)
            # è€Œä¸æ˜¯ä¾†æºåŸ ï¼Œé€™æ¨£æ‰èƒ½æ­£ç¢ºåˆ¤æ–·æ˜¯å¦è¢«æƒæ
            target_ports = [f['dst_port'] for f in flows if 'dst_port' in f and f['dst_port'] > 0]
            label = 'targeted_service_ports'

            # ã€è£œå……ã€‘åŒæ™‚æ”¶é›†ä¾†æºåŸ è³‡è¨Šï¼Œç”¨æ–¼å±•ç¤ºï¼ˆä½†ä¸ç”¨æ–¼æƒæåˆ¤å®šï¼‰
            src_ports = [f['src_port'] for f in flows if 'src_port' in f and f['src_port'] > 0]

        port_counter = Counter(target_ports)
        unique_ports = len(port_counter)

        # åˆ†é¡å¸¸è¦‹é€šè¨ŠåŸ 
        well_known_ports = {
            80: 'HTTP', 443: 'HTTPS', 53: 'DNS', 22: 'SSH',
            25: 'SMTP', 3389: 'RDP', 21: 'FTP', 23: 'Telnet',
            43: 'WHOIS', 445: 'SMB', 3306: 'MySQL', 5432: 'PostgreSQL', 6379: 'Redis',
            161: 'SNMP', 162: 'SNMP-Trap', 9200: 'Elasticsearch', 9100: 'Prometheus'
        }

        # åˆ†é›¢è‡¨æ™‚åŸ å’Œæœå‹™åŸ 
        ephemeral_ports = []  # >32000 è‡¨æ™‚åŸ ï¼ˆå®¢æˆ¶ç«¯éš¨æ©Ÿå›å‚³ç”¨ï¼‰
        service_ports = []    # <=32000 æœå‹™åŸ ï¼ˆä¼ºæœå™¨ç›£è½ç”¨ï¼‰

        port_distribution = defaultdict(int)
        for port in target_ports:
            if port < 1024:
                port_distribution['well_known'] += 1
                service_ports.append(port)
            elif port <= self.EPHEMERAL_PORT_START:
                port_distribution['registered'] += 1
                service_ports.append(port)
            else:
                port_distribution['ephemeral'] += 1
                ephemeral_ports.append(port)

        # éè‡¨æ™‚åŸ è¨ˆæ•¸æ³•ï¼šè¨ˆç®—æœ‰å¤šå°‘å€‹ä¸åŒçš„æœå‹™åŸ 
        unique_service_ports = len(set(service_ports))
        unique_ephemeral_ports = len(set(ephemeral_ports))
        ephemeral_ratio = len(ephemeral_ports) / len(target_ports) if target_ports else 0

        top_ports = port_counter.most_common(10)

        # æ”¹é€²çš„æƒæåµæ¸¬é‚è¼¯ï¼šä½¿ç”¨éè‡¨æ™‚åŸ è¨ˆæ•¸æ³•
        # çœŸæ­£çš„æƒææœƒé‡å°å¤§é‡ã€Œæœå‹™åŸ ã€(<=32000)
        # å¦‚æœå¤§éƒ¨åˆ†æ˜¯è‡¨æ™‚åŸ ï¼ˆ>32000ï¼‰ï¼Œä¸”æœå‹™åŸ å°‘ï¼Œå‰‡æ˜¯æ­£å¸¸ä¼ºæœå™¨å›æ‡‰è¡Œç‚º
        scanning_reason = None
        if role == 'dst':
            # DST è§’è‰²ï¼šåˆ¤æ–·æ˜¯å¦è¢«æƒæ
            if unique_ports > 20:
                if unique_service_ports < 10:
                    # é›–ç„¶ç¸½åŸ æ•¸å¾ˆå¤šï¼Œä½†æœå‹™åŸ å¾ˆå°‘ â†’ æ­£å¸¸ä¼ºæœå™¨ + å®¢æˆ¶ç«¯æ··åˆæµé‡
                    is_scanning = False
                    scanning_reason = 'normal_hybrid_server_client'
                elif unique_service_ports < 30:
                    # æœå‹™åŸ æ•¸é‡é©ä¸­ï¼ˆ10-29ï¼‰â†’ å¯èƒ½æ˜¯æ­£å¸¸çš„å¤šæœå‹™ä¸»æ©Ÿ
                    is_scanning = False
                    scanning_reason = 'limited_service_ports_dst'
                else:
                    # æœå‹™åŸ å¾ˆå¤šï¼ˆ>=30ï¼‰â†’ çœŸæ­£è¢«æƒæ
                    is_scanning = True
                    scanning_reason = 'many_service_ports_targeted'
            else:
                is_scanning = False
                scanning_reason = 'low_port_count'
        else:
            # SRC è§’è‰²ï¼šåŒæ¨£ä½¿ç”¨éè‡¨æ™‚åŸ è¨ˆæ•¸æ³•
            # å¦‚æœä½œç‚ºæºé€£åˆ°å¤§é‡è‡¨æ™‚åŸ  â†’ é€™æ˜¯ä¼ºæœå™¨å›æ‡‰çµ¦å®¢æˆ¶ç«¯ï¼ˆæ­£å¸¸ï¼‰
            # å¦‚æœä½œç‚ºæºé€£åˆ°å¤§é‡æœå‹™åŸ  â†’ é€™æ˜¯çœŸæ­£çš„æƒæè¡Œç‚ºï¼ˆç•°å¸¸ï¼‰
            if unique_ports > 20 and len(target_ports) > 100:
                if ephemeral_ratio > 0.9 and unique_service_ports < 20:
                    # é€£åˆ°å¤§é‡è‡¨æ™‚åŸ ï¼Œæœå‹™åŸ å°‘ â†’ ä¼ºæœå™¨å›æ‡‰æµé‡
                    is_scanning = False
                    scanning_reason = 'server_response_to_clients'
                elif unique_service_ports < 30:
                    # æœå‹™åŸ æ•¸é‡å°‘ï¼ˆ<30ï¼‰â†’ å¯èƒ½æ˜¯æ­£å¸¸çš„è³‡æ–™æ”¶é›†ï¼ˆå¦‚ WHOIS æŸ¥è©¢ï¼‰
                    is_scanning = False
                    scanning_reason = 'limited_service_ports'
                else:
                    # é€£åˆ°å¤§é‡æœå‹™åŸ ï¼ˆ>=30ï¼‰â†’ çœŸæ­£æƒæ
                    is_scanning = True
                    scanning_reason = 'scanning_many_service_ports'
            else:
                is_scanning = False
                scanning_reason = 'below_threshold'

        # ã€ä¿®æ­£ã€‘åªæª¢æŸ¥æœå‹™åŸ çš„é€£çºŒæ€§ï¼Œä¸æª¢æŸ¥è‡¨æ™‚åŸ 
        # è‡¨æ™‚åŸ çš„é€£çºŒæ€§ä¸ä»£è¡¨æƒæè¡Œç‚º
        service_port_list = list(set(service_ports))
        is_sequential_scan = self._check_sequential_ports(service_port_list)

        result = {
            'role': role,
            'label': label,
            'unique_ports': unique_ports,
            'unique_service_ports': unique_service_ports,
            'unique_ephemeral_ports': unique_ephemeral_ports,
            'ephemeral_ratio': ephemeral_ratio,
            'total_connections': len(target_ports),
            'port_diversity_ratio': unique_ports / len(target_ports) if target_ports else 0,
            'top_ports': [{'port': port,
                          'service': well_known_ports.get(port, 'Unknown'),
                          'count': count,
                          'percentage': count/len(target_ports)*100}
                         for port, count in top_ports],
            'port_distribution': dict(port_distribution),
            'is_scanning': is_scanning,
            'scanning_reason': scanning_reason,
            'is_sequential_scan': is_sequential_scan,
        }

        # ã€è£œå……ã€‘DST è§’è‰²æ™‚ï¼Œé¡å¤–æä¾›ä¾†æºåŸ è³‡è¨Šï¼ˆç”¨æ–¼å±•ç¤ºï¼Œä¸å½±éŸ¿æƒæåˆ¤å®šï¼‰
        if role == 'dst':
            src_port_counter = Counter(src_ports)
            src_service_ports = [p for p in src_ports if p <= self.EPHEMERAL_PORT_START]
            src_ephemeral_ports = [p for p in src_ports if p > self.EPHEMERAL_PORT_START]

            result['source_port_info'] = {
                'unique_src_ports': len(src_port_counter),
                'unique_service_src_ports': len(set(src_service_ports)),
                'unique_ephemeral_src_ports': len(set(src_ephemeral_ports)),
                'src_ephemeral_ratio': len(src_ephemeral_ports) / len(src_ports) if src_ports else 0,
                'note': 'ä¾†æºåŸ è³‡è¨Šï¼ˆåƒè€ƒç”¨ï¼Œæƒæåˆ¤å®šåŸºæ–¼ targeted_service_portsï¼‰'
            }

        return result

    def _check_sequential_ports(self, ports):
        """æª¢æŸ¥æ˜¯å¦ç‚ºé€£çºŒé€šè¨ŠåŸ æƒæ"""
        if len(ports) < 10:
            return False

        sorted_ports = sorted(ports)
        sequential_count = 0

        for i in range(len(sorted_ports) - 1):
            if sorted_ports[i+1] - sorted_ports[i] == 1:
                sequential_count += 1

        return sequential_count / len(sorted_ports) > 0.3  # 30% ä»¥ä¸Šé€£çºŒ

    def _analyze_protocols(self, flows):
        """å”å®šåˆ†æ"""
        protocols = [f.get('protocol', 0) for f in flows]
        proto_counter = Counter(protocols)

        proto_names = {
            1: 'ICMP', 6: 'TCP', 17: 'UDP'
        }

        proto_distribution = [
            {
                'protocol': proto_names.get(proto, f'Unknown({proto})'),
                'count': count,
                'percentage': count/len(protocols)*100
            }
            for proto, count in proto_counter.most_common()
        ]

        return {
            'protocol_distribution': proto_distribution,
            'is_icmp_heavy': proto_counter.get(1, 0) / len(protocols) > 0.5 if protocols else False,
            'is_udp_heavy': proto_counter.get(17, 0) / len(protocols) > 0.5 if protocols else False,
        }

    def _analyze_temporal_pattern(self, flows):
        """æ™‚é–“æ¨¡å¼åˆ†æ"""
        timestamps = []
        for f in flows:
            ts = f.get('@timestamp', f.get('timestamp', ''))
            if ts:
                try:
                    # å¦‚æœæ˜¯æ¯«ç§’æ™‚é–“æˆ³ï¼ˆæ•¸å­—ï¼‰
                    if isinstance(ts, (int, float)):
                        ts_dt = datetime.fromtimestamp(ts / 1000.0)
                    else:
                        # å¦‚æœæ˜¯ ISO å­—ä¸²
                        ts_dt = datetime.fromisoformat(str(ts).replace('Z', '+00:00'))
                    timestamps.append(ts_dt)
                except:
                    continue

        if len(timestamps) < 2:
            return {'insufficient_data': True}

        timestamps.sort()

        # è¨ˆç®—æ™‚é–“é–“éš”
        intervals = [(timestamps[i+1] - timestamps[i]).total_seconds()
                    for i in range(len(timestamps) - 1)]

        avg_interval = sum(intervals) / len(intervals) if intervals else 0

        # æª¢æ¸¬çªç™¼æµé‡
        burst_threshold = 1  # 1 ç§’å…§
        burst_count = sum(1 for interval in intervals if interval < burst_threshold)
        burst_ratio = burst_count / len(intervals) if intervals else 0

        return {
            'time_span_seconds': (timestamps[-1] - timestamps[0]).total_seconds(),
            'average_interval_seconds': avg_interval,
            'is_burst_traffic': burst_ratio > 0.5,
            'is_periodic': self._check_periodicity(intervals),
        }

    def _check_periodicity(self, intervals):
        """æª¢æŸ¥æ˜¯å¦ç‚ºé€±æœŸæ€§æµé‡"""
        if len(intervals) < 10:
            return False

        # ç°¡å–®çš„é€±æœŸæ€§æª¢æ¸¬ï¼šçœ‹é–“éš”çš„æ¨™æº–å·®
        import numpy as np
        std = np.std(intervals)
        mean = np.mean(intervals)

        # å¦‚æœæ¨™æº–å·®å¾ˆå°ï¼Œè¡¨ç¤ºå¾ˆè¦å¾‹
        cv = std / mean if mean > 0 else float('inf')
        return cv < 0.3  # è®Šç•°ä¿‚æ•¸ < 0.3 è¡¨ç¤ºé€±æœŸæ€§

    def _analyze_traffic_pattern(self, flows):
        """æµé‡æ¨¡å¼åˆ†æ"""
        bytes_list = [f.get('in_bytes', 0) + f.get('out_bytes', 0) for f in flows]
        packets_list = [f.get('in_pkts', 0) + f.get('out_pkts', 0) for f in flows]

        if not bytes_list:
            return {'insufficient_data': True}

        import numpy as np

        return {
            'mean_bytes': np.mean(bytes_list),
            'std_bytes': np.std(bytes_list),
            'max_bytes': np.max(bytes_list),
            'min_bytes': np.min(bytes_list),
            'median_bytes': np.median(bytes_list),
            'bytes_cv': np.std(bytes_list) / np.mean(bytes_list) if np.mean(bytes_list) > 0 else 0,
            'is_uniform_size': np.std(bytes_list) / np.mean(bytes_list) < 0.3 if np.mean(bytes_list) > 0 else False,
        }

    def _identify_role(self, port_analysis, role='dst'):
        """
        æ ¹æ“šé€šè¨ŠåŸ ç‰¹å¾µè‡ªå‹•è­˜åˆ¥è¨­å‚™è§’è‰²

        Args:
            port_analysis: åŸ åˆ†æçµæœï¼ˆå¿…é ˆåŒ…å« top_portsï¼‰
            role: 'src' æˆ– 'dst'

        Returns:
            list: è­˜åˆ¥å‡ºçš„è§’è‰²åˆ—è¡¨ï¼Œæ¯å€‹è§’è‰²åŒ…å«:
                - role: è§’è‰²åç¨±
                - desc: è§’è‰²æè¿°
                - confidence: ä¿¡å¿ƒåº¦ (HIGH/MEDIUM)
                - matched_ports: åŒ¹é…çš„åŸ åˆ—è¡¨
                - traffic_ratio: åŒ¹é…æµé‡ä½”æ¯”
        """
        if not port_analysis.get('top_ports'):
            return []

        # è¨ˆç®—ç¸½æµé‡ï¼ˆé€£ç·šæ•¸ï¼‰
        total_count = sum(p['count'] for p in port_analysis['top_ports'])
        if total_count == 0:
            return []

        # è½‰æ› top_ports ç‚º {port: count} æ–¹ä¾¿æŸ¥è©¢
        port_counts = {p['port']: p['count'] for p in port_analysis['top_ports']}

        detected_roles = []

        for role_key, sig in self.ROLE_SIGNATURES.items():
            # è¨ˆç®—å‘½ä¸­ç‰¹å¾µåŸ çš„æµé‡ä½”æ¯”
            match_count = sum(port_counts.get(p, 0) for p in sig['ports'])
            ratio = match_count / total_count

            # åŸºæœ¬é–¾å€¼æª¢æŸ¥
            if ratio < sig['threshold']:
                continue

            # AD ç‰¹æ®Šè™•ç†ï¼šéœ€è¦é¡å¤–æª¢æŸ¥æ ¸å¿ƒåŸ 
            if role_key == 'AD_CONTROLLER' and 'core_ports' in sig:
                matched_ports_set = sig['ports'] & set(port_counts.keys())
                core_matched = sig['core_ports'] & matched_ports_set
                # è‡³å°‘è¦åŒ¹é… 2 å€‹æ ¸å¿ƒåŸ ï¼ˆå¦‚ DNS+Kerberos, DNS+LDAP ç­‰ï¼‰
                if len(core_matched) < 2:
                    continue

            # ä¿¡å¿ƒåº¦åˆ¤å®š
            if ratio > 0.8:
                confidence = 'HIGH'
            elif ratio > 0.6:
                confidence = 'MEDIUM'
            else:
                confidence = 'LOW'

            detected_roles.append({
                'role': role_key,
                'desc': sig['desc'],
                'confidence': confidence,
                'category': sig.get('category', 'unknown'),
                'matched_ports': sorted(list(sig['ports'] & set(port_counts.keys()))),
                'traffic_ratio': ratio
            })

        # æŒ‰æµé‡ä½”æ¯”æ’åºï¼ˆä¿¡å¿ƒåº¦é«˜çš„åœ¨å‰ï¼‰
        detected_roles.sort(key=lambda x: x['traffic_ratio'], reverse=True)

        return detected_roles

    def _identify_domain_controller(self, flows, role, port_analysis):
        """
        è­˜åˆ¥æ˜¯å¦ç‚º Active Directory Domain Controller

        AD ç‰¹å¾µ:
        - DST è¦–è§’: Port 53/88/389/445 æ¥æ”¶å¤§é‡é€£ç·šï¼ˆä½œç‚ºæœå‹™æä¾›è€…ï¼‰
        - SRC è¦–è§’: Port 53/88/389/445 ä½œç‚ºä¾†æºåŸ ï¼ˆä¸»å‹•æä¾›æœå‹™ï¼‰

        Returns:
            dict: {
                'is_dc': bool,
                'confidence': float,
                'ad_ports': dict,
                'reason': str
            }
        """

        # çµ±è¨ˆ AD ç›¸é—œåŸ çš„æµé‡
        ad_ports = {
            53: 'DNS',
            88: 'Kerberos',
            389: 'LDAP',
            636: 'LDAPS',
            445: 'SMB',
            135: 'RPC',
            3268: 'Global Catalog',
            3269: 'Global Catalog SSL'
        }

        # å¾ flows ä¸­çµ±è¨ˆå„åŸ çš„æµé‡
        port_counter = Counter()
        total_flows = len(flows)

        if role == 'dst':
            # DST è¦–è§’ï¼šæª¢æŸ¥ã€Œè¢«è¨ªå•ã€çš„åŸ  (dst_port)
            for flow in flows:
                dst_port = flow.get('dst_port', 0)
                if dst_port in ad_ports:
                    port_counter[dst_port] += 1
        else:  # role == 'src'
            # SRC è¦–è§’ï¼šæª¢æŸ¥ã€Œä¾†æºåŸ ã€(src_port)ï¼ŒAD ä¼ºæœå™¨æœƒç”¨é€™äº›åŸ ä½œç‚ºä¾†æº
            for flow in flows:
                src_port = flow.get('src_port', 0)
                if src_port in ad_ports:
                    port_counter[src_port] += 1

        ad_traffic = sum(port_counter.values())
        ad_traffic_ratio = ad_traffic / total_flows if total_flows > 0 else 0

        # æª¢æŸ¥æ˜¯å¦æœ‰ AD æ ¸å¿ƒæœå‹™ (DNS + Kerberos + LDAP)
        has_dns = port_counter.get(53, 0) > total_flows * 0.3
        has_kerberos = port_counter.get(88, 0) > total_flows * 0.05
        has_ldap = port_counter.get(389, 0) > total_flows * 0.05

        # AD åˆ¤å®šæ¢ä»¶
        is_dc = False
        confidence = 0.0
        reason = ''

        if has_dns and has_kerberos and has_ldap:
            # åŒæ™‚æœ‰ DNS, Kerberos, LDAP â†’ æ¥µé«˜å¯èƒ½æ€§æ˜¯ AD
            is_dc = True
            confidence = 0.95
            reason = 'Has DNS, Kerberos, and LDAP services (å…¸å‹ AD ç‰¹å¾µ)'
        elif has_dns and (has_kerberos or has_ldap):
            # DNS + (Kerberos æˆ– LDAP) â†’ é«˜å¯èƒ½æ€§
            is_dc = True
            confidence = 0.85
            reason = 'Has DNS and AD authentication services'
        elif ad_traffic_ratio > 0.7:
            # 70% ä»¥ä¸Šæµé‡æ˜¯ AD ç›¸é—œåŸ  â†’ å¯èƒ½æ˜¯ AD
            is_dc = True
            confidence = 0.75
            reason = f'High AD traffic ratio ({ad_traffic_ratio*100:.1f}%)'

        return {
            'is_dc': is_dc,
            'confidence': confidence,
            'ad_ports': dict(port_counter),
            'ad_traffic_ratio': ad_traffic_ratio,
            'reason': reason,
            'has_dns': has_dns,
            'has_kerberos': has_kerberos,
            'has_ldap': has_ldap
        }

    def _analyze_behavior(self, flows, role='src'):
        """
        è¡Œç‚ºåˆ†æï¼ˆæ ¹æ“šè§’è‰²å‹•æ…‹èª¿æ•´ï¼‰

        Args:
            flows: æµé‡è¨˜éŒ„åˆ—è¡¨
            role: 'src' æˆ– 'dst'
        """
        dst_analysis = self._analyze_destinations(flows, role)
        port_analysis = self._analyze_ports(flows, role)
        proto_analysis = self._analyze_protocols(flows)
        traffic_analysis = self._analyze_traffic_pattern(flows)

        behaviors = []

        # ========================================
        # Step 1: è‡ªå‹•è­˜åˆ¥è¨­å‚™è§’è‰²ï¼ˆåŸºæ–¼ç‰¹å¾µåº«ï¼‰
        # ========================================
        identified_roles = self._identify_role(port_analysis, role)

        # æ¨™è¨˜è­˜åˆ¥å‡ºçš„è§’è‰²
        is_known_server = len(identified_roles) > 0
        management_roles = {'MONITORING_SYSTEM', 'AD_CONTROLLER'}  # ç®¡ç†é¡è§’è‰²
        current_role_names = {r['role'] for r in identified_roles}
        is_management = not current_role_names.isdisjoint(management_roles)

        # æ·»åŠ è§’è‰²è­˜åˆ¥æ¨™è¨˜
        for r in identified_roles:
            behaviors.append({
                'type': f"ROLE_{r['role']}",
                'severity': 'INFO',
                'description': f"è­˜åˆ¥ç‚º {r['desc']} (ä¿¡å¿ƒåº¦: {r['confidence']}, æµé‡ä½”æ¯”: {r['traffic_ratio']*100:.1f}%)",
                'evidence': {
                    'matched_ports': r['matched_ports'],
                    'traffic_ratio': r['traffic_ratio'],
                    'confidence': r['confidence'],
                    'category': r['category']
                }
            })

        # ========================================
        # Step 2: å¿«é€Ÿè·¯å¾‘ - ä¼ºæœå™¨å›æ‡‰æµé‡æ—©æœŸè¿”å›
        # ========================================
        # å¦‚æœæ˜¯å·²çŸ¥çš„é«˜æµé‡æœå‹™ï¼ˆDNS/Web/Mailï¼‰ï¼Œä¸”ç¬¦åˆå…¸å‹æœå‹™æ¨¡å¼ï¼Œç›´æ¥è¿”å›
        if role == 'src' and is_known_server:
            # æª¢æŸ¥æ˜¯å¦ç‚ºä¼ºæœå™¨å›æ‡‰æ¨¡å¼ï¼ˆä¾†æºåŸ ç‚ºæœå‹™åŸ ï¼‰
            src_ports = [f.get('src_port', 0) for f in flows if 'src_port' in f]
            src_port_counter = Counter(src_ports)
            most_common_src_port = src_port_counter.most_common(1)[0] if src_port_counter else (0, 0)

            # å¦‚æœä¸»è¦ä¾†æºåŸ æ˜¯æœå‹™åŸ ï¼ˆä¸”ä½”æ¯”è¶…é 50%ï¼‰ï¼Œå‰‡ç‚ºå…¸å‹æœå‹™å›æ‡‰
            service_port_ratio = most_common_src_port[1] / len(flows) if flows else 0
            if most_common_src_port[0] < self.EPHEMERAL_PORT_START and service_port_ratio > 0.5:
                # æ·»åŠ æœå‹™å›æ‡‰æ¨™è¨˜
                for r in identified_roles:
                    if r['role'] in ['DNS_SERVER', 'WEB_SERVER', 'MAIL_SERVER']:
                        behaviors.append({
                            'type': f"{r['role']}_RESPONSE",
                            'severity': 'LOW',
                            'description': f"{r['desc']}å›æ‡‰æµé‡ï¼ˆæºé€šè¨ŠåŸ  {most_common_src_port[0]}ï¼‰",
                            'evidence': {
                                'responses': most_common_src_port[1],
                                'percentage': service_port_ratio * 100
                            }
                        })
                        # æœå‹™å›æ‡‰æµé‡ä¸æ‡‰è¢«æ¨™è¨˜ç‚ºæƒæ
                        return behaviors

        # ========================================
        # Step 3: æƒæè¡Œç‚ºæª¢æ¸¬ï¼ˆä½¿ç”¨è§’è‰²ç‰¹å¾µè±å…é‚è¼¯ï¼‰
        # ========================================
        if port_analysis['is_scanning'] or port_analysis['is_sequential_scan']:
            ignore_scan = False

            if role == 'src':
                # SRC è¦–è§’ï¼šç›£æ§/ç®¡ç†é¡è§’è‰²è±å… PORT_SCANNING
                if is_management:
                    # ç®¡ç†é¡ä¸»æ©Ÿï¼ˆç›£æ§ç³»çµ±ã€ADï¼‰é€£ç·šå¤šå€‹åŸ æ˜¯æ­£å¸¸è¡Œç‚º
                    role_desc = ', '.join([r['desc'] for r in identified_roles if r['role'] in management_roles])
                    behaviors.append({
                        'type': 'MANAGEMENT_CONNECTIVITY',
                        'severity': 'LOW',
                        'description': f"{role_desc}æ­£å¸¸ç®¡ç†é€£ç·šï¼š{port_analysis['unique_service_ports']} å€‹ç›®çš„åŸ ï¼ˆå«å‹•æ…‹åŸ  {port_analysis['unique_ephemeral_ports']} å€‹ï¼‰",
                        'evidence': {
                            'unique_service_ports': port_analysis['unique_service_ports'],
                            'unique_ephemeral_ports': port_analysis['unique_ephemeral_ports'],
                            'ephemeral_ratio': port_analysis.get('ephemeral_ratio', 0),
                            'management_roles': list(current_role_names & management_roles)
                        }
                    })
                    ignore_scan = True

                if not ignore_scan:
                    behaviors.append({
                        'type': 'PORT_SCANNING',
                        'severity': 'HIGH',
                        'description': f"æª¢æ¸¬åˆ°é€šè¨ŠåŸ æƒæï¼š{port_analysis['unique_service_ports']} å€‹æœå‹™åŸ è¢«æƒæ",
                        'evidence': {
                            'unique_service_ports': port_analysis['unique_service_ports'],
                            'unique_ephemeral_ports': port_analysis['unique_ephemeral_ports'],
                            'is_sequential': port_analysis['is_sequential_scan']
                        }
                    })

            else:  # role == 'dst'
                # DST è¦–è§’ï¼šä¼ºæœå™¨è¢«å¤§é‡å®¢æˆ¶ç«¯é€£ç·šæ˜¯æ­£å¸¸çš„ï¼ˆä¸è¦–ç‚ºè¢«æƒæï¼‰
                if is_known_server:
                    # å·²çŸ¥æœå‹™é¡å‹çš„ä¼ºæœå™¨ï¼Œè¢«å¤šå€‹å®¢æˆ¶ç«¯é€£ç·šæ˜¯æ­£å¸¸è¡Œç‚º
                    role_desc = ', '.join([r['desc'] for r in identified_roles[:2]])  # å–å‰å…©å€‹è§’è‰²
                    behaviors.append({
                        'type': 'HIGH_LOAD_SERVER',
                        'severity': 'LOW',
                        'description': f"{role_desc}é«˜è² è¼‰ï¼š{port_analysis['unique_service_ports']} å€‹æœå‹™åŸ æä¾›æœå‹™",
                        'evidence': {
                            'unique_service_ports': port_analysis['unique_service_ports'],
                            'unique_ephemeral_ports': port_analysis['unique_ephemeral_ports'],
                            'server_roles': [r['role'] for r in identified_roles]
                        }
                    })
                    ignore_scan = True

                if not ignore_scan:
                    behaviors.append({
                        'type': 'UNDER_PORT_SCAN',
                        'severity': 'HIGH',
                        'description': f"æª¢æ¸¬åˆ°è¢«æƒæï¼š{port_analysis['unique_service_ports']} å€‹æœå‹™åŸ è¢«é‡å°",
                        'evidence': {
                            'unique_service_ports': port_analysis['unique_service_ports'],
                            'unique_ephemeral_ports': port_analysis['unique_ephemeral_ports'],
                            'is_sequential': port_analysis['is_sequential_scan']
                        }
                    })
        elif role == 'dst' and port_analysis.get('scanning_reason') == 'normal_hybrid_server_client':
            # é›–ç„¶åŸ æ•¸å¤šï¼Œä½†ä¸»è¦æ˜¯è‡¨æ™‚åŸ  â†’ æ­£å¸¸ä¼ºæœå™¨ + å®¢æˆ¶ç«¯æ··åˆæµé‡
            behaviors.append({
                'type': 'HYBRID_SERVER_CLIENT',
                'severity': 'LOW',
                'description': f"æ··åˆæµé‡ï¼šæœå‹™åŸ  ({port_analysis['unique_service_ports']}) + è‡¨æ™‚åŸ å›å‚³ ({port_analysis['unique_ephemeral_ports']})",
                'evidence': {
                    'unique_service_ports': port_analysis['unique_service_ports'],
                    'unique_ephemeral_ports': port_analysis['unique_ephemeral_ports'],
                    'ephemeral_ratio': port_analysis['ephemeral_ratio']
                }
            })
        elif role == 'dst' and port_analysis.get('scanning_reason') == 'limited_service_ports_dst':
            # DST è§’è‰²ï¼šæœ‰é©é‡æœå‹™åŸ è¢«é€£ â†’ å¤šæœå‹™ä¸»æ©Ÿï¼ˆæ­£å¸¸ï¼‰
            behaviors.append({
                'type': 'MULTI_SERVICE_HOST',
                'severity': 'LOW',
                'description': f"å¤šæœå‹™ä¸»æ©Ÿï¼š{port_analysis['unique_service_ports']} å€‹æœå‹™åŸ æä¾›æœå‹™ï¼ˆå«è‡¨æ™‚åŸ  {port_analysis['unique_ephemeral_ports']} å€‹ï¼‰",
                'evidence': {
                    'unique_service_ports': port_analysis['unique_service_ports'],
                    'unique_ephemeral_ports': port_analysis['unique_ephemeral_ports'],
                    'ephemeral_ratio': port_analysis['ephemeral_ratio']
                }
            })
        elif role == 'src' and port_analysis.get('scanning_reason') == 'server_response_to_clients':
            # SRC è§’è‰²ï¼šå›æ‡‰åˆ°å¤§é‡è‡¨æ™‚åŸ  â†’ ä¼ºæœå™¨å›æ‡‰æµé‡
            behaviors.append({
                'type': 'SERVER_RESPONSE_TO_CLIENTS',
                'severity': 'LOW',
                'description': f"ä¼ºæœå™¨å›æ‡‰æµé‡ï¼šå›æ‡‰åˆ° {port_analysis['unique_ephemeral_ports']} å€‹å®¢æˆ¶ç«¯è‡¨æ™‚åŸ ",
                'evidence': {
                    'unique_service_ports': port_analysis['unique_service_ports'],
                    'unique_ephemeral_ports': port_analysis['unique_ephemeral_ports'],
                    'ephemeral_ratio': port_analysis['ephemeral_ratio']
                }
            })
        elif role == 'src' and port_analysis.get('scanning_reason') == 'limited_service_ports':
            # SRC è§’è‰²ï¼šé€£åˆ°å°‘é‡æœå‹™åŸ  â†’ è³‡æ–™æ”¶é›†è¡Œç‚ºï¼ˆå¦‚ WHOISã€API æŸ¥è©¢ï¼‰
            behaviors.append({
                'type': 'DATA_COLLECTION',
                'severity': 'LOW',
                'description': f"è³‡æ–™æ”¶é›†è¡Œç‚ºï¼šé€£åˆ° {port_analysis['unique_service_ports']} å€‹æœå‹™åŸ ï¼ˆå«è‡¨æ™‚åŸ å›å‚³ {port_analysis['unique_ephemeral_ports']} å€‹ï¼‰",
                'evidence': {
                    'unique_service_ports': port_analysis['unique_service_ports'],
                    'unique_ephemeral_ports': port_analysis['unique_ephemeral_ports'],
                    'top_ports': port_analysis['top_ports'][:5]
                }
            })

        # ========================================
        # Step 4: é«˜åº¦åˆ†æ•£é€£ç·šæª¢æ¸¬ï¼ˆNETWORK_SCANNING / UNDER_ATTACKï¼‰
        # ========================================
        if dst_analysis['is_highly_distributed']:
            ignore_distributed = False

            if role == 'src':
                # SRC è¦–è§’ï¼šç›£æ§/ç®¡ç†é¡è§’è‰²è±å… NETWORK_SCANNING
                if is_management:
                    role_desc = ', '.join([r['desc'] for r in identified_roles if r['role'] in management_roles])
                    behaviors.append({
                        'type': 'MANAGEMENT_MULTI_TARGET',
                        'severity': 'LOW',
                        'description': f"{role_desc}æ­£å¸¸å¤šç›®æ¨™é€£ç·šï¼š{dst_analysis['unique_destinations']} å€‹ç›®çš„åœ°ï¼ˆç®¡ç†ç‰¹æ€§ï¼‰",
                        'evidence': {
                            'unique_destinations': dst_analysis['unique_destinations'],
                            'dst_diversity': dst_analysis['dst_diversity_ratio'],
                            'management_roles': list(current_role_names & management_roles)
                        }
                    })
                    ignore_distributed = True

                if not ignore_distributed:
                    behaviors.append({
                        'type': 'NETWORK_SCANNING',
                        'severity': 'HIGH',
                        'description': f"æª¢æ¸¬åˆ°ç¶²è·¯æƒæï¼š{dst_analysis['unique_destinations']} å€‹ç›®çš„åœ°",
                        'evidence': {
                            'unique_destinations': dst_analysis['unique_destinations'],
                            'dst_diversity': dst_analysis['dst_diversity_ratio']
                        }
                    })

            else:  # role == 'dst'
                # DST è¦–è§’ï¼šä¼ºæœå™¨è¢«å¤§é‡ä¾†æºé€£ç·šæ˜¯æ­£å¸¸çš„ï¼ˆä¸è¦–ç‚ºè¢«æ”»æ“Šï¼‰
                if is_known_server:
                    role_desc = ', '.join([r['desc'] for r in identified_roles[:2]])
                    behaviors.append({
                        'type': 'HIGH_CLIENT_LOAD',
                        'severity': 'LOW',
                        'description': f"{role_desc}æ­£å¸¸å®¢æˆ¶ç«¯è² è¼‰ï¼šä¾†è‡ª {dst_analysis['unique_destinations']} å€‹å®¢æˆ¶ç«¯",
                        'evidence': {
                            'unique_sources': dst_analysis['unique_destinations'],
                            'source_diversity': dst_analysis['dst_diversity_ratio'],
                            'server_roles': [r['role'] for r in identified_roles]
                        }
                    })
                    ignore_distributed = True

                if not ignore_distributed:
                    behaviors.append({
                        'type': 'UNDER_ATTACK',
                        'severity': 'HIGH',
                        'description': f"æª¢æ¸¬åˆ°é­å—æ”»æ“Šï¼šä¾†è‡ª {dst_analysis['unique_destinations']} å€‹ä¸åŒä¾†æº",
                        'evidence': {
                            'unique_sources': dst_analysis['unique_destinations'],
                            'source_diversity': dst_analysis['dst_diversity_ratio']
                        }
                    })

        # DNS æ¿«ç”¨ï¼ˆåªåœ¨ä½œç‚ºæºæ™‚æª¢æŸ¥ï¼‰
        if role == 'src':
            dns_flows = [f for f in flows if f.get('dst_port') == 53]
            if len(dns_flows) > 1000 and traffic_analysis.get('mean_bytes', 0) < 500:
                behaviors.append({
                    'type': 'DNS_ABUSE',
                    'severity': 'MEDIUM',
                    'description': f"ç–‘ä¼¼ DNS æ¿«ç”¨ï¼š{len(dns_flows)} å€‹ DNS æŸ¥è©¢",
                    'evidence': {
                        'dns_query_count': len(dns_flows),
                        'avg_bytes': traffic_analysis.get('mean_bytes', 0)
                    }
                })

        # æ•¸æ“šå¤–æ´©/å…§æµ
        total_bytes = sum(f.get('in_bytes', 0) + f.get('out_bytes', 0) for f in flows)
        if total_bytes > 1_000_000_000 and dst_analysis['unique_destinations'] < 5:  # 1GB+
            if role == 'src':
                behaviors.append({
                    'type': 'DATA_EXFILTRATION',
                    'severity': 'HIGH',
                    'description': f"ç–‘ä¼¼æ•¸æ“šå¤–æ´©ï¼š{total_bytes/1024/1024/1024:.2f} GB åˆ°å°‘æ•¸ç›®çš„åœ°",
                    'evidence': {
                        'total_bytes': total_bytes,
                        'unique_destinations': dst_analysis['unique_destinations']
                    }
                })
            else:  # role == 'dst'
                behaviors.append({
                    'type': 'LARGE_DATA_RECEIVE',
                    'severity': 'MEDIUM',
                    'description': f"æ¥æ”¶å¤§é‡æ•¸æ“šï¼š{total_bytes/1024/1024/1024:.2f} GB ä¾†è‡ªå°‘æ•¸ä¾†æº",
                    'evidence': {
                        'total_bytes': total_bytes,
                        'unique_sources': dst_analysis['unique_destinations']
                    }
                })

        # ICMP æ¿«ç”¨
        if proto_analysis['is_icmp_heavy']:
            behaviors.append({
                'type': 'ICMP_ABUSE',
                'severity': 'MEDIUM',
                'description': "å¤§é‡ ICMP æµé‡ï¼ˆå¯èƒ½ç‚º ping æƒææˆ– DDoSï¼‰",
                'evidence': proto_analysis['protocol_distribution']
            })

        # æ­£å¸¸è¡Œç‚ºæ¨¡å¼
        if not behaviors:
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ­£å¸¸æœå‹™
            top_ports = [p['port'] for p in port_analysis['top_ports'][:3]]
            if set(top_ports).intersection({80, 443, 53, 22}):
                behaviors.append({
                    'type': 'NORMAL_SERVICE',
                    'severity': 'LOW',
                    'description': "çœ‹èµ·ä¾†åƒæ­£å¸¸æœå‹™æµé‡",
                    'evidence': {
                        'top_ports': port_analysis['top_ports'][:3]
                    }
                })

        return behaviors

    def _generate_verdict(self, analysis):
        """ç”Ÿæˆæœ€çµ‚åˆ¤æ–·"""
        behaviors = analysis['behavioral_analysis']

        high_severity = sum(1 for b in behaviors if b['severity'] == 'HIGH')
        medium_severity = sum(1 for b in behaviors if b['severity'] == 'MEDIUM')
        low_severity_types = [b['type'] for b in behaviors if b['severity'] == 'LOW']

        # æœå‹™å™¨å›æ‡‰æµé‡æ‡‰è©²è¢«è¦–ç‚ºèª¤å ±
        if any(t in ['DNS_SERVER_RESPONSE', 'WEB_SERVER_RESPONSE', 'NORMAL_SERVICE', 'HYBRID_SERVER_CLIENT', 'SERVER_RESPONSE_TO_CLIENTS', 'DATA_COLLECTION', 'MULTI_SERVICE_HOST'] for t in low_severity_types):
            verdict = 'FALSE_POSITIVE'
            confidence = 'HIGH'
            if 'DNS_SERVER_RESPONSE' in low_severity_types:
                recommendation = 'é€™æ˜¯ DNS æœå‹™å™¨å›æ‡‰æµé‡ï¼Œå»ºè­°èª¿æ•´ Transform æˆ–ç‰¹å¾µå·¥ç¨‹ä¾†æ’é™¤æœå‹™å™¨å›æ‡‰'
            elif 'WEB_SERVER_RESPONSE' in low_severity_types:
                recommendation = 'é€™æ˜¯ Web æœå‹™å™¨å›æ‡‰æµé‡ï¼Œå»ºè­°èª¿æ•´ Transform æˆ–ç‰¹å¾µå·¥ç¨‹ä¾†æ’é™¤æœå‹™å™¨å›æ‡‰'
            elif 'DATA_COLLECTION' in low_severity_types:
                recommendation = 'é€™æ˜¯æ­£å¸¸çš„è³‡æ–™æ”¶é›†è¡Œç‚ºï¼ˆå¦‚ WHOIS æŸ¥è©¢ã€API èª¿ç”¨ï¼‰ï¼Œå»ºè­°èª¿æ•´ç‰¹å¾µé–¾å€¼'
            elif 'MULTI_SERVICE_HOST' in low_severity_types:
                recommendation = 'é€™æ˜¯æ­£å¸¸çš„å¤šæœå‹™ä¸»æ©Ÿæµé‡ï¼Œå»ºè­°èª¿æ•´ç‰¹å¾µé–¾å€¼'
            elif 'HYBRID_SERVER_CLIENT' in low_severity_types or 'SERVER_RESPONSE_TO_CLIENTS' in low_severity_types:
                recommendation = 'é€™æ˜¯æ­£å¸¸çš„ä¼ºæœå™¨å›æ‡‰æµé‡ï¼ˆå›æ‡‰åˆ°å®¢æˆ¶ç«¯è‡¨æ™‚åŸ ï¼‰ï¼Œå»ºè­°èª¿æ•´ç‰¹å¾µé–¾å€¼'
            else:
                recommendation = 'å»ºè­°èª¿æ•´ç‰¹å¾µé–¾å€¼ï¼Œé™ä½æ­¤é¡èª¤å ±'
        elif high_severity > 0:
            verdict = 'TRUE_ANOMALY'
            confidence = 'HIGH'
            recommendation = 'å»ºè­°ç«‹å³èª¿æŸ¥'
        elif medium_severity > 0:
            verdict = 'SUSPICIOUS'
            confidence = 'MEDIUM'
            recommendation = 'å»ºè­°æŒçºŒè§€å¯Ÿ'
        else:
            verdict = 'UNCLEAR'
            confidence = 'LOW'
            recommendation = 'éœ€è¦æ›´å¤šæ•¸æ“šæˆ–äººå·¥åˆ¤æ–·'

        return {
            'verdict': verdict,
            'confidence': confidence,
            'recommendation': recommendation,
            'detected_behaviors': len(behaviors),
        }

    def _generate_bidirectional_verdict(self, analysis_result):
        """ç”Ÿæˆé›™å‘åˆ†æçš„ç¶œåˆåˆ¤æ–·"""
        src_analysis = analysis_result.get('as_source')
        dst_analysis = analysis_result.get('as_destination')

        all_behaviors = []
        high_severity_count = 0
        medium_severity_count = 0
        low_severity_types = []

        # æ”¶é›†å…©å€‹æ–¹å‘çš„è¡Œç‚º
        if src_analysis:
            src_behaviors = src_analysis.get('behavioral_analysis', [])
            all_behaviors.extend([{**b, 'direction': 'as_source'} for b in src_behaviors])
            high_severity_count += sum(1 for b in src_behaviors if b['severity'] == 'HIGH')
            medium_severity_count += sum(1 for b in src_behaviors if b['severity'] == 'MEDIUM')
            low_severity_types.extend([b['type'] for b in src_behaviors if b['severity'] == 'LOW'])

        if dst_analysis:
            dst_behaviors = dst_analysis.get('behavioral_analysis', [])
            all_behaviors.extend([{**b, 'direction': 'as_destination'} for b in dst_behaviors])
            high_severity_count += sum(1 for b in dst_behaviors if b['severity'] == 'HIGH')
            medium_severity_count += sum(1 for b in dst_behaviors if b['severity'] == 'MEDIUM')
            low_severity_types.extend([b['type'] for b in dst_behaviors if b['severity'] == 'LOW'])

        # ç¶œåˆåˆ¤æ–·
        if high_severity_count > 0:
            verdict = 'TRUE_ANOMALY'
            confidence = 'HIGH'
            if high_severity_count > 1:
                recommendation = f'æª¢æ¸¬åˆ° {high_severity_count} å€‹é«˜å±ç•°å¸¸è¡Œç‚ºï¼Œå»ºè­°ç«‹å³èª¿æŸ¥'
            else:
                recommendation = 'æª¢æ¸¬åˆ°é«˜å±ç•°å¸¸è¡Œç‚ºï¼Œå»ºè­°ç«‹å³èª¿æŸ¥'
        elif any(t in ['DNS_SERVER_RESPONSE', 'WEB_SERVER_RESPONSE', 'NORMAL_SERVICE', 'HYBRID_SERVER_CLIENT', 'SERVER_RESPONSE_TO_CLIENTS', 'DATA_COLLECTION', 'MULTI_SERVICE_HOST'] for t in low_severity_types):
            # å¦‚æœæœ‰é«˜å±è¡Œç‚ºï¼Œä¸æ‡‰è©²è¢«æœå‹™å™¨å›æ‡‰æ©è“‹
            if high_severity_count == 0:
                verdict = 'FALSE_POSITIVE'
                confidence = 'HIGH'
                recommendation = 'ä¸»è¦ç‚ºæ­£å¸¸æœå‹™æµé‡ï¼ˆè³‡æ–™æ”¶é›†ã€å¤šæœå‹™ä¸»æ©Ÿæˆ–ä¼ºæœå™¨å›æ‡‰ï¼‰ï¼Œå»ºè­°èª¿æ•´ç‰¹å¾µé–¾å€¼'
            else:
                verdict = 'MIXED'
                confidence = 'MEDIUM'
                recommendation = 'åŒæ™‚æª¢æ¸¬åˆ°æ­£å¸¸æœå‹™å’Œç•°å¸¸è¡Œç‚ºï¼Œéœ€é€²ä¸€æ­¥åˆ†æ'
        elif medium_severity_count > 0:
            verdict = 'SUSPICIOUS'
            confidence = 'MEDIUM'
            recommendation = 'æª¢æ¸¬åˆ°å¯ç–‘è¡Œç‚ºï¼Œå»ºè­°æŒçºŒè§€å¯Ÿ'
        elif all_behaviors:
            verdict = 'UNCLEAR'
            confidence = 'LOW'
            recommendation = 'è¡Œç‚ºæ¨¡å¼ä¸æ˜ç¢ºï¼Œéœ€è¦æ›´å¤šæ•¸æ“šæˆ–äººå·¥åˆ¤æ–·'
        else:
            verdict = 'NORMAL'
            confidence = 'MEDIUM'
            recommendation = 'æœªæª¢æ¸¬åˆ°æ˜é¡¯ç•°å¸¸è¡Œç‚º'

        return {
            'verdict': verdict,
            'confidence': confidence,
            'recommendation': recommendation,
            'total_behaviors': len(all_behaviors),
            'high_severity': high_severity_count,
            'medium_severity': medium_severity_count,
            'behaviors': all_behaviors,
        }

    def _print_bidirectional_report(self, analysis_result):
        """åˆ—å°é›™å‘åˆ†æå ±å‘Š"""
        print(f"\n{'='*100}")
        print(f"ğŸ“‹ é›™å‘åˆ†æå ±å‘Š")
        print(f"{'='*100}\n")

        target_ip = analysis_result['target_ip']
        src_analysis = analysis_result.get('as_source')
        dst_analysis = analysis_result.get('as_destination')

        # å ±å‘Šä½œç‚ºæº IP çš„åˆ†æ
        if src_analysis:
            print(f"{'â”€'*100}")
            print(f"ğŸ“¤ ä½œç‚ºæº IP çš„è¡Œç‚ºåˆ†æ")
            print(f"{'â”€'*100}\n")
            self._print_single_direction_report(src_analysis)

        # å ±å‘Šä½œç‚ºç›®çš„åœ° IP çš„åˆ†æ
        if dst_analysis:
            print(f"\n{'â”€'*100}")
            print(f"ğŸ“¥ ä½œç‚ºç›®çš„åœ° IP çš„è¡Œç‚ºåˆ†æ")
            print(f"{'â”€'*100}\n")
            self._print_single_direction_report(dst_analysis)

        # ç¶œåˆåˆ¤æ–·
        verdict = analysis_result['verdict']
        print(f"\n{'='*100}")
        print(f"ğŸ¯ ç¶œåˆåˆ¤æ–·")
        print(f"{'='*100}\n")

        verdict_icons = {
            'TRUE_ANOMALY': 'ğŸš¨',
            'SUSPICIOUS': 'âš ï¸',
            'FALSE_POSITIVE': 'âœ…',
            'MIXED': 'ğŸ”€',
            'UNCLEAR': 'â“',
            'NORMAL': 'âœ”ï¸'
        }
        verdict_names = {
            'TRUE_ANOMALY': 'çœŸå¯¦ç•°å¸¸',
            'SUSPICIOUS': 'å¯ç–‘è¡Œç‚º',
            'FALSE_POSITIVE': 'èª¤å ±ï¼ˆæ­£å¸¸æµé‡ï¼‰',
            'MIXED': 'æ··åˆæƒ…æ³',
            'UNCLEAR': 'ç„¡æ³•ç¢ºå®š',
            'NORMAL': 'æ­£å¸¸æµé‡'
        }

        icon = verdict_icons.get(verdict['verdict'], 'â“')
        name = verdict_names.get(verdict['verdict'], verdict['verdict'])

        print(f"{icon} åˆ¤æ–·çµæœ: {name}")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {verdict['confidence']}")
        print(f"ğŸ“ æª¢æ¸¬åˆ°çš„è¡Œç‚ºæ•¸é‡: {verdict['total_behaviors']}")
        if verdict['high_severity'] > 0:
            print(f"   ğŸ”´ é«˜å±è¡Œç‚º: {verdict['high_severity']}")
        if verdict['medium_severity'] > 0:
            print(f"   ğŸŸ¡ å¯ç–‘è¡Œç‚º: {verdict['medium_severity']}")
        print(f"\nğŸ’¡ å»ºè­°: {verdict['recommendation']}\n")

    def _print_single_direction_report(self, analysis):
        """åˆ—å°å–®ä¸€æ–¹å‘çš„åˆ†æå ±å‘Šï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        role = analysis.get('role', 'src')

        # åŸºæœ¬çµ±è¨ˆ
        stats = analysis['basic_stats']
        print(f"ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"   â€¢ ç¸½é€£ç·šæ•¸: {stats['total_flows']:,}")
        print(f"   â€¢ ç¸½æµé‡: {stats['total_bytes']/1024/1024:.2f} MB")
        print(f"   â€¢ å¹³å‡æ¯é€£ç·š: {stats['avg_bytes_per_flow']:,.0f} bytes\n")

        # ç›®çš„åœ°/ä¾†æºåˆ†æ
        dst = analysis['destination_analysis']
        if role == 'src':
            print(f"ğŸ¯ ç›®çš„åœ°åˆ†æ:")
            print(f"   â€¢ ä¸åŒç›®çš„åœ°æ•¸é‡: {dst['unique_destinations']}")
            print(f"   â€¢ åˆ†æ•£åº¦: {dst['dst_diversity_ratio']:.3f}")
            # é¡¯ç¤º TOP 5 ç›®çš„åœ°
            if dst['top_destinations']:
                num_to_display = min(5, len(dst['top_destinations']))
                if num_to_display == len(dst['top_destinations']) and num_to_display < 5:
                    print(f"\n   é€£ç·šæ¬¡æ•¸æœ€å¤šçš„å‰ {num_to_display} å€‹ç›®çš„åœ°:")
                else:
                    print(f"\n   TOP 5 é€£ç·šç›®çš„åœ°:")
                for i, dst_info in enumerate(dst['top_destinations'][:5], 1):
                    ip = dst_info['ip']
                    if ip in ['0.0.0.0', '::']:
                        ip_display = f"{ip} (æ•¸æ“šç¼ºå¤±)"
                    else:
                        ip_display = self._format_ip_with_name(ip)
                    print(f"      {i}. {ip_display:50s} â†’ {dst_info['count']:5,} æ¬¡ ({dst_info['percentage']:.1f}%)")
            print()
        else:
            print(f"ğŸ¯ ä¾†æºåˆ†æ:")
            print(f"   â€¢ ä¸åŒä¾†æºæ•¸é‡: {dst['unique_destinations']}")
            print(f"   â€¢ åˆ†æ•£åº¦: {dst['dst_diversity_ratio']:.3f}")
            # é¡¯ç¤º TOP 5 ä¾†æº
            if dst['top_destinations']:
                num_to_display = min(5, len(dst['top_destinations']))
                if num_to_display == len(dst['top_destinations']) and num_to_display < 5:
                    print(f"\n   é€£ç·šæ¬¡æ•¸æœ€å¤šçš„å‰ {num_to_display} å€‹ä¾†æº:")
                else:
                    print(f"\n   TOP 5 é€£ç·šä¾†æº:")
                for i, src_info in enumerate(dst['top_destinations'][:5], 1):
                    ip = src_info['ip']
                    if ip in ['0.0.0.0', '::']:
                        ip_display = f"{ip} (æ•¸æ“šç¼ºå¤±)"
                    else:
                        ip_display = self._format_ip_with_name(ip)
                    print(f"      {i}. {ip_display:50s} â†’ {src_info['count']:5,} æ¬¡ ({src_info['percentage']:.1f}%)")
            print()

        # é€šè¨ŠåŸ åˆ†æ
        port = analysis['port_analysis']
        if role == 'src':
            print(f"ğŸ”Œ ç›®çš„é€šè¨ŠåŸ åˆ†æ:")
        else:
            print(f"ğŸ”Œ è¢«è¨ªå•çš„æœå‹™åŸ åˆ†æ (åˆ¤æ–·æ˜¯å¦è¢«æƒæ):")
        print(f"   â€¢ ä¸åŒé€šè¨ŠåŸ æ•¸é‡: {port['unique_ports']}")
        if role == 'dst':
            # DST è§’è‰²é¡¯ç¤ºè©³ç´°åˆ†é¡
            print(f"   â€¢ æœå‹™åŸ : {port['unique_service_ports']} å€‹, è‡¨æ™‚åŸ : {port['unique_ephemeral_ports']} å€‹ ({port['ephemeral_ratio']*100:.1f}%)")

        # é¡¯ç¤º TOP 5 é€šè¨ŠåŸ 
        if port['top_ports']:
            if role == 'src':
                print(f"\n   TOP 5 ç›®çš„é€šè¨ŠåŸ :")
            else:
                print(f"\n   TOP 5 è¢«è¨ªå•çš„æœå‹™åŸ :")
            for i, port_info in enumerate(port['top_ports'][:5], 1):
                print(f"      {i}. {port_info['port']:5d} ({port_info['service']:15s}) â†’ {port_info['count']:5,} æ¬¡ ({port_info['percentage']:.1f}%)")
            print()
        else:
            print()

        # DST è¦–è§’æ™‚ï¼Œè£œå……é¡¯ç¤ºä¾†æºåŸ è³‡è¨Š
        if role == 'dst' and 'source_port_info' in port:
            src_info = port['source_port_info']
            print(f"ğŸ“ è£œå……ï¼šä¾†æºåŸ è³‡è¨Š (åƒè€ƒç”¨ï¼Œä¸å½±éŸ¿æƒæåˆ¤å®š)")
            print(f"   â€¢ ä¸åŒä¾†æºåŸ æ•¸é‡: {src_info['unique_src_ports']}")
            print(f"   â€¢ æœå‹™ä¾†æºåŸ : {src_info['unique_service_src_ports']} å€‹, è‡¨æ™‚ä¾†æºåŸ : {src_info['unique_ephemeral_src_ports']} å€‹")
            print(f"   â€¢ ä¾†æºè‡¨æ™‚åŸ æ¯”ä¾‹: {src_info['src_ephemeral_ratio']*100:.1f}%")
            print()

        # è¡Œç‚ºåˆ†æ
        behaviors = analysis['behavioral_analysis']
        if behaviors:
            print(f"ğŸ” æª¢æ¸¬åˆ°çš„è¡Œç‚º:")
            for behavior in behaviors:
                severity_icon = {'HIGH': 'ğŸ”´', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸŸ¢'}.get(behavior['severity'], 'âšª')
                print(f"   {severity_icon} [{behavior['severity']}] {behavior['type']}")
                print(f"      {behavior['description']}")
        else:
            print(f"ğŸ” æœªæª¢æ¸¬åˆ°æ˜é¡¯ç•°å¸¸è¡Œç‚º")

    def _print_report(self, analysis):
        """åˆ—å°åˆ†æå ±å‘Š"""
        print(f"ğŸ“‹ åˆ†æå ±å‘Š\n")

        role = analysis.get('role', 'src')

        # åŸºæœ¬çµ±è¨ˆ
        stats = analysis['basic_stats']
        print(f"ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"   â€¢ ç¸½é€£ç·šæ•¸: {stats['total_flows']:,}")
        print(f"   â€¢ ç¸½æµé‡: {stats['total_bytes']/1024/1024:.2f} MB")
        print(f"   â€¢ å¹³å‡æ¯é€£ç·š: {stats['avg_bytes_per_flow']:,.0f} bytes")
        print()

        # ç›®çš„åœ°/ä¾†æºåˆ†æï¼ˆæ ¹æ“šè§’è‰²å‹•æ…‹æ¨™ç±¤ï¼‰
        dst = analysis['destination_analysis']
        if role == 'src':
            title = "ğŸ¯ ç›®çš„åœ°åˆ†æ:"
            count_label = "ä¸åŒç›®çš„åœ°æ•¸é‡"
            diversity_label = "ç›®çš„åœ°åˆ†æ•£åº¦"
            top_label = "ç›®çš„åœ°"
        else:  # role == 'dst'
            title = "ğŸ¯ ä¾†æºåˆ†æ:"
            count_label = "ä¸åŒä¾†æºæ•¸é‡"
            diversity_label = "ä¾†æºåˆ†æ•£åº¦"
            top_label = "ä¾†æº"

        print(title)
        print(f"   â€¢ {count_label}: {dst['unique_destinations']}")
        print(f"   â€¢ {diversity_label}: {dst['dst_diversity_ratio']:.3f}")

        # æª¢æŸ¥æ˜¯å¦ç‚ºæ•¸æ“šè³ªé‡å•é¡Œ
        has_zero_ip = any(d['ip'] == '0.0.0.0' or d['ip'] == '::' for d in dst['top_destinations'])
        if has_zero_ip:
            print(f"   âš ï¸  æ³¨æ„ï¼š{top_label}åŒ…å« 0.0.0.0ï¼Œé€™æ˜¯æ•¸æ“šæ¡é›†å•é¡Œï¼ˆå–®å‘æµé‡è¨˜éŒ„ï¼‰")
        elif dst['is_highly_distributed']:
            if role == 'src':
                print(f"   âš ï¸  é€£ç·šé«˜åº¦åˆ†æ•£ï¼ˆç–‘ä¼¼æƒæè¡Œç‚ºï¼‰")
            else:
                print(f"   âš ï¸  ä¾†æºé«˜åº¦åˆ†æ•£ï¼ˆç–‘ä¼¼é­å—æ”»æ“Šï¼‰")
        elif dst['is_concentrated']:
            if role == 'src':
                print(f"   âš ï¸  é€£ç·šé«˜åº¦é›†ä¸­ï¼ˆç–‘ä¼¼å®šå‘æ”»æ“Šï¼‰")
            else:
                print(f"   âš ï¸  ä¾†æºé«˜åº¦é›†ä¸­ï¼ˆè¢«å°‘æ•¸ä¾†æºå¤§é‡é€£ç·šï¼‰")

        # é¡¯ç¤º TOP 5 ç›®çš„åœ°/ä¾†æºï¼ˆçªå‡ºé¡¯ç¤ºï¼‰
        if dst['top_destinations']:
            # å‹•æ…‹èª¿æ•´æ¨™é¡Œï¼šå¦‚æœå°‘æ–¼5å€‹ï¼Œé¡¯ç¤ºå¯¦éš›æ•¸é‡
            num_to_display = min(5, len(dst['top_destinations']))
            if num_to_display == len(dst['top_destinations']) and num_to_display < 5:
                # å¦‚æœç¸½æ•¸å°‘æ–¼5å€‹ï¼Œé¡¯ç¤ºå¯¦éš›æ•¸é‡
                print(f"\n   é€£ç·šæ¬¡æ•¸æœ€å¤šçš„å‰ {num_to_display} å€‹{top_label}:")
            else:
                # å¦‚æœæœ‰5å€‹ä»¥ä¸Šï¼Œé¡¯ç¤º TOP 5
                print(f"\n   ğŸ” TOP 5 é€£ç·š{top_label}:")

            for i, dst_info in enumerate(dst['top_destinations'][:5], 1):
                ip = dst_info['ip']
                if ip in ['0.0.0.0', '::']:
                    ip_display = f"{ip} (æ•¸æ“šç¼ºå¤±)"
                else:
                    ip_display = self._format_ip_with_name(ip)
                print(f"      {i}. {ip_display:50s} â†’ {dst_info['count']:5,} æ¬¡ ({dst_info['percentage']:.1f}%)")

        # é¡¯ç¤ºé¡å¤–çš„ç›®çš„åœ°/ä¾†æºï¼ˆ6-20åï¼‰
        if len(dst['top_destinations']) > 5:
            num_to_show = min(20, len(dst['top_destinations']))
            remaining_to_show = num_to_show - 5
            if remaining_to_show > 0:
                print(f"\n   å…¶ä»–é«˜é »{top_label}ï¼ˆ6-{num_to_show}åï¼‰:")
                for i, dst_info in enumerate(dst['top_destinations'][5:num_to_show], 6):
                    ip = dst_info['ip']
                    if ip in ['0.0.0.0', '::']:
                        ip_display = f"{ip} (æ•¸æ“šç¼ºå¤±)"
                    else:
                        ip_display = self._format_ip_with_name(ip)
                    print(f"      {i}. {ip_display:50s} â†’ {dst_info['count']:5,} æ¬¡ ({dst_info['percentage']:.1f}%)")

            # å¦‚æœé‚„æœ‰æ›´å¤šï¼Œæç¤ºç”¨æˆ¶
            if len(dst['top_destinations']) > num_to_show:
                remaining = len(dst['top_destinations']) - num_to_show
                print(f"      ... é‚„æœ‰ {remaining} å€‹{top_label}")
        print()

        # é€šè¨ŠåŸ åˆ†æï¼ˆæ ¹æ“šè§’è‰²å‹•æ…‹æ¨™ç±¤ï¼‰
        port = analysis['port_analysis']
        if role == 'src':
            port_title = "ğŸ”Œ ç›®çš„é€šè¨ŠåŸ åˆ†æ:"
            port_label = "ç›®çš„é€šè¨ŠåŸ "
        else:  # role == 'dst'
            port_title = "ğŸ”Œ è¢«è¨ªå•çš„æœå‹™åŸ åˆ†æ (åˆ¤æ–·æ˜¯å¦è¢«æƒæ):"
            port_label = "è¢«è¨ªå•çš„æœå‹™åŸ "

        print(port_title)
        print(f"   â€¢ ä¸åŒ{port_label}æ•¸é‡: {port['unique_ports']}")
        print(f"   â€¢ {port_label}åˆ†æ•£åº¦: {port['port_diversity_ratio']:.3f}")
        if role == 'dst':
            # DST è§’è‰²é¡¯ç¤ºæœå‹™åŸ å’Œè‡¨æ™‚åŸ åˆ†å¸ƒ
            print(f"   â€¢ æœå‹™åŸ  (â‰¤{self.EPHEMERAL_PORT_START}): {port['unique_service_ports']} å€‹")
            print(f"   â€¢ è‡¨æ™‚åŸ  (>{self.EPHEMERAL_PORT_START}): {port['unique_ephemeral_ports']} å€‹")
            print(f"   â€¢ è‡¨æ™‚åŸ æ¯”ä¾‹: {port['ephemeral_ratio']*100:.1f}%")
        if port['is_scanning']:
            if role == 'src':
                print(f"   âš ï¸  ç–‘ä¼¼é€šè¨ŠåŸ æƒæ (åŸå› : {port.get('scanning_reason', 'unknown')})")
            else:
                print(f"   âš ï¸  ç–‘ä¼¼è¢«é€šè¨ŠåŸ æƒæ (åŸå› : {port.get('scanning_reason', 'unknown')})")
        elif role == 'dst' and port.get('scanning_reason') == 'normal_hybrid_server_client':
            print(f"   âœ“ æ­£å¸¸æ··åˆæµé‡ (æœå‹™åŸ å°‘ï¼Œå¤§éƒ¨åˆ†ç‚ºè‡¨æ™‚åŸ å›å‚³)")
        if port['is_sequential_scan']:
            print(f"   âš ï¸  æª¢æ¸¬åˆ°é€£çºŒé€šè¨ŠåŸ æ¨¡å¼")

        # é¡¯ç¤º TOP 5 é€šè¨ŠåŸ 
        if port['top_ports']:
            print(f"\n   ğŸ” TOP 5 {port_label}:")
            for i, port_info in enumerate(port['top_ports'][:5], 1):
                print(f"      {i}. {port_info['port']:5d} ({port_info['service']:15s}) â†’ {port_info['count']:5,} æ¬¡ ({port_info['percentage']:.1f}%)")
        print()

        # å”å®šåˆ†æ
        proto = analysis['protocol_analysis']
        print(f"ğŸ“¡ å”å®šåˆ†æ:")
        for proto_info in proto['protocol_distribution']:
            print(f"   â€¢ {proto_info['protocol']:10s}: {proto_info['count']:5,} ({proto_info['percentage']:.1f}%)")
        print()

        # è¡Œç‚ºåˆ†æ
        behaviors = analysis['behavioral_analysis']
        print(f"ğŸ” è¡Œç‚ºåˆ†æ:")
        if behaviors:
            for behavior in behaviors:
                severity_icon = {'HIGH': 'ğŸ”´', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸŸ¢'}.get(behavior['severity'], 'âšª')
                print(f"   {severity_icon} [{behavior['severity']}] {behavior['type']}")
                print(f"      {behavior['description']}")
            print()
        else:
            print(f"   âœ“ æœªæª¢æ¸¬åˆ°æ˜é¡¯ç•°å¸¸è¡Œç‚º")
            print()

        # æœ€çµ‚åˆ¤æ–·
        verdict = analysis['verdict']
        verdict_icons = {
            'TRUE_ANOMALY': 'ğŸš¨',
            'SUSPICIOUS': 'âš ï¸',
            'FALSE_POSITIVE': 'âœ…',
            'UNCLEAR': 'â“'
        }
        verdict_names = {
            'TRUE_ANOMALY': 'çœŸå¯¦ç•°å¸¸',
            'SUSPICIOUS': 'å¯ç–‘è¡Œç‚º',
            'FALSE_POSITIVE': 'èª¤å ±ï¼ˆæ­£å¸¸æµé‡ï¼‰',
            'UNCLEAR': 'ç„¡æ³•ç¢ºå®š'
        }

        print(f"{'='*100}")
        icon = verdict_icons.get(verdict['verdict'], 'â“')
        name = verdict_names.get(verdict['verdict'], verdict['verdict'])
        print(f"{icon} æœ€çµ‚åˆ¤æ–·: {name} (ç½®ä¿¡åº¦: {verdict['confidence']})")
        print(f"{'='*100}")
        print(f"ğŸ’¡ å»ºè­°: {verdict['recommendation']}\n")


def main():
    parser = argparse.ArgumentParser(description='é©—è­‰ Isolation Forest æª¢æ¸¬å‡ºçš„ç•°å¸¸')
    parser.add_argument('--ip', type=str, help='è¦åˆ†æçš„ IP åœ°å€')
    parser.add_argument('--minutes', type=int, default=30, help='åˆ†ææ™‚é–“ç¯„åœï¼ˆåˆ†é˜ï¼Œé»˜èª 30ï¼‰')
    parser.add_argument('--auto', action='store_true', help='è‡ªå‹•åˆ†ææœ€è¿‘æª¢æ¸¬åˆ°çš„ç•°å¸¸')
    parser.add_argument('--top', type=int, default=5, help='è‡ªå‹•æ¨¡å¼ä¸‹åˆ†æå‰ N å€‹ç•°å¸¸ï¼ˆé»˜èª 5ï¼‰')

    args = parser.parse_args()

    # è¼‰å…¥é…ç½®
    config = load_config()

    # é€£æ¥ Elasticsearch
    es_host = config.get('elasticsearch', {}).get('host', 'http://localhost:9200')
    es = Elasticsearch([es_host], timeout=30)

    if not es.ping():
        print(f"âŒ ç„¡æ³•é€£æ¥åˆ° Elasticsearch: {es_host}")
        sys.exit(1)

    print(f"âœ“ å·²é€£æ¥åˆ° Elasticsearch: {es_host}")

    verifier = AnomalyVerifier(es, config)

    # é¡¯ç¤º MySQL é€£ç·šç‹€æ…‹
    if verifier.mysql_connected:
        mysql_cfg = config.get('mysql', {})
        print(f"âœ“ å·²é€£æ¥åˆ° MySQL: {mysql_cfg.get('host')}:{mysql_cfg.get('port')} (è¨­å‚™åç¨±æŸ¥è©¢å·²å•Ÿç”¨)")
    else:
        print(f"â—‹ MySQL æœªé€£æ¥ (è¨­å‚™åç¨±æŸ¥è©¢åŠŸèƒ½åœç”¨)")
    print()

    if args.auto:
        print(f"ğŸ¤– è‡ªå‹•æ¨¡å¼ï¼šåˆ†ææœ€è¿‘æª¢æ¸¬åˆ°çš„å‰ {args.top} å€‹ç•°å¸¸\n")
        print("ğŸ’¡ æç¤ºï¼šå…ˆé‹è¡Œ realtime_detection.py ä¾†æª¢æ¸¬ç•°å¸¸\n")

        # é€™è£¡å¯ä»¥å¾æª¢æ¸¬çµæœä¸­è‡ªå‹•è®€å–ç•°å¸¸ IP
        # æš«æ™‚æç¤ºç”¨æˆ¶æ‰‹å‹•æŒ‡å®š
        print("è«‹å…ˆé‹è¡Œï¼špython3 realtime_detection.py --minutes 30")
        print("ç„¶å¾Œä½¿ç”¨ --ip åƒæ•¸æŒ‡å®šè¦åˆ†æçš„ IP\n")

    elif args.ip:
        verifier.verify_ip(args.ip, args.minutes)
    else:
        print("ç”¨æ³•:")
        print("  python3 verify_anomaly.py --ip 192.168.1.100 --minutes 30")
        print("  python3 verify_anomaly.py --auto --top 5")
        print()


if __name__ == '__main__':
    main()
