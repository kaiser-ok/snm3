# Pair 聚合時間間隔分析：5分鐘 vs 30分鐘

## 核心問題

**每 30 分鐘進行 pair aggregation 是否仍然有效？**

---

## 快速答案

### ✅ 對某些場景有效，但會失去關鍵能力

**結論：不建議用 30 分鐘，建議保持 5 分鐘**

理由：
1. ❌ 會失去精確的 Port Scan 偵測能力
2. ❌ 無法區分短時攻擊 vs 長期正常流量
3. ⚠️ 數據量減少有限（只減少 6 倍，不是 6 倍的效益）
4. ⚠️ 偵測延遲增加（從 5 分鐘變成 30 分鐘）

---

## 詳細分析

### 數據量對比

| 間隔 | Pairs/間隔 | 每天文檔數 | 30天儲存 | 減少比例 |
|------|-----------|----------|----------|---------|
| **5 分鐘** | 4,000 | 1,152,000 | ~600 MB | 基準 |
| **30 分鐘** | 24,000 | 192,000 | ~100 MB | **僅減少 17%** |

**關鍵發現：30 分鐘間隔的數據量減少並不明顯！**

原因：
```python
# 5 分鐘聚合
intervals_per_day = 24 × 12 = 288
total_docs = 4,000 × 288 = 1,152,000

# 30 分鐘聚合
intervals_per_day = 24 × 2 = 48
# 但每個間隔會有更多 unique pairs！
pairs_per_30min = 4,000 × 6 = 24,000 (不是簡單的 6 倍，而是更多)
total_docs = 24,000 × 48 = 1,152,000

# 實際上可能更多，因為：
# - 30 分鐘內會有更多不同的 src-dst 組合
# - 短期的臨時連線也會被聚合進來
```

---

## 關鍵問題：失去的偵測能力

### 問題 1: Port Scan 偵測失效

#### 場景：攻擊者在 5 分鐘內掃描完成

**5 分鐘聚合（有效）：**
```json
時間段 13:00-13:05:
{
  "src_ip": "attacker",
  "dst_ip": "target",
  "unique_dst_ports": 5000,  // ← 5分鐘內掃描 5000 個端口
  "flow_count": 5000,
  "avg_bytes": 64
}

判斷：✅ Port Scan（置信度 95%）
```

**30 分鐘聚合（失效）：**
```json
時間段 13:00-13:30:
{
  "src_ip": "attacker",
  "dst_ip": "target",
  "unique_dst_ports": 5000,  // ← 看起來一樣
  "flow_count": 5000,
  "avg_bytes": 64
}

但混雜了：
  - 13:00-13:05: 攻擊掃描 5000 端口
  - 13:05-13:30: 正常流量 0 端口

問題：無法判斷是「5分鐘快速掃描」還是「30分鐘慢速掃描」
```

#### 更嚴重的問題：微服務誤報無法排除

**微服務的正常模式（5分鐘）：**
```json
13:00-13:05:
  (gateway, service-1): unique_dst_ports = 1  ✅
  (gateway, service-2): unique_dst_ports = 1  ✅
  ...
  (gateway, service-50): unique_dst_ports = 1  ✅

判斷：每個 pair 都只用 1 個端口 → 微服務模式
```

**同樣的流量（30分鐘）：**
```json
13:00-13:30:
  (gateway, service-1): unique_dst_ports = 6  ← 30分鐘內可能有 6 次重啟/重連
  (gateway, service-2): unique_dst_ports = 4
  ...
  (gateway, service-50): unique_dst_ports = 5

平均每個服務: 5 個端口

判斷：❌ 無法確定是微服務還是慢速掃描！
```

---

### 問題 2: 無法區分攻擊模式

#### 場景：區分快速攻擊 vs 正常使用

**真實 Port Scan（快速）：**
```
攻擊者在 2 分鐘內掃描 1000 個端口
```

**正常用戶（慢速）：**
```
用戶在 30 分鐘內訪問 1000 個不同的網頁/API（不同端口）
```

**5 分鐘聚合能區分：**
```
13:00-13:05:
  attacker: unique_dst_ports = 1000, flow_count = 1000
  → 判斷：Port Scan（速度異常快）

  normal_user: unique_dst_ports = 170, flow_count = 200
  → 判斷：正常（速度正常）
```

**30 分鐘聚合無法區分：**
```
13:00-13:30:
  attacker: unique_dst_ports = 1000, flow_count = 1000
  normal_user: unique_dst_ports = 1000, flow_count = 1200

兩者看起來很相似！❌
```

---

### 問題 3: 時間敏感性降低

| 攻擊類型 | 持續時間 | 5分鐘聚合 | 30分鐘聚合 |
|---------|---------|----------|-----------|
| **快速 Port Scan** | 2-5 分鐘 | ✅ 立即偵測 | ⚠️ 延遲 25 分鐘 |
| **Burst Attack** | 1-3 分鐘 | ✅ 能偵測 | ❌ 可能被稀釋 |
| **C2 通訊** | 持續性 | ✅ 能偵測 | ✅ 能偵測 |
| **資料外洩** | 10-30 分鐘 | ✅ 能偵測 | ✅ 能偵測 |

---

## 實際測試對比

### 測試場景：微服務 Gateway

**環境：**
- Gateway: 192.168.10.135
- 連接 50 個微服務
- 每個服務使用固定端口（8001-8050）

#### 5 分鐘聚合結果

```json
時間段 13:00-13:05:
  pairs 數量: 50

  範例 pairs:
  (192.168.10.135, service-1:8001): {
    "unique_dst_ports": 1,
    "flow_count": 20,
    "avg_bytes": 1500
  }
  (192.168.10.135, service-2:8002): {
    "unique_dst_ports": 1,
    "flow_count": 18,
    "avg_bytes": 1600
  }
  ...

判斷邏輯:
  - 每個 pair 的 unique_dst_ports = 1
  - ✅ 確定是微服務模式（置信度 90%）
```

#### 30 分鐘聚合結果

```json
時間段 13:00-13:30:
  pairs 數量: 50

  範例 pairs:
  (192.168.10.135, service-1): {
    "unique_dst_ports": 3,  // ← 30分鐘內可能有重啟、重連
    "flow_count": 120,
    "avg_bytes": 1550
  }
  (192.168.10.135, service-2): {
    "unique_dst_ports": 2,
    "flow_count": 108,
    "avg_bytes": 1620
  }
  ...

判斷邏輯:
  - 每個 pair 的 unique_dst_ports = 2-4
  - ⚠️ 無法確定：可能是微服務，也可能是慢速掃描
  - 降低置信度到 60-70%
```

---

## 數據量實際估算

### 5 分鐘聚合

```python
# 假設每 5 分鐘的 unique pairs
external_connections = 2000  # 外部連線 pairs
large_flows = 800            # 大流量 pairs
abnormal_ports = 1200        # 異常端口 pairs

# 去重後（有重疊）
total_unique_pairs_5min = 4000

# 每天
intervals_per_day = 288
total_docs_per_day = 4000 × 288 = 1,152,000

# 30 天
total_docs_30days = 1,152,000 × 30 = 34,560,000
storage_30days = 34,560,000 × 500 bytes ≈ 17 GB
```

### 30 分鐘聚合

```python
# 30 分鐘內的 unique pairs（不是簡單的 6 倍）
# 因為會有更多臨時的、短期的連線

# 估算：30 分鐘內會出現的 unique pairs
external_connections_30min = 2000 × 5 = 10000  # 不是 6 倍，因為有新的臨時連線
large_flows_30min = 800 × 4 = 3200
abnormal_ports_30min = 1200 × 5 = 6000

# 去重後
total_unique_pairs_30min = 15000  # 而不是 4000 × 6 = 24000

# 每天
intervals_per_day = 48
total_docs_per_day = 15000 × 48 = 720,000

# 30 天
total_docs_30days = 720,000 × 30 = 21,600,000
storage_30days = 21,600,000 × 500 bytes ≈ 11 GB

# 減少比例
reduction = (17 - 11) / 17 = 35%
```

**結論：30 分鐘聚合只能減少約 35% 的儲存，但失去了關鍵的偵測能力！**

---

## 方案對比

| 維度 | 5 分鐘聚合 | 30 分鐘聚合 | 差異 |
|------|-----------|------------|------|
| **儲存空間（30天）** | 17 GB | 11 GB | 減少 35% ⚠️ |
| **Port Scan 偵測** | ✅ 精確 | ❌ 不準確 | 嚴重降級 |
| **微服務識別** | ✅ 準確 | ⚠️ 模糊 | 降級 |
| **攻擊模式區分** | ✅ 能區分 | ❌ 無法區分 | 失效 |
| **偵測延遲** | 5 分鐘 | 30 分鐘 | +25 分鐘 |
| **時間精確度** | ✅ 高 | ❌ 低 | 降級 |

---

## 替代方案：如果真的需要減少數據量

### 方案 1: 更嚴格的篩選條件（推薦）

保持 5 分鐘間隔，但縮小篩選範圍：

```json
{
  "query": {
    "bool": {
      "should": [
        // 只保留外部連線（移除其他條件）
        {
          "bool": {
            "must_not": [
              {"wildcard": {"IPV4_DST_ADDR": "192.168.*"}},
              {"wildcard": {"IPV4_DST_ADDR": "10.*"}},
              // ...
            ]
          }
        }
      ],
      "minimum_should_match": 1
    }
  }
}
```

**效果：**
- 數據量減少 50-70%（只聚合外部連線）
- 保持 5 分鐘的時間精確度
- 不失去偵測能力

### 方案 2: 分層聚合

**Tier 1: 5 分鐘聚合（高優先級）**
- 外部連線
- 異常端口
- 保留 7 天

**Tier 2: 30 分鐘聚合（低優先級）**
- 內網大流量
- 保留 30 天

```python
# 查詢邏輯
def query_pairs(src_ip, dst_ip, time_range):
    # 優先查詢 5 分鐘聚合
    result = query_5min_pairs(src_ip, dst_ip, time_range)

    if result:
        return result

    # 如果沒有（可能是內網流量），查詢 30 分鐘聚合
    result = query_30min_pairs(src_ip, dst_ip, time_range)

    return result
```

### 方案 3: 動態保留策略

```python
# 根據重要性動態調整保留時間
if is_anomaly(pair):
    retention = 30 days  # 異常數據保留 30 天
else:
    retention = 7 days   # 正常數據保留 7 天
```

---

## 實際建議

### ✅ 推薦：保持 5 分鐘 + 嚴格篩選

```bash
# 只聚合外部連線（最重要）
# 預期數據量：2,000 pairs/5min
# 30 天儲存：~8 GB
```

**理由：**
1. 保持時間精確度（關鍵）
2. 保持偵測能力（關鍵）
3. 數據量仍然可控（8 GB vs 17 GB）

### ⚠️ 可考慮：5分鐘（外部）+ 30分鐘（內網）

```bash
# Transform 1: 外部連線（5 分鐘）
# Transform 2: 內網大流量（30 分鐘）
```

**理由：**
- 外部連線保持高精確度
- 內網流量降低儲存成本
- 綜合最佳

### ❌ 不推薦：全部用 30 分鐘

**理由：**
1. 數據量減少有限（只減少 35%）
2. 失去關鍵的偵測能力
3. 無法區分攻擊模式
4. 微服務識別不準確

---

## 決策流程圖

```
是否需要減少數據量？
  ├─ No  → 使用 5 分鐘聚合（全部外部+大流量+異常端口）
  │        數據量：4,000 pairs/5min, 17 GB/30天
  │
  └─ Yes → 考慮以下方案：
      │
      ├─ 方案 1（推薦）：5分鐘 + 更嚴格篩選
      │   └─ 只聚合外部連線
      │   └─ 數據量：2,000 pairs/5min, 8 GB/30天
      │   └─ 保持偵測能力 ✅
      │
      ├─ 方案 2：分層聚合
      │   ├─ 外部連線：5 分鐘（保留 7 天）
      │   └─ 內網流量：30 分鐘（保留 30 天）
      │   └─ 總數據量：~10 GB/30天
      │
      └─ 方案 3（不推薦）：全部 30 分鐘
          └─ 數據量：15,000 pairs/30min, 11 GB/30天
          └─ 失去偵測能力 ❌
```

---

## 總結

### 問題：每 30 分鐘進行 pair aggregation 是否仍然有效？

**答案：不建議**

**核心原因：**
1. ❌ **數據量減少有限**：只減少 35%（不值得）
2. ❌ **失去時間精確度**：無法區分快速攻擊 vs 慢速正常使用
3. ❌ **Port Scan 偵測失效**：無法區分真實掃描 vs 微服務
4. ❌ **偵測延遲增加**：從 5 分鐘延遲到 30 分鐘

**更好的方案：**
- ✅ 保持 5 分鐘間隔
- ✅ 使用更嚴格的篩選條件（只聚合外部連線）
- ✅ 數據量減少 50%（8 GB vs 17 GB）
- ✅ 保持完整的偵測能力

**如果真的需要 30 分鐘：**
- 只用於內網流量的歷史分析
- 外部連線仍然用 5 分鐘
- 分層聚合架構
