#!/usr/bin/env python3
"""
æ¸¬è©¦é€šè¨ŠåŸ æ”¹é€²æ•ˆæœ

å¿«é€Ÿæ¸¬è©¦æ–°çš„æº/ç›®çš„é€šè¨ŠåŸ ç‰¹å¾µæ˜¯å¦æ­£ç¢ºè¨ˆç®—
"""

import sys
from elasticsearch import Elasticsearch
from nad.utils.config_loader import load_config
from nad.ml.feature_engineer import FeatureEngineer

def test_feature_extraction():
    """æ¸¬è©¦ç‰¹å¾µæå–"""
    print("\n" + "="*100)
    print("æ¸¬è©¦é€šè¨ŠåŸ ç‰¹å¾µæå–")
    print("="*100 + "\n")

    # è¼‰å…¥é…ç½®
    config = load_config()
    es_host = config.get('elasticsearch', {}).get('host', 'http://localhost:9200')
    es = Elasticsearch([es_host], timeout=30)

    if not es.ping():
        print(f"âŒ ç„¡æ³•é€£æ¥åˆ° Elasticsearch: {es_host}")
        sys.exit(1)

    print(f"âœ“ å·²é€£æ¥åˆ° Elasticsearch: {es_host}\n")

    # æŸ¥è©¢æœ‰æ–°æ¬„ä½çš„è¨˜éŒ„
    query = {
        "size": 10,
        "query": {
            "exists": {"field": "unique_src_ports"}
        },
        "sort": [{"time_bucket": "desc"}]
    }

    try:
        response = es.search(index="netflow_stats_5m", **query)
        hits = response['hits']['hits']

        if not hits:
            print("âŒ æ²’æœ‰æ‰¾åˆ°æœ‰æ–°æ¬„ä½çš„è¨˜éŒ„")
            print("   è«‹ç­‰å¾… Transform ç”¢ç”Ÿè³‡æ–™å¾Œå†è©¦")
            sys.exit(1)

        print(f"âœ“ æ‰¾åˆ° {len(hits)} ç­†æ¸¬è©¦è¨˜éŒ„\n")

        # å‰µå»ºç‰¹å¾µå·¥ç¨‹å™¨
        fe = FeatureEngineer(config)

        print(f"ğŸ“Š ç‰¹å¾µæ•¸é‡: {len(fe.feature_names)}")
        print(f"   ç‰¹å¾µåç¨±: {', '.join(fe.feature_names)}\n")

        print("="*100)
        print("æ¸¬è©¦è¨˜éŒ„ç‰¹å¾µæå–")
        print("="*100 + "\n")

        # æ¸¬è©¦å¹¾å€‹è¨˜éŒ„
        for i, hit in enumerate(hits[:5], 1):
            record = hit['_source']
            print(f"{i}. IP: {record['src_ip']}")
            print(f"   æ™‚é–“: {record['time_bucket']}")
            print(f"   é€£ç·šæ•¸: {record['flow_count']:,}")
            print(f"   ä¸åŒç›®çš„åœ°: {record['unique_dsts']}")
            print(f"   ä¸åŒæºé€šè¨ŠåŸ : {record.get('unique_src_ports', 'N/A')}")
            print(f"   ä¸åŒç›®çš„é€šè¨ŠåŸ : {record.get('unique_dst_ports', 'N/A')}")

            # æå–ç‰¹å¾µ
            features = fe.extract_features(record)

            print(f"\n   è¨ˆç®—çš„ç‰¹å¾µ:")
            print(f"     ç›®çš„åœ°åˆ†æ•£åº¦: {features['dst_diversity']:.3f}")
            print(f"     æºé€šè¨ŠåŸ åˆ†æ•£åº¦: {features['src_port_diversity']:.3f}")
            print(f"     ç›®çš„é€šè¨ŠåŸ åˆ†æ•£åº¦: {features['dst_port_diversity']:.3f}")
            print(f"     æ˜¯å¦é«˜é€£ç·šæ•¸: {features['is_high_connection']}")
            print(f"     æ˜¯å¦æƒææ¨¡å¼: {features['is_scanning_pattern']}")
            print(f"     æ˜¯å¦ä¼ºæœå™¨å›æ‡‰: {features['is_likely_server_response']}")

            # åˆ¤æ–·
            if features['is_likely_server_response']:
                print(f"   âœ… åˆ¤æ–·: ä¼ºæœå™¨å›æ‡‰æµé‡")
            elif features['is_scanning_pattern']:
                print(f"   ğŸš¨ åˆ¤æ–·: æƒææ¨¡å¼")
            elif features['is_high_connection']:
                print(f"   âš ï¸  åˆ¤æ–·: é«˜é€£ç·šæ•¸")
            else:
                print(f"   âœ“ åˆ¤æ–·: æ­£å¸¸æµé‡")

            print()

        print("="*100)
        print("âœ… ç‰¹å¾µæå–æ¸¬è©¦å®Œæˆ")
        print("="*100 + "\n")

        # çµ±è¨ˆä¼ºæœå™¨å›æ‡‰çš„æ¯”ä¾‹
        server_responses = sum(1 for hit in hits if
                               fe.extract_features(hit['_source'])['is_likely_server_response'])
        scanning = sum(1 for hit in hits if
                      fe.extract_features(hit['_source'])['is_scanning_pattern'])

        print("ğŸ“ˆ çµ±è¨ˆçµæœ:")
        print(f"   ä¼ºæœå™¨å›æ‡‰: {server_responses}/{len(hits)} ({server_responses/len(hits)*100:.1f}%)")
        print(f"   æƒææ¨¡å¼: {scanning}/{len(hits)} ({scanning/len(hits)*100:.1f}%)")
        print()

        print("ğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   1. åŸ·è¡Œ ./monitor_transform.sh æª¢æŸ¥è³‡æ–™é‡")
        print("   2. ç•¶è³‡æ–™é‡ > 10,000 ç­†æ™‚:")
        print("      python3 train_isolation_forest.py --days 1 --evaluate --exclude-servers")
        print("   3. æ¸¬è©¦ AD ä¼ºæœå™¨:")
        print("      python3 realtime_detection.py --minutes 30 --exclude-servers")
        print("      python3 verify_anomaly.py --ip 192.168.10.135 --minutes 30")
        print()

    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def test_server_detection_logic():
    """æ¸¬è©¦ä¼ºæœå™¨æª¢æ¸¬é‚è¼¯"""
    print("\n" + "="*100)
    print("æ¸¬è©¦ä¼ºæœå™¨æª¢æ¸¬é‚è¼¯")
    print("="*100 + "\n")

    config = load_config()
    fe = FeatureEngineer(config)

    # æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        {
            "name": "AD ä¼ºæœå™¨ï¼ˆDNS + LDAPï¼‰",
            "record": {
                "flow_count": 6000,
                "total_bytes": 120000000,
                "total_packets": 600000,
                "unique_dsts": 67,
                "unique_src_ports": 2,      # 53, 389
                "unique_dst_ports": 6000,   # å®¢æˆ¶ç«¯éš¨æ©ŸåŸ 
                "avg_bytes": 20000,
                "max_bytes": 100000,
            },
            "expected": "ä¼ºæœå™¨å›æ‡‰"
        },
        {
            "name": "DNS ä¼ºæœå™¨",
            "record": {
                "flow_count": 5000,
                "total_bytes": 25000000,
                "total_packets": 250000,
                "unique_dsts": 50,
                "unique_src_ports": 1,      # 53
                "unique_dst_ports": 5000,   # å®¢æˆ¶ç«¯éš¨æ©ŸåŸ 
                "avg_bytes": 5000,
                "max_bytes": 15000,
            },
            "expected": "ä¼ºæœå™¨å›æ‡‰"
        },
        {
            "name": "é€šè¨ŠåŸ æƒæ",
            "record": {
                "flow_count": 5000,
                "total_bytes": 25000000,
                "total_packets": 250000,
                "unique_dsts": 50,
                "unique_src_ports": 4800,   # éš¨æ©ŸæºåŸ 
                "unique_dst_ports": 200,    # æƒæå¤šå€‹åŸ 
                "avg_bytes": 5000,
                "max_bytes": 15000,
            },
            "expected": "æƒæ"
        },
        {
            "name": "ç¶²è·¯æƒæ",
            "record": {
                "flow_count": 1000,
                "total_bytes": 5000000,
                "total_packets": 50000,
                "unique_dsts": 100,
                "unique_src_ports": 900,    # éš¨æ©ŸæºåŸ 
                "unique_dst_ports": 5,      # å›ºå®šåŸ ï¼ˆå¦‚ 22, 80ï¼‰
                "avg_bytes": 5000,
                "max_bytes": 10000,
            },
            "expected": "æƒæ"
        },
    ]

    for case in test_cases:
        print(f"æ¸¬è©¦: {case['name']}")
        print(f"  é æœŸ: {case['expected']}")

        features = fe.extract_features(case['record'])

        print(f"  ç‰¹å¾µ:")
        print(f"    æºé€šè¨ŠåŸ åˆ†æ•£åº¦: {features['src_port_diversity']:.3f}")
        print(f"    ç›®çš„é€šè¨ŠåŸ åˆ†æ•£åº¦: {features['dst_port_diversity']:.3f}")
        print(f"    ä¸åŒæºé€šè¨ŠåŸ : {features['unique_src_ports']}")
        print(f"    ä¸åŒç›®çš„é€šè¨ŠåŸ : {features['unique_dst_ports']}")

        if features['is_likely_server_response']:
            result = "ä¼ºæœå™¨å›æ‡‰"
            icon = "âœ…"
        elif features['is_scanning_pattern']:
            result = "æƒæ"
            icon = "ğŸš¨"
        else:
            result = "æ­£å¸¸"
            icon = "âœ“"

        match = "âœ… æ­£ç¢º" if result == case['expected'] else "âŒ éŒ¯èª¤"
        print(f"  çµæœ: {icon} {result} {match}")
        print()

    print("="*100)
    print("âœ… é‚è¼¯æ¸¬è©¦å®Œæˆ")
    print("="*100 + "\n")


if __name__ == "__main__":
    print("\n" + "="*100)
    print("é€šè¨ŠåŸ æ”¹é€²æ¸¬è©¦")
    print("="*100)

    # æ¸¬è©¦ 1: é‚è¼¯æ¸¬è©¦ï¼ˆä¸éœ€è¦è³‡æ–™ï¼‰
    test_server_detection_logic()

    # æ¸¬è©¦ 2: å¯¦éš›è³‡æ–™æ¸¬è©¦ï¼ˆéœ€è¦ Transform è³‡æ–™ï¼‰
    test_feature_extraction()
