#!/usr/bin/env python3
"""
åˆ†é¡å™¨é–¾å€¼å„ªåŒ–å·¥å…·

åŸºæ–¼æ­·å²ç•°å¸¸æ•¸æ“šï¼Œåˆ†æä¸¦å„ªåŒ–å¨è„…åˆ†é¡å™¨çš„é–¾å€¼ã€‚
é€™å€‹å·¥å…·æœƒï¼š
1. æ”¶é›† Isolation Forest æª¢æ¸¬åˆ°çš„æ‰€æœ‰ç•°å¸¸
2. åˆ†ææ¯ç¨®å¨è„…é¡å‹çš„ç‰¹å¾µåˆ†ä½ˆ
3. åŸºæ–¼çµ±è¨ˆæ–¹æ³•æ¨è–¦æœ€å„ªé–¾å€¼
4. ç”Ÿæˆè©³ç´°çš„åˆ†æå ±å‘Š

åƒè€ƒæ–‡ç»ï¼š
- Port Scan: PLOS ONE (2018) - Detection of slow port scans in flow-based network traffic
- DNS Tunneling: GIAC (2016) - Detecting DNS Tunneling
- DDoS Detection: MDPI Sensors (2023) - Detection and Mitigation of SYN Flooding Attacks
- Data Exfiltration: TU Delft (2019) - Automated data exfiltration detection using netflow metadata
- C2 Detection: ScienceDirect (2013) - Periodic behavior in botnet traffic
- Network Scan: Splunk Research - Detection of Internal Horizontal Port Scan
"""

import sys
import argparse
import json
import warnings
from datetime import datetime, timedelta
from collections import defaultdict
from typing import Dict, List, Tuple
import numpy as np

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

from nad.utils import load_config
from nad.ml import OptimizedIsolationForest
from nad.ml.anomaly_classifier import AnomalyClassifier


class ClassifierThresholdOptimizer:
    """
    åˆ†é¡å™¨é–¾å€¼å„ªåŒ–å™¨

    åŸºæ–¼æ­·å²ç•°å¸¸æ•¸æ“šåˆ†ææœ€å„ªé–¾å€¼
    """

    def __init__(self, config):
        """åˆå§‹åŒ–å„ªåŒ–å™¨"""
        self.config = config
        self.detector = OptimizedIsolationForest(config)
        self.classifier = AnomalyClassifier(config)

        # å­˜å„²å„é¡ç•°å¸¸çš„ç‰¹å¾µæ•¸æ“š
        self.anomaly_features = {
            'PORT_SCAN': [],
            'NETWORK_SCAN': [],
            'DNS_TUNNELING': [],
            'DDOS': [],
            'DATA_EXFILTRATION': [],
            'C2_COMMUNICATION': [],
            'NORMAL_HIGH_TRAFFIC': [],
            'UNKNOWN': []
        }

        # æ‰€æœ‰ç•°å¸¸ç‰¹å¾µï¼ˆç”¨æ–¼å…¨å±€çµ±è¨ˆï¼‰
        self.all_anomaly_features = []

    def collect_historical_anomalies(self, days: int = 7) -> int:
        """
        æ”¶é›†æ­·å²ç•°å¸¸æ•¸æ“š

        Args:
            days: åˆ†æéå» N å¤©çš„æ•¸æ“š

        Returns:
            æ”¶é›†åˆ°çš„ç•°å¸¸æ•¸é‡
        """
        print(f"\n{'='*80}")
        print(f"æ”¶é›†éå» {days} å¤©çš„ç•°å¸¸æ•¸æ“š...")
        print(f"{'='*80}\n")

        # è¼‰å…¥æ¨¡å‹
        try:
            self.detector._load_model()
        except Exception as e:
            print(f"âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹: {e}")
            print(f"   è«‹å…ˆè¨“ç·´æ¨¡å‹: python3 train_isolation_forest.py --days 7\n")
            return 0

        total_anomalies = 0

        # æŒ‰å¤©æ”¶é›†æ•¸æ“šï¼ˆé¿å…ä¸€æ¬¡æŸ¥è©¢å¤ªå¤šæ•¸æ“šï¼‰
        for day_offset in range(days):
            print(f"ğŸ“… åˆ†æç¬¬ {day_offset + 1}/{days} å¤©...")

            # è¨ˆç®—è©²å¤©çš„åˆ†é˜æ•¸
            minutes = (day_offset * 1440) + 720  # å¾ day_offset å¤©å‰çš„ä¸­é–“é–‹å§‹

            try:
                # æª¢æ¸¬è©²æ™‚é–“æ®µçš„ç•°å¸¸
                anomalies = self.detector.predict_realtime(recent_minutes=1440)

                if anomalies:
                    print(f"   æ‰¾åˆ° {len(anomalies)} å€‹ç•°å¸¸")

                    # å°æ¯å€‹ç•°å¸¸é€²è¡Œåˆ†é¡ä¸¦å­˜å„²
                    for anomaly in anomalies:
                        features = anomaly['features']
                        context = {
                            'timestamp': datetime.fromisoformat(
                                anomaly['time_bucket'].replace('Z', '+00:00')
                            ),
                            'src_ip': anomaly['src_ip'],
                            'anomaly_score': anomaly['anomaly_score']
                        }

                        # ä½¿ç”¨ç•¶å‰åˆ†é¡å™¨é€²è¡Œåˆ†é¡
                        classification = self.classifier.classify(features, context)
                        threat_class = classification['class']

                        # å­˜å„²ç‰¹å¾µæ•¸æ“š
                        self.anomaly_features[threat_class].append(features)
                        self.all_anomaly_features.append({
                            'features': features,
                            'class': threat_class,
                            'timestamp': context['timestamp'],
                            'src_ip': context['src_ip']
                        })

                    total_anomalies += len(anomalies)
                else:
                    print(f"   æœªç™¼ç¾ç•°å¸¸")

            except Exception as e:
                print(f"   âš ï¸  åˆ†æå¤±æ•—: {e}")
                continue

        print(f"\n{'='*80}")
        print(f"æ”¶é›†å®Œæˆï¼šå…± {total_anomalies} å€‹ç•°å¸¸")
        print(f"{'='*80}\n")

        # é¡¯ç¤ºå„é¡åˆ¥çµ±è¨ˆ
        print("å¨è„…é¡åˆ¥åˆ†ä½ˆï¼š\n")
        for threat_class, features_list in self.anomaly_features.items():
            count = len(features_list)
            if count > 0:
                percentage = (count / total_anomalies * 100) if total_anomalies > 0 else 0
                print(f"  {threat_class:25} {count:5} å€‹ ({percentage:5.1f}%)")

        print()
        return total_anomalies

    def analyze_threat_class(self, threat_class: str) -> Dict:
        """
        åˆ†æç‰¹å®šå¨è„…é¡åˆ¥çš„ç‰¹å¾µåˆ†ä½ˆ

        Args:
            threat_class: å¨è„…é¡åˆ¥åç¨±

        Returns:
            åˆ†æçµæœå­—å…¸
        """
        features_list = self.anomaly_features[threat_class]

        if not features_list:
            return {
                'count': 0,
                'message': 'ç„¡æ•¸æ“š'
            }

        # æå–é—œéµç‰¹å¾µ
        key_features = [
            'flow_count', 'unique_dsts', 'unique_dst_ports',
            'avg_bytes', 'total_bytes', 'dst_diversity',
            'dst_port_diversity'
        ]

        analysis = {
            'count': len(features_list),
            'features': {}
        }

        for feature in key_features:
            values = [f.get(feature, 0) for f in features_list]

            if values:
                analysis['features'][feature] = {
                    'min': float(np.min(values)),
                    'max': float(np.max(values)),
                    'mean': float(np.mean(values)),
                    'median': float(np.median(values)),
                    'std': float(np.std(values)),
                    'p10': float(np.percentile(values, 10)),
                    'p25': float(np.percentile(values, 25)),
                    'p75': float(np.percentile(values, 75)),
                    'p90': float(np.percentile(values, 90)),
                    'p95': float(np.percentile(values, 95)),
                    'p99': float(np.percentile(values, 99))
                }

        return analysis

    def recommend_thresholds(self) -> Dict:
        """
        åŸºæ–¼æ•¸æ“šåˆ†ææ¨è–¦æ–°çš„é–¾å€¼

        Returns:
            æ¨è–¦é–¾å€¼å­—å…¸
        """
        recommendations = {}

        # ========== 1. PORT_SCAN ==========
        port_scan_analysis = self.analyze_threat_class('PORT_SCAN')
        if port_scan_analysis['count'] > 5:
            features = port_scan_analysis['features']

            # æ ¹æ“šç ”ç©¶æ–‡ç»ï¼šç«¯å£æƒæé€šå¸¸æƒæ > 100 å€‹ç«¯å£
            # æˆ‘å€‘ä½¿ç”¨ P10 ä½œç‚ºæœ€å°é–¾å€¼ï¼ˆä¿å®ˆä¼°è¨ˆï¼‰
            recommendations['PORT_SCAN'] = {
                'unique_dst_ports': {
                    'current': 100,
                    'recommended': max(50, int(features['unique_dst_ports']['p10'])),
                    'rationale': 'P10 å€¼ï¼ŒåŸºæ–¼ PLOS ONE (2018) ç«¯å£æƒæç ”ç©¶',
                    'reference': 'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0204507'
                },
                'avg_bytes': {
                    'current': 5000,
                    'recommended': int(features['avg_bytes']['p75']),
                    'rationale': 'P75 å€¼ï¼Œç«¯å£æƒæä½¿ç”¨å°å°åŒ…',
                    'reference': 'Nmap å·¥å…·ç‰¹å¾µåˆ†æ'
                },
                'dst_port_diversity': {
                    'current': 0.5,
                    'recommended': round(features['dst_port_diversity']['p25'], 2),
                    'rationale': 'P25 å€¼ï¼Œä¿è­‰ç«¯å£åˆ†æ•£æ€§',
                    'reference': 'ç‰¹å¾µå·¥ç¨‹æœ€ä½³å¯¦è¸'
                }
            }

        # ========== 2. NETWORK_SCAN ==========
        network_scan_analysis = self.analyze_threat_class('NETWORK_SCAN')
        if network_scan_analysis['count'] > 5:
            features = network_scan_analysis['features']

            # æ ¹æ“š Splunk ç ”ç©¶ï¼šæ°´å¹³æƒæé€šå¸¸ > 50 å€‹ç›®æ¨™
            recommendations['NETWORK_SCAN'] = {
                'unique_dsts': {
                    'current': 50,
                    'recommended': max(30, int(features['unique_dsts']['p10'])),
                    'rationale': 'P10 å€¼ï¼ŒåŸºæ–¼ Splunk æ°´å¹³æƒææª¢æ¸¬ç ”ç©¶',
                    'reference': 'https://research.splunk.com/network/1ff9eb9a-7d72-4993-a55e-59a839e607f1/'
                },
                'dst_diversity': {
                    'current': 0.3,
                    'recommended': round(features['dst_diversity']['p25'], 2),
                    'rationale': 'P25 å€¼ï¼Œç›®æ¨™åˆ†æ•£åº¦æŒ‡æ¨™',
                    'reference': 'ç¶²è·¯æƒæè¡Œç‚ºåˆ†æ'
                },
                'flow_count': {
                    'current': 1000,
                    'recommended': int(features['flow_count']['p10']),
                    'rationale': 'P10 å€¼ï¼Œæƒæé€šå¸¸ç”¢ç”Ÿå¤§é‡é€£ç·š',
                    'reference': 'æµé‡åˆ†ææœ€ä½³å¯¦è¸'
                }
            }

        # ========== 3. DNS_TUNNELING ==========
        dns_tunnel_analysis = self.analyze_threat_class('DNS_TUNNELING')
        if dns_tunnel_analysis['count'] > 5:
            features = dns_tunnel_analysis['features']

            # æ ¹æ“š GIAC ç ”ç©¶ï¼šDNS éš§é“ç‰¹å¾µ
            recommendations['DNS_TUNNELING'] = {
                'flow_count': {
                    'current': 1000,
                    'recommended': int(features['flow_count']['p10']),
                    'rationale': 'P10 å€¼ï¼ŒDNS éš§é“éœ€è¦å¤§é‡æŸ¥è©¢',
                    'reference': 'https://www.giac.org/paper/gcia/1116/detecting-dns-tunneling/108367'
                },
                'avg_bytes': {
                    'current': 1000,
                    'recommended': int(features['avg_bytes']['p75']),
                    'rationale': 'P75 å€¼ï¼ŒDNS æŸ¥è©¢é€šå¸¸ < 512 bytes',
                    'reference': 'DNS å”è­°æ¨™æº– (RFC 1035)'
                },
                'unique_dsts': {
                    'current': 5,
                    'recommended': max(3, int(features['unique_dsts']['p90'])),
                    'rationale': 'P90 å€¼ï¼Œéš§é“é€šå¸¸åªç”¨å°‘æ•¸ DNS æœå‹™å™¨',
                    'reference': 'DNS éš§é“å·¥å…·ç‰¹å¾µåˆ†æ'
                }
            }

        # ========== 4. DDOS ==========
        ddos_analysis = self.analyze_threat_class('DDOS')
        if ddos_analysis['count'] > 5:
            features = ddos_analysis['features']

            # æ ¹æ“š MDPI Sensors (2023) ç ”ç©¶
            recommendations['DDOS'] = {
                'flow_count': {
                    'current': 10000,
                    'recommended': int(features['flow_count']['p10']),
                    'rationale': 'P10 å€¼ï¼ŒDDoS ç”¢ç”Ÿæ¥µé«˜é€£ç·šæ•¸',
                    'reference': 'https://www.mdpi.com/1424-8220/23/8/3817'
                },
                'avg_bytes': {
                    'current': 500,
                    'recommended': int(features['avg_bytes']['p75']),
                    'rationale': 'P75 å€¼ï¼ŒSYN Flood ä½¿ç”¨æ¥µå°å°åŒ…',
                    'reference': 'SYN Flood æ”»æ“Šç‰¹å¾µåˆ†æ'
                },
                'unique_dsts': {
                    'current': 20,
                    'recommended': max(10, int(features['unique_dsts']['p90'])),
                    'rationale': 'P90 å€¼ï¼Œæ”»æ“Šç›®æ¨™é›†ä¸­',
                    'reference': 'DDoS æ”»æ“Šæ¨¡å¼ç ”ç©¶'
                }
            }

        # ========== 5. DATA_EXFILTRATION ==========
        exfil_analysis = self.analyze_threat_class('DATA_EXFILTRATION')
        if exfil_analysis['count'] > 5:
            features = exfil_analysis['features']

            # æ ¹æ“š TU Delft ç ”ç©¶
            recommendations['DATA_EXFILTRATION'] = {
                'total_bytes': {
                    'current': 1e9,  # 1GB
                    'recommended': int(features['total_bytes']['p10']),
                    'rationale': 'P10 å€¼ï¼Œæ•¸æ“šå¤–æ´©é–¾å€¼',
                    'reference': 'https://repository.tudelft.nl/islandora/object/uuid:19aa873d-b38d-4133-bcf8-7c6c625af739'
                },
                'unique_dsts': {
                    'current': 5,
                    'recommended': max(3, int(features['unique_dsts']['p90'])),
                    'rationale': 'P90 å€¼ï¼Œå¤–æ´©ç›®æ¨™é›†ä¸­',
                    'reference': 'NetFlow æ•¸æ“šå¤–æ´©æª¢æ¸¬ç ”ç©¶'
                },
                'dst_diversity': {
                    'current': 0.1,
                    'recommended': round(features['dst_diversity']['p75'], 2),
                    'rationale': 'P75 å€¼ï¼Œæµé‡é«˜åº¦é›†ä¸­',
                    'reference': 'æ•¸æ“šå¤–æ´©è¡Œç‚ºæ¨¡å¼åˆ†æ'
                }
            }

        # ========== 6. C2_COMMUNICATION ==========
        c2_analysis = self.analyze_threat_class('C2_COMMUNICATION')
        if c2_analysis['count'] > 5:
            features = c2_analysis['features']

            # æ ¹æ“š ScienceDirect (2013) æ®­å±ç¶²è·¯ç ”ç©¶
            recommendations['C2_COMMUNICATION'] = {
                'flow_count': {
                    'current': (100, 1000),  # ç¯„åœ
                    'recommended': (
                        int(features['flow_count']['p10']),
                        int(features['flow_count']['p90'])
                    ),
                    'rationale': 'P10-P90 ç¯„åœï¼ŒC2 é€šè¨Šä¸­ç­‰é€£ç·šæ•¸',
                    'reference': 'https://www.sciencedirect.com/science/article/pii/S2090123213001410'
                },
                'avg_bytes': {
                    'current': (1000, 100000),  # ç¯„åœ
                    'recommended': (
                        int(features['avg_bytes']['p10']),
                        int(features['avg_bytes']['p90'])
                    ),
                    'rationale': 'P10-P90 ç¯„åœï¼Œå‘½ä»¤å’Œæ§åˆ¶æ•¸æ“šå¤§å°',
                    'reference': 'æ®­å±ç¶²è·¯è¡Œç‚ºåˆ†æ'
                }
            }

        return recommendations

    def generate_report(self, recommendations: Dict, output_file: str = None):
        """
        ç”Ÿæˆè©³ç´°çš„åˆ†æå ±å‘Š

        Args:
            recommendations: æ¨è–¦é–¾å€¼å­—å…¸
            output_file: è¼¸å‡ºæ–‡ä»¶è·¯å¾‘ï¼ˆå¯é¸ï¼‰
        """
        report_lines = []

        # æ¨™é¡Œ
        report_lines.append("=" * 100)
        report_lines.append("åˆ†é¡å™¨é–¾å€¼å„ªåŒ–å ±å‘Š")
        report_lines.append(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("=" * 100)
        report_lines.append("")

        # æ•¸æ“šçµ±è¨ˆ
        report_lines.append("## æ•¸æ“šçµ±è¨ˆ")
        report_lines.append("")
        total = len(self.all_anomaly_features)
        report_lines.append(f"ç¸½ç•°å¸¸æ•¸é‡: {total}")
        report_lines.append("")

        for threat_class, features_list in self.anomaly_features.items():
            count = len(features_list)
            if count > 0:
                percentage = (count / total * 100) if total > 0 else 0
                report_lines.append(f"  {threat_class:25} {count:5} å€‹ ({percentage:5.1f}%)")

        report_lines.append("")
        report_lines.append("=" * 100)
        report_lines.append("")

        # æ¨è–¦é–¾å€¼
        report_lines.append("## æ¨è–¦é–¾å€¼")
        report_lines.append("")

        if not recommendations:
            report_lines.append("âš ï¸  æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•ç”Ÿæˆæ¨è–¦é–¾å€¼")
            report_lines.append("   å»ºè­°ï¼šæ”¶é›†æ›´å¤šå¤©æ•¸çš„æ•¸æ“šï¼ˆ--days 14 æˆ–æ›´å¤šï¼‰")
        else:
            for threat_class, thresholds in recommendations.items():
                report_lines.append(f"### {threat_class}")
                report_lines.append("")

                for param, details in thresholds.items():
                    report_lines.append(f"**{param}:**")
                    report_lines.append(f"  ç•¶å‰å€¼: {details['current']}")
                    report_lines.append(f"  æ¨è–¦å€¼: {details['recommended']}")
                    report_lines.append(f"  ç†ç”±: {details['rationale']}")
                    report_lines.append(f"  åƒè€ƒ: {details['reference']}")
                    report_lines.append("")

        report_lines.append("=" * 100)
        report_lines.append("")

        # è©³ç´°ç‰¹å¾µåˆ†æ
        report_lines.append("## è©³ç´°ç‰¹å¾µåˆ†æ")
        report_lines.append("")

        for threat_class in ['PORT_SCAN', 'NETWORK_SCAN', 'DNS_TUNNELING',
                            'DDOS', 'DATA_EXFILTRATION', 'C2_COMMUNICATION']:
            analysis = self.analyze_threat_class(threat_class)

            if analysis['count'] > 0:
                report_lines.append(f"### {threat_class} ({analysis['count']} å€‹æ¨£æœ¬)")
                report_lines.append("")

                for feature, stats in analysis.get('features', {}).items():
                    report_lines.append(f"**{feature}:**")

                    # å°æ–¼ diversity é¡ç‰¹å¾µä½¿ç”¨æ›´é«˜ç²¾åº¦ï¼ˆ4ä½å°æ•¸ï¼‰
                    # å› ç‚ºå®ƒå€‘æ˜¯æ¯”ç‡ï¼Œé€šå¸¸åœ¨ 0-1 ä¹‹é–“
                    if 'diversity' in feature:
                        precision = 4
                    # å°æ–¼ bytes é¡ç‰¹å¾µä½¿ç”¨æ•´æ•¸æ ¼å¼
                    elif 'bytes' in feature:
                        precision = 0
                    # å…¶ä»–ä½¿ç”¨ 2 ä½å°æ•¸
                    else:
                        precision = 2

                    if precision == 0:
                        report_lines.append(f"  ç¯„åœ: {stats['min']:.0f} - {stats['max']:.0f}")
                        report_lines.append(f"  å¹³å‡: {stats['mean']:.0f} Â± {stats['std']:.0f}")
                        report_lines.append(f"  ä¸­ä½æ•¸: {stats['median']:.0f}")
                        report_lines.append(f"  P10/P25/P75/P90: {stats['p10']:.0f} / {stats['p25']:.0f} / {stats['p75']:.0f} / {stats['p90']:.0f}")
                    elif precision == 4:
                        report_lines.append(f"  ç¯„åœ: {stats['min']:.4f} - {stats['max']:.4f}")
                        report_lines.append(f"  å¹³å‡: {stats['mean']:.4f} Â± {stats['std']:.4f}")
                        report_lines.append(f"  ä¸­ä½æ•¸: {stats['median']:.4f}")
                        report_lines.append(f"  P10/P25/P75/P90: {stats['p10']:.4f} / {stats['p25']:.4f} / {stats['p75']:.4f} / {stats['p90']:.4f}")
                    else:
                        report_lines.append(f"  ç¯„åœ: {stats['min']:.2f} - {stats['max']:.2f}")
                        report_lines.append(f"  å¹³å‡: {stats['mean']:.2f} Â± {stats['std']:.2f}")
                        report_lines.append(f"  ä¸­ä½æ•¸: {stats['median']:.2f}")
                        report_lines.append(f"  P10/P25/P75/P90: {stats['p10']:.2f} / {stats['p25']:.2f} / {stats['p75']:.2f} / {stats['p90']:.2f}")

                    report_lines.append("")

        report_lines.append("=" * 100)

        # æ‰“å°å ±å‘Š
        report_text = "\n".join(report_lines)
        print(report_text)

        # ä¿å­˜åˆ°æ–‡ä»¶
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report_text)
                print(f"\nâœ… å ±å‘Šå·²ä¿å­˜åˆ°: {output_file}\n")
            except Exception as e:
                print(f"\nâš ï¸  ç„¡æ³•ä¿å­˜å ±å‘Š: {e}\n")


def main():
    parser = argparse.ArgumentParser(
        description='åˆ†é¡å™¨é–¾å€¼å„ªåŒ–å·¥å…· - åŸºæ–¼æ­·å²æ•¸æ“šåˆ†ææœ€å„ªé–¾å€¼'
    )
    parser.add_argument(
        '--days',
        type=int,
        default=7,
        help='åˆ†æéå» N å¤©çš„æ•¸æ“šï¼ˆé»˜èª: 7ï¼‰'
    )
    parser.add_argument(
        '--config',
        type=str,
        default='nad/config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾‘'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='reports/classifier_threshold_optimization.txt',
        help='å ±å‘Šè¼¸å‡ºè·¯å¾‘'
    )

    args = parser.parse_args()

    # è¼‰å…¥é…ç½®
    print(f"\nğŸ“‹ è¼‰å…¥é…ç½®...")
    try:
        config = load_config(args.config)
        print(f"âœ“ é…ç½®è¼‰å…¥æˆåŠŸ\n")
    except Exception as e:
        print(f"âŒ é…ç½®è¼‰å…¥å¤±æ•—: {e}\n")
        sys.exit(1)

    # å‰µå»ºå„ªåŒ–å™¨
    optimizer = ClassifierThresholdOptimizer(config)

    # æ”¶é›†æ­·å²ç•°å¸¸
    total = optimizer.collect_historical_anomalies(days=args.days)

    if total == 0:
        print("âŒ æ²’æœ‰æ”¶é›†åˆ°ç•°å¸¸æ•¸æ“šï¼Œç„¡æ³•å„ªåŒ–é–¾å€¼\n")
        print("å»ºè­°ï¼š")
        print("  1. ç¢ºä¿ Isolation Forest æ¨¡å‹å·²è¨“ç·´")
        print("  2. ç¢ºä¿æœ‰è¶³å¤ çš„æ­·å²æµé‡æ•¸æ“š")
        print("  3. å˜—è©¦å¢åŠ åˆ†æå¤©æ•¸ï¼ˆ--days 14ï¼‰\n")
        sys.exit(1)

    # åˆ†æä¸¦æ¨è–¦é–¾å€¼
    print(f"\n{'='*80}")
    print("åˆ†æç‰¹å¾µåˆ†ä½ˆä¸¦æ¨è–¦é–¾å€¼...")
    print(f"{'='*80}\n")

    recommendations = optimizer.recommend_thresholds()

    # ç”Ÿæˆå ±å‘Š
    optimizer.generate_report(recommendations, args.output)


if __name__ == "__main__":
    main()
