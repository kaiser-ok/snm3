#!/usr/bin/env python3
"""
æª¢æŸ¥è¨“ç·´æº–å‚™æƒ…æ³
"""

import requests
import json
import warnings
from datetime import datetime

# å¿½ç•¥ Elasticsearch å®‰å…¨è­¦å‘Š
warnings.filterwarnings('ignore', message='.*Elasticsearch built-in security features.*')

ES_HOST = "http://localhost:9200"
INDEX = "netflow_stats_5m"

print("=" * 70)
print("Isolation Forest è¨“ç·´æº–å‚™æƒ…æ³æª¢æŸ¥")
print("=" * 70)
print()

# 1. æª¢æŸ¥ç´¢å¼•
print("âœ“ æª¢æŸ¥ 1: Elasticsearch ç´¢å¼•...")
try:
    resp = requests.get(f"{ES_HOST}/{INDEX}/_count")
    data = resp.json()
    total = data['count']
    print(f"  - ç´¢å¼•: {INDEX}")
    print(f"  - ç¸½æ–‡æª”æ•¸: {total:,}")

    if total > 0:
        print(f"  âœ… ç´¢å¼•æœ‰æ•¸æ“š")
    else:
        print(f"  âŒ ç´¢å¼•ç„¡æ•¸æ“šï¼Œç„¡æ³•è¨“ç·´")
        exit(1)
except Exception as e:
    print(f"  âŒ ES é€£æ¥å¤±æ•—: {e}")
    exit(1)

print()

# 2. æª¢æŸ¥æ™‚é–“ç¯„åœ
print("âœ“ æª¢æŸ¥ 2: æ•¸æ“šæ™‚é–“ç¯„åœ...")
query = {
    "size": 0,
    "aggs": {
        "time_range": {
            "stats": {"field": "time_bucket"}
        }
    }
}

try:
    resp = requests.post(
        f"{ES_HOST}/{INDEX}/_search",
        json=query,
        headers={'Content-Type': 'application/json'}
    )
    data = resp.json()
    stats = data['aggregations']['time_range']

    min_time = datetime.fromtimestamp(stats['min'] / 1000)
    max_time = datetime.fromtimestamp(stats['max'] / 1000)
    count = int(stats['count'])

    duration_hours = (max_time - min_time).total_seconds() / 3600
    duration_days = duration_hours / 24

    print(f"  - æœ€æ—©æ™‚é–“: {min_time}")
    print(f"  - æœ€æ–°æ™‚é–“: {max_time}")
    print(f"  - æ™‚é–“è·¨åº¦: {duration_hours:.1f} å°æ™‚ ({duration_days:.1f} å¤©)")

    if duration_hours >= 24:
        print(f"  âœ… æ•¸æ“šå……è¶³ï¼ˆ{duration_days:.1f} å¤©ï¼‰")
        days_param = min(int(duration_days), 7)
    elif duration_hours >= 6:
        print(f"  âš ï¸  æ•¸æ“šè¼ƒå°‘ï¼ˆ{duration_hours:.1f} å°æ™‚ï¼‰ï¼Œä½†å¯è¨“ç·´")
        days_param = 1
    else:
        print(f"  âš ï¸  æ•¸æ“šä¸è¶³ï¼ˆ{duration_hours:.1f} å°æ™‚ï¼‰")
        days_param = 1

except Exception as e:
    print(f"  âŒ æŸ¥è©¢å¤±æ•—: {e}")
    exit(1)

print()

# 3. æª¢æŸ¥æ¨£æœ¬åˆ†å¸ƒ
print("âœ“ æª¢æŸ¥ 3: æ¨£æœ¬åˆ†å¸ƒ...")
query = {
    "size": 0,
    "aggs": {
        "by_ip": {
            "cardinality": {
                "field": "src_ip",
                "precision_threshold": 10000
            }
        },
        "flow_stats": {
            "stats": {
                "field": "flow_count"
            }
        }
    }
}

try:
    resp = requests.post(
        f"{ES_HOST}/{INDEX}/_search",
        json=query,
        headers={'Content-Type': 'application/json'}
    )
    data = resp.json()

    unique_ips = int(data['aggregations']['by_ip']['value'])
    flow_stats = data['aggregations']['flow_stats']

    print(f"  - å”¯ä¸€ IP æ•¸: {unique_ips:,}")
    print(f"  - å¹³å‡é€£ç·šæ•¸: {flow_stats['avg']:.0f}")
    print(f"  - æœ€å¤§é€£ç·šæ•¸: {flow_stats['max']:.0f}")
    print(f"  - æœ€å°é€£ç·šæ•¸: {flow_stats['min']:.0f}")

    if unique_ips >= 100:
        print(f"  âœ… IP å¤šæ¨£æ€§è‰¯å¥½")
    else:
        print(f"  âš ï¸  IP æ•¸é‡è¼ƒå°‘ï¼Œå¯èƒ½å½±éŸ¿æ•ˆæœ")

except Exception as e:
    print(f"  âŒ æŸ¥è©¢å¤±æ•—: {e}")

print()

# 4. æª¢æŸ¥æ•¸æ“šå“è³ª
print("âœ“ æª¢æŸ¥ 4: æ•¸æ“šå“è³ª...")
query = {
    "size": 10,
    "sort": [{"time_bucket": "desc"}]
}

try:
    resp = requests.post(
        f"{ES_HOST}/{INDEX}/_search",
        json=query,
        headers={'Content-Type': 'application/json'}
    )
    data = resp.json()

    if data['hits']['total']['value'] > 0:
        sample = data['hits']['hits'][0]['_source']

        required_fields = [
            'flow_count', 'total_bytes', 'total_packets',
            'unique_dsts', 'unique_ports', 'avg_bytes', 'max_bytes'
        ]

        missing = [f for f in required_fields if f not in sample]

        if not missing:
            print(f"  âœ… æ‰€æœ‰å¿…è¦æ¬„ä½éƒ½å­˜åœ¨")
        else:
            print(f"  âš ï¸  ç¼ºå°‘æ¬„ä½: {missing}")

        # é¡¯ç¤ºæ¨£æœ¬
        print(f"\n  æœ€æ–°è¨˜éŒ„æ¨£æœ¬:")
        print(f"    - time_bucket: {sample.get('time_bucket')}")
        print(f"    - src_ip: {sample.get('src_ip')}")
        print(f"    - flow_count: {sample.get('flow_count', 0):,}")
        print(f"    - unique_dsts: {sample.get('unique_dsts', 0)}")
        print(f"    - total_bytes: {sample.get('total_bytes', 0):,}")

except Exception as e:
    print(f"  âŒ æŸ¥è©¢å¤±æ•—: {e}")

print()
print("=" * 70)
print("è¨“ç·´å»ºè­°")
print("=" * 70)
print()

print(f"âœ… æº–å‚™æƒ…æ³: æ•¸æ“šå·²å°±ç·’ï¼Œå¯ä»¥é–‹å§‹è¨“ç·´\n")

print(f"ğŸ“‹ æ¨è–¦è¨“ç·´å‘½ä»¤:\n")
print(f"  python3 train_isolation_forest.py --days {days_param} --evaluate\n")

if duration_hours < 24:
    print(f"âš ï¸  æ³¨æ„äº‹é …:")
    print(f"  - ç•¶å‰æ•¸æ“šé‡è¼ƒå°‘ï¼ˆ{duration_hours:.1f} å°æ™‚ï¼‰")
    print(f"  - æ¨¡å‹å¯èƒ½å°æ­£å¸¸è¡Œç‚ºç†è§£ä¸å®Œæ•´")
    print(f"  - å»ºè­°24å°æ™‚å¾Œä½¿ç”¨æ›´å¤šæ•¸æ“šé‡è¨“ç·´")
    print(f"  - é‡è¨“ç·´å‘½ä»¤: python3 train_isolation_forest.py --days 1")
    print()

print(f"ğŸ’¡ æç¤º:")
print(f"  - è¨“ç·´æ™‚é–“é ä¼°: {total/10000:.0f}-{total/5000:.0f} åˆ†é˜")
print(f"  - è¨“ç·´å®Œæˆå¾Œå¯ä½¿ç”¨: python3 realtime_detection.py --minutes 10")
print()

print("=" * 70)
